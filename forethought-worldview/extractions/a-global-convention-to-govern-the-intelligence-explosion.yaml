paper:
  slug: "a-global-convention-to-govern-the-intelligence-explosion"
  title: "A global convention to govern the intelligence explosion"

premises_taken_as_given:
  - claim: "AI may plausibly lead to an 'intelligence explosion'â€”a speed-up in technological development comparable in magnitude to the agricultural and industrial revolutions."
    confidence: "strong"
    evidence: "Stated in the introduction as background framing and linked to other Forethought work; the paper builds its entire proposal on this possibility without arguing for it."
  - claim: "The intelligence explosion could unfold over months or a small number of years ('medium-speed takeoff' is the best-guess scenario)."
    confidence: "strong"
    evidence: "Explicitly stated as the author's best guess in the objections section; the proposal is designed around this timeline assumption."
  - claim: "The US is and will remain the frontrunner in AI development with a lead of more than one month over rivals."
    confidence: "strong"
    evidence: "The entire feasibility argument for the one-month pause rests on this assumption; acknowledged as a scenario where the plan could fail if wrong."
  - claim: "Misaligned AI takeover is a serious risk but is only one of many catastrophic risks from the intelligence explosion."
    confidence: "near-certain"
    evidence: "Listed alongside democratic erosion, WMD governance, digital rights, resource races, etc. as co-equal concerns, without arguing for AI risk specifically."
  - claim: "The governance period surrounding the intelligence explosion is among the most consequential moments in human history."
    confidence: "near-certain"
    evidence: "Described as 'crucial' and 'one of the highest-leverage things we can do' without further justification."
  - claim: "AI-assisted deliberation will be substantially more capable near the threshold of an intelligence explosion than it is today, enough to dramatically increase policy-design efficiency."
    confidence: "strong"
    evidence: "Listed as a key benefit of timing the pause later rather than sooner; no argument is offered for this capability jump."
  - claim: "Lock-in of power structures and resource distribution is a real and tractable concern during rapid capability gains."
    confidence: "strong"
    evidence: "Space resource grabs, automation of military/police, and economic obsolescence of human labour are treated as near-inevitable governance challenges."

distinctive_claims:
  - claim: "Governance of the intelligence explosion should be organized around a predefined threshold that converts a gradual process into a discrete political event."
    centrality: "thesis"
    key_argument: "A step-change framing makes it easier for politicians to act, for civil society to rally, and for the pause to be politically and strategically feasible."
  - claim: "The optimal intervention is a pre-committed one-month pause of frontier AI development by the US at this threshold, coupled with a time-bound international convention."
    centrality: "thesis"
    key_argument: "The pause is short enough to be feasible (US doesn't lose its lead), timed when AI-assisted deliberation and political salience are maximized, and creates space for drafting multilateral treaties."
  - claim: "The convention should bundle many disparate governance issues (AI safety, space resources, digital rights, WMD regulation, democratic preservation, economic redistribution) into a single event rather than addressing them separately."
    centrality: "load-bearing"
    key_argument: "Explosive capability progress will surface many issues simultaneously; they interact with each other; and there will be unforeseen issues requiring a catch-all process."
  - claim: "Political feasibility requires the US to ultimately 'call the shots' at such a convention, with other countries (especially China and European nations) gaining influence through verifiable participation in the pause."
    centrality: "load-bearing"
    key_argument: "Analogized to UN Charter formation where participation was incentivized but the text was largely US-written; greater ambition in power-sharing is judged too politically costly."
  - claim: "The threshold should be defined by a combination of technical benchmarks and a panel of leading experts, not purely by automated metrics."
    centrality: "supporting"
    key_argument: "Expert judgment provides flexibility to handle edge cases that rigid benchmarks would miss."
  - claim: "The ML research community could use collective leverage (a 'Union of Concerned Computer Scientists') to force the pause."
    centrality: "supporting"
    key_argument: "Researchers could conditionally withhold labor once the threshold is crossed, creating a credible enforcement mechanism."
  - claim: "A one-month pause could lead to longer pauses, slowdowns via non-standard routes (e.g. energy restrictions), or agreements to delay specific moments of lock-in."
    centrality: "load-bearing"
    key_argument: "The initial pause is a foot-in-the-door; once convened, the convention could extend itself or produce agreements with compounding effects."

positions_rejected:
  - position: "Focus entirely on substantive regulation now rather than planning a future convention."
    why_rejected: "Acknowledged as the most compelling alternative but judged inferior because it forfeits benefits of AI-assisted deliberation, better information closer to the explosion, and wider political buy-in."
  - position: "Address each governance challenge (space, digital rights, AI safety, etc.) through separate conventions."
    why_rejected: "Issues will arrive simultaneously, interact with each other, and there will be unforeseen issues; bundling avoids bad treaty interactions and provides a catch-all."
  - position: "Push for a more ambitious power-sharing arrangement giving non-US countries equal governance authority."
    why_rejected: "Judged much less politically feasible; feasibility cost is considered decisive, though the author leaves the door open."
  - position: "Very fast takeoff (days or weeks) as a likely scenario."
    why_rejected: "Explicitly called 'very unlikely'; the proposal is designed for medium-speed takeoff and acknowledged as not helpful for extremely fast scenarios."
  - position: "Business-as-usual politics can handle the intelligence explosion if it's slow enough."
    why_rejected: "Even in slower scenarios, the convention has no significant downside and creates useful focal points for advance policy work."
  - position: "The US would never voluntarily pause because charging ahead maximizes its power."
    why_rejected: "Pausing reduces risks of weight theft, supply chain disruption, and preemptive military action; leaders are ideologically motivated not purely self-interested; the cost is small relative to gains."

methodological_commitments:
  - "Policy design via institutional analogy: extensive use of historical precedents (UN Charter formation, NPT, Montreal Protocol, WTO, Chemical Weapons Convention) to calibrate feasibility."
  - "Explicit objection-and-response dialectical structure as the primary method of stress-testing the proposal."
  - "Scenario-based reasoning organized around takeoff speed (fast/medium/slow) and lead size of the frontrunner."
  - "Political feasibility as a binding constraint on proposal design, repeatedly invoked to reject more ambitious alternatives."
  - "Focus on creating discrete decision points and focal points for coordination, rather than continuous regulatory processes."
  - "Qualitative reasoning and judgment calls rather than formal models or quantitative estimates."

cross_references:
  - "preparing-for-the-intelligence-explosion"
  - "three-types-of-intelligence-explosion"
  - "the-un-charter-a-case-study-in-international-governance"
  - "what-an-international-project-to-develop-agi-should-look-like"
  - "international-ai-projects-and-differential-ai-development"
  - "an-overview-of-some-international-organisations-with-their-voting-structures"