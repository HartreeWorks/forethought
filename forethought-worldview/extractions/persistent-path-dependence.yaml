paper:
  slug: "persistent-path-dependence"
  title: "Persistent Path-Dependence: Why Our Actions Matter Long-Term"

premises_taken_as_given:
  - claim: "AGI will very likely be developed within our lifetimes, probably within the next two decades."
    confidence: "near-certain"
    evidence: "Cites Metaculus forecasts (90% by 2100, 77% by 2045) and builds entire argument on this assumption without defending it."
  - claim: "The expected value of future civilisation is positive rather than negative."
    confidence: "strong"
    evidence: "Treats this as a baseline assumption for extinction risk reduction arguments, though notes it's a necessary premise."
  - claim: "Different human-directed futures vary dramatically in value."
    confidence: "near-certain"
    evidence: "References prior essays ('No Easy Eutopia', 'Convergence and Compromise') as having established this, and builds on it without re-arguing."
  - claim: "AGI could plausibly drive explosive technological progress and industrial expansion."
    confidence: "strong"
    evidence: "States 'I also think is more likely than not' but does not argue for it; treats it as a working assumption throughout section 6."
  - claim: "Longtermism—the view that positively influencing the long-term future is a key moral priority—is correct."
    confidence: "near-certain"
    evidence: "The entire framing assumes longtermism; the paper's question is which longtermist priorities to pursue, not whether longtermism is valid."
  - claim: "Values are the most important thing to get right for the long-term future, more so than which specific individuals or regimes persist."
    confidence: "strong"
    evidence: "Explicitly states 'I also focus in particular on how values persist into the future. This, in my view, is much more important than whether some particular individual or regime persists.'"

distinctive_claims:
  - claim: "The 'wash out' objection does not justify prioritising extinction risk reduction over 'better futures' work, because multiple non-extinction mechanisms can produce persistent path-dependent effects of comparable durability."
    centrality: "thesis"
    key_argument: "AGI-enforced institutions, immortality, designed beings, strong self-modification, power concentration, and defense-dominance each provide mechanisms for values to persist indefinitely; these are likely to be activated this century."
  - claim: "Extinction risk reduction is not unique in its ability to predictably affect the long-run future; the same logic that justifies caring about AI takeover also justifies caring about which human-directed future we get."
    centrality: "load-bearing"
    key_argument: "Judging AI-takeover as bad requires a comparative judgment about civilisation quality, not just quantity—the same type of judgment needed to compare, e.g., US-hegemonic vs. China-hegemonic futures."
  - claim: "Reducing human extinction risk mainly affects WHO occupies our cosmic neighbourhood rather than WHETHER it gets occupied, because replacement civilisations (re-evolved intelligence, alien settlement) are reasonably likely."
    centrality: "load-bearing"
    key_argument: "Assigns >50% probability to re-evolution of intelligence from surviving mammals, and ~50% to alien civilisations eventually settling our region, meaning extinction risk reduction is ~75% less valuable than naively calculated."
  - claim: "'Lock-in escape velocity'—short-term power entrenchment can bootstrap into indefinite lock-in through iteratively extending control horizons."
    centrality: "load-bearing"
    key_argument: "If you can entrench power for 10 years, you can use that to develop means for 20 years, then 40, etc.; the point of no return may come well before full lock-in mechanisms exist. Even the US Founding Fathers may have achieved this."
  - claim: "The expected variance in the value of the future will reduce by about a third this century, with the majority of that reduction coming from things other than extinction risk or AI disempowerment."
    centrality: "thesis"
    key_argument: "This is the paper's core quantitative claim, derived from the combined likelihood of the multiple lock-in mechanisms discussed."
  - claim: "Post-AGI dictatorship need not be totalitarian because populations can be designed to endorse the regime, making surveillance unnecessary."
    centrality: "supporting"
    key_argument: "The ability to design beings' preferences means dystopia is more likely to look like willing endorsement than enforced compliance."
  - claim: "Defense-dominance of star systems could make the initial allocation of space resources a permanently path-dependent event."
    centrality: "supporting"
    key_argument: "If star systems are strongly defense-dominant, whoever controls them at initial settlement retains them indefinitely; the allocation process thus becomes a pivotal moment."
  - claim: "The historical dynamism that has prevented lock-in to date is driven by specific factors (death of leaders, generational value change, technological disruption, external competition) that are each plausibly ending due to near-term technological developments."
    centrality: "load-bearing"
    key_argument: "Immortality removes death; designing beings removes generational drift; technological maturity removes tech disruption; power concentration or defense-dominance removes external competition."

positions_rejected:
  - position: "The effects of our actions (short of extinction) will inevitably 'wash out' over long time horizons."
    why_rejected: "Multiple concrete mechanisms—AGI-enforced institutions, immortality, designed beings, self-modification, power concentration, defense-dominance—could cause effects to persist indefinitely; the historical flux that motivates this view is driven by factors that are themselves ending."
  - position: "Extinction risk reduction is the only longtermist priority with predictably persistent effects."
    why_rejected: "This position requires an inconsistent epistemology: judging AI takeover as bad requires the same kind of comparative judgment about civilisation quality that 'better futures' work requires."
  - position: "Reducing human extinction risk by X% increases the probability of any future civilisation by X%."
    why_rejected: "Replacement civilisations (re-evolved species, alien settlement) are plausible enough that extinction mainly shifts who occupies our region, not whether it's occupied."
  - position: "Historical patterns of societal flux should make us confident the future will remain similarly open and dynamic."
    why_rejected: "The roulette wheel analogy: past unpredictability doesn't entail future unpredictability; the ball eventually settles. The specific drivers of historical flux are ending."
  - position: "Lock-in requires a state from which escape is literally impossible."
    why_rejected: "This definition misses central cases where agents with power continuously choose to maintain a state; what matters is persistent path-dependence, not strict impossibility of change."

methodological_commitments:
  - "Expected value reasoning applied to very long time horizons, with explicit probability estimates for key parameters."
  - "Thought experiments and vivid hypothetical scenarios to illustrate mechanisms (e.g. Stalin uploading his mind, roulette wheel analogy)."
  - "Argument by mechanism identification: establishing that persistent path-dependence is likely by enumerating concrete causal pathways rather than arguing from abstract principles."
  - "Historical analogy as evidence for political dynamics (ideological purges, power entrenchment in Russia/China/Hungary/Turkey/Belarus)."
  - "Conceptual analysis of key terms ('lock-in', 'path-dependence') to clarify what exactly is being claimed."
  - "Forecasting platform citations (Metaculus) as evidence for probability estimates."
  - "Willingness to assign rough numerical probabilities to highly uncertain claims (e.g. >50% for re-evolution, ~50% for alien civilisations, ~75% reduction in extinction risk value, ~1/3 variance reduction this century)."

cross_references:
  - "agi-and-lock-in"
  - "no-easy-eutopia"
  - "convergence-and-compromise"
  - "how-to-make-the-future-better"
  - "ai-enabled-coups-how-a-small-group-could-use-ai-to-seize-power"
  - "preparing-for-the-intelligence-explosion"