paper:
  slug: "design-sketches-for-a-more-sensible-world"
  title: "Design sketches for a more sensible world"

premises_taken_as_given:
  - claim: "AI development represents an epoch-defining transition for humanity."
    confidence: "near-certain"
    evidence: "Framed without argument as foundational context; links to 'the crucible,' 'intelligence explosion,' and 'the choice transition' as complementary framings of the same premise."
  - claim: "Humanity currently lacks adequate foresight and coordination to navigate AI development well."
    confidence: "near-certain"
    evidence: "Stated flatly in the opening ('We don't think that humanity knows what it's doing') and treated as the motivating problem, not as a claim requiring defense."
  - claim: "The speed of AI progress is accelerating and this acceleration is itself a risk factor."
    confidence: "near-certain"
    evidence: "'Things are getting faster and faster' is asserted without evidence as background context."
  - claim: "Near-term AI systems are already capable enough to serve as building blocks for reasoning and coordination tools."
    confidence: "strong"
    evidence: "The entire paper presupposes that the proposed technologies are achievable soon with current or near-future AI capabilities, though it acknowledges 'actual technologies that make most sense could in some cases look quite different.'"
  - claim: "Surviving historical transitions by 'muddling through' was substantially luck-dependent and this strategy is inadequate for AI."
    confidence: "strong"
    evidence: "The airlock analogy explicitly frames survival-through-luck as not-wisdom; historical muddling-through is acknowledged but treated as insufficient precedent."
  - claim: "Improving collective epistemics, individual decision-making, and coordination are complementary and mutually reinforcing."
    confidence: "strong"
    evidence: "The systems diagram shows these feeding into each other (fewer mistakes → more trust → less conflict → more sensible world), treated as a natural architecture rather than argued for."

distinctive_claims:
  - claim: "The highest-leverage intervention for AI safety/governance is building AI-powered tools that augment human reasoning and coordination capacity, rather than focusing primarily on alignment of frontier models or governance restrictions."
    centrality: "thesis"
    key_argument: "The core framing is that the problem is humanity's collective cluelessness, and the solution is to use AI itself to upgrade our epistemic and coordination infrastructure before the transition gets away from us."
  - claim: "A 'more sensible world' is achievable soon—the gap between our current fumbling and adequate navigation is closable with near-term technology."
    centrality: "thesis"
    key_argument: "Presented as the paper's optimistic but actionable claim: 'a more sensible world should be achievable, soon — and more should be done to help us get there.'"
  - claim: "Concrete design sketches and technology visions are an important intervention for directing builder/maker effort toward beneficial applications."
    centrality: "load-bearing"
    key_argument: "The paper's explicit theory of change: being concrete helps 'kickstart more of the visioning process' and 'encourage builders and makers to push ahead on directions inspired by these technologies.'"
  - claim: "Privacy-preserving assurance technology can unlock currently impossible forms of cooperation by enabling deals based on confidential information."
    centrality: "supporting"
    key_argument: "Presented as enabling agreements that are 'currently unenforceable,' suggesting a structural barrier to cooperation that technology can remove."
  - claim: "Recommender systems should optimize for long-term user endorsement rather than short-term engagement."
    centrality: "supporting"
    key_argument: "Treats the current engagement-maximizing paradigm as a clear failure mode and the endorsed-outcomes framing as the obvious alternative."
  - claim: "The taxonomy of needed tools spans five clusters: collective epistemics, individual decision-support ('angels'), strategic awareness, coordination, and assurance/privacy."
    centrality: "load-bearing"
    key_argument: "This categorization structures the entire series and implicitly claims these are the key bottlenecks to a 'more sensible world.'"

positions_rejected:
  - position: "We can rely on muddling through / historical precedent to navigate AI development safely."
    why_rejected: "Explicitly compared to releasing an airlock on an unknown planet; the argument is that AI is sufficiently unprecedented that past survival is not evidence of adequate strategy."
  - position: "The primary response to AI risk should be slowing down or restricting AI development."
    why_rejected: "Not explicitly argued against, but conspicuously absent; the entire framing is about harnessing AI as a tool for better reasoning and coordination rather than constraining it."
  - position: "Sufficient AI safety comes from aligning individual AI systems."
    why_rejected: "Implicitly deprioritized; the paper frames the core problem as humanity's collective epistemic and coordination failures, not as properties of AI systems themselves."
  - position: "Detailed future technology design is premature or not useful because actual implementations will differ."
    why_rejected: "Acknowledged ('actual technologies... could look quite different') but explicitly argued that concreteness is valuable for kickstarting vision and builder motivation."

methodological_commitments:
  - "Design fiction / concrete scenario sketching as a research output—using detailed technology mockups to make abstract ideas viscerally imaginable."
  - "Systems thinking: explicitly mapping causal relationships between tool categories and downstream outcomes (the hand-drawn systems diagram)."
  - "Theory of change oriented toward inspiring builders and makers rather than producing formal analysis or quantitative estimates."
  - "Emphasis on complementary interventions and positive-sum framing (win-win deals, tools that serve everyone's interests) rather than adversarial or zero-sum framings."
  - "Iterative collaborative process: multiple rounds of development, AI assistance, and extensive expert consultation."

cross_references:
  - "preparing-for-the-intelligence-explosion"
  - "design-sketches-collective-epistemics"
  - "design-sketches-angels-on-the-shoulder"