**[The Second-Order Catastrophist]** Suppose the paper is correct that compute bottlenecks don't kick in until "a few OOMs of progress" into the SIE. This means we get rapid, largely unconstrained algorithmic improvement for months or years before hitting any natural speed limit. The paper frames this as good news for SIE believers, but consider the failure mode: a sudden, unpredictable transition from "progress accelerating freely" to "hard wall." Labs will have built organizational structures, raised capital, and made commitments premised on continued acceleration. When the bottleneck hits, they face massive sunk costs and pressure to find workaroundsâ€”potentially including abandoning safety-relevant compute overhead, cutting corners on alignment testing, or racing to deploy undertested systems before competitors. The paper's "good chance bottlenecks don't slow things until late stages" is precisely the setup for a whiplash transition where the deceleration itself causes catastrophic decision-making.