**[The Empirical Hardliner]** The paper claims that ρ values between -0.2 and 0 are "most likely" for AI R&D, but provides zero empirical evidence specific to AI research productivity. The author dismisses economic estimates of ρ (ranging from -1.2 to -0.15) as inapplicable, then substitutes personal intuitions about "optimising every part of the stack" and conversations with unnamed AI researchers. Where is the data on how AI research output actually scales with researcher count at fixed compute? Where are the controlled experiments varying cognitive labor inputs while holding compute constant? The author's "max speed seems implausibly low" argument is pure intuition pump—there's no identified causal mechanism explaining why AI R&D should have fundamentally different substitution elasticity than other empirically-studied domains. If the claim is that AI R&D is special, the burden is to demonstrate this empirically, not to gesture at theoretical possibilities like "AGIs doing math in their heads to simulate experiments."