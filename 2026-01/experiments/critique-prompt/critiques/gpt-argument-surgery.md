**Surgical Mode Chosen:** Equilibrium/Institutional Pinch Points (attack incentive compatibility + strategic responses)

**Steelman (≤120 words):**
The paper argues that reaching a "mostly-great future" requires either (a) widespread, accurate, motivational convergence on correct moral views (WAM-convergence), or (b) partial convergence plus trade/compromise under favorable institutional conditions. The authors grant that WAM-convergence is unlikely given both realist and anti-realist metaethics, but maintain that trade/compromise offers a plausible path—if value-destroying threats can be contained and collective decision-making doesn't seal off valuable futures. The strongest version holds that even minority groups holding correct views could, through gains from trade with resource-compatible counterparties, secure outcomes approaching near-best on their view. The paper's practical upshot is that scenario (3)—broad convergence—warrants more attention than power-seeking, because marginal impact is higher there.

---

**Argument Skeleton Map:**

- **C (Main Conclusion):** A mostly-great future is unlikely via WAM-convergence alone, but plausible via partial AM-convergence plus trade/compromise, conditional on avoiding key blockers (threats, power concentration, poor collective decision-making).

- **P1:** A mostly-great future is a narrow target (inherited from prior essay).
- **P2:** WAM-convergence is unlikely under both moral realism and anti-realism (Section 2.4).
- **P3:** Under partial AM-convergence, trade/compromise can generate large mutual gains across views with different resource valuations (Section 3.1-3.2).
- **P4:** Value-destroying threats can undermine trade gains, but if contained, trade yields mostly-great outcomes for "bounded above" views (Section 3.3-3.4).
- **P5:** If no one aims at the good, self-interest alone is insufficient to hit the narrow target (Section 4).
- **P6:** Scenario (3) (broad convergence) is higher-stakes and higher-impact than scenario (1) (no convergence), so should dominate decision-making (Section 5).

- **I1:** P1 + P2 → WAM-convergence path is unlikely.
- **I2:** P3 + P4 → Trade/compromise path is conditionally viable.
- **I3:** P5 → Cannot rely on self-interest as substitute for moral motivation.
- **I4:** P6 → Practical focus should be on improving conditions for trade/compromise rather than personal power-seeking.

**Load-bearing nodes:** P3, P4, P6, I2

---

**Load-bearing Node Critiques:**

---

### Node P3: Trade/compromise generates large mutual gains across views

**Critique A (Strategic Response / Goodhart):**

The paper assumes that views will trade based on revealed moral preferences, but strategic actors will misrepresent their preferences to extract rents. Section 3.1 claims that "different groups could continue to value different natural resources" and that "superintelligence could enable iron-clad contracts." But iron-clad contracts enforce *stated* terms, not *sincere* moral valuations. If a group knows that expressing indifference to digital welfare yields better trade terms (because the minority who cares will pay more), groups will strategically claim indifference regardless of actual views. This is a Goodhart dynamic: the metric being optimized (stated preferences for trade) diverges from the target (actual moral valuations). The result is systematic misallocation away from hybrid goods toward whatever preferences are strategically advantageous to claim.

**Author's Best Reply:**
Superintelligent advisors could detect insincere preference revelation through behavioral analysis, consistency checks, and prediction markets on actual resource use. Moreover, repeated trade relationships incentivize honesty to maintain reputation. The gains from trade are so large that even imperfect preference revelation still yields substantial improvements over autarky.

**Rebuttal:**
Detection assumes preferences are stable and observable, but the paper itself (Section 2.2.1) argues that future beings will modify themselves into "one of a million different forms." Self-modification makes historical behavioral data unreliable for inference. Moreover, reputation mechanisms require iterated games, but the paper's scenario involves one-shot allocation of cosmic resources. Finally, "substantial improvements over autarky" is not the claim—the claim is that trade yields *mostly-great* futures, which requires precision the mechanism cannot deliver under strategic distortion.

**If true, what must change?**
The paper must either (a) specify an incentive-compatible mechanism for preference revelation that survives self-modification and one-shot allocation, or (b) downgrade the claim from "mostly-great future plausible via trade" to "moderately improved future."

---

**Critique B (Hidden Parameter):**

The paper treats "resource-compatibility" as a property of moral views (Section 3.2: "two views can be 'resource-compatible'"), but resource-compatibility depends critically on *technology*, which the argument treats as exogenous. Whether hedonists and objective-list theorists can create "beings that are both very blissful and very wise" depends on whether such beings are *computationally feasible* at comparable cost to specialized alternatives. If the production frontier exhibits strong trade-offs (wisdom requires cognitive architectures incompatible with maximal bliss), then the "hybrid good" strategy collapses. The paper assumes a convex production possibility frontier without argument.

**Author's Best Reply:**
We explicitly acknowledge uncertainty about which goods are resource-compatible (Section 3.2: "it's hard to know what fraction of resources the correct view will control"). The point is that *some* views are plausibly resource-compatible, and that's sufficient for conditional optimism.

**Rebuttal:**
The reply concedes the central point: resource-compatibility is an empirical variable, not a structural feature of moral trade. But the paper's optimism about trade (Section 3.4) depends on resource-compatibility being *common enough* that the correct view likely finds compatible trading partners. Without a model of how production frontiers relate to moral views, this is an ungrounded assumption. The paper cannot distinguish "some views are compatible" from "the correct view is probably compatible"—the latter requires the former plus a prior over which views are correct, which the paper explicitly declines to specify.

**If true, what must change?**
The paper must either characterize the distribution of resource-compatibility across plausible moral views, or weaken the claim to "trade helps *if* the correct view happens to be resource-compatible with prevalent views."

---

### Node P4: Value-destroying threats can be contained

**Critique A (Equilibrium Instability):**

Section 3.3 acknowledges that "even small risks of executed threats can easily eat into the expected value" and that "it's not obvious to us that some kind of legal system which reliably prevents value-undermining threats would be mutually agreeable and stable." But the paper then proceeds (Section 3.4) to condition optimism on threats being "prevented" without specifying the equilibrium that achieves this. The problem is that threat-prevention is itself a public good with standard free-rider dynamics: each group prefers others to bear the cost of enforcement while retaining private threat capacity. Absent a monopoly on violence (which the paper elsewhere treats as a "blocker" via power concentration), there is no stable equilibrium in which threats are reliably prevented.

**Author's Best Reply:**
Mutual vulnerability could create deterrence equilibria, similar to nuclear MAD. Alternatively, groups could pre-commit to retaliation against threat-makers, creating a stable norm against threats. Superintelligent coordination could identify and implement such equilibria.

**Rebuttal:**
MAD works because retaliation is cheap relative to first-strike gains and detection is reliable. But Section 3.3 notes that "those who hold the correct moral view may be less likely to themselves threaten other groups"—meaning the morally correct are systematically disadvantaged in deterrence games. They cannot credibly commit to value-destroying retaliation without abandoning their moral commitments. This is an asymmetric game where the correct view loses. Superintelligent coordination doesn't help if the correct view's commitment type is common knowledge.

**If true, what must change?**
The paper must either (a) explain how morally-motivated groups can credibly deter without compromising their values, or (b) accept that trade equilibria systematically disadvantage the correct moral view, making "mostly-great" outcomes unlikely even with trade.

---

**Critique B (Quantitative Cliff):**

Section 3.4 asserts that if "executed moral threats amount to a small but meaningful fraction of future resource use," then bounded-above views with jointly-aggregated goods achieve mostly-great futures. But "small but meaningful" is doing enormous work. The paper's own framework (No Easy Eutopia) claims the target is *narrow*—perhaps capturing only a small fraction of configuration space. If threats consume even 1% of resources but are optimized for destruction (as threat-makers would rationally do), and if the production function for bads is more efficient than for goods (plausible: entropy is easier than order), then 1% of resources devoted to threats could destroy value equivalent to 10% or more of resources devoted to goods. The "small fraction" framing obscures that threat efficiency, not threat prevalence, determines outcomes.

**Author's Best Reply:**
We explicitly consider cases where "bads weigh heavily against goods" (Section 3.4) and note these lead to pessimistic conclusions. The optimistic cases are conditional on bads not weighing heavily.

**Rebuttal:**
The reply treats "bads weigh heavily" as an axiological parameter, but threat efficiency is an *empirical* parameter that the paper ignores. Even on views where bads don't intrinsically weigh heavily, if destroying value is cheaper than creating it (a physical fact about entropy, not a moral fact), then small threat fractions yield large value losses. The paper conflates axiological weight with production efficiency.

**If true, what must change?**
The paper must incorporate threat *efficiency* as a separate parameter from axiological weight, and re-derive conditions under which trade yields mostly-great outcomes.

---

### Node P6: Scenario (3) is higher-stakes/higher-impact than Scenario (1)

**Critique A (Reversal):**

Section 5 argues that marginal impact is higher in Scenario (3) because "the future has a *lot* more value in scenario (3) than in scenario (1)." But this reasoning reverses under a different decision theory. If you assign non-negligible probability to Scenario (1), then the *marginal value of information* about which scenario obtains is extremely high—because your optimal strategy differs radically across scenarios. The paper's recommendation to "act much more on the assumption that we live in scenario (3)" is only correct if you're already confident in (3). If you're genuinely uncertain, the highest-impact action might be *resolving the uncertainty* (e.g., through philosophical research on convergence), not acting as if (3) is true.

**Author's Best Reply:**
We acknowledge uncertainty but argue that even under uncertainty, the expected impact calculation favors (3)-oriented actions because the payoffs are higher there. Philosophical research is itself a (3)-oriented action if it could shift probabilities toward convergence.

**Rebuttal:**
The reply assumes that (3)-oriented actions don't have opportunity costs in Scenario (1). But Section 5's own example shows they do: in Scenario (1), power-seeking has positive value; in Scenario (3), it has negative value (foregone cooperation). If you're uncertain, (3)-oriented actions actively harm you in Scenario (1). The expected value calculation requires probability-weighted payoffs across both scenarios, not just noting that (3) payoffs are higher conditional on (3).

**If true, what must change?**
The paper must either (a) provide a probability estimate for Scenario (3) sufficient to justify ignoring Scenario (1), or (b) recommend a mixed strategy or value-of-information strategy rather than "act on (3)."

---

**Critique B (Reference Class Sabotage):**

Section 5's impact calculation assumes that "devoting your life to the issue" yields comparable proportional improvements across scenarios. The example claims you can "increase the chance of *Surviving* by more than one part in a hundred thousand." But this assumes your efforts are not crowded out by others with similar motivations. In Scenario (3), by hypothesis, many beings converge on correct views—meaning many beings are working on the same problems. Marginal impact in (3) is therefore *lower* than the paper assumes due to diminishing returns to additional effort. In Scenario (1), you're one of few working on the problem, so marginal impact is *higher*. The paper's reference class ("you" as a representative agent) ignores the population of aligned agents, which differs systematically across scenarios.

**Author's Best Reply:**
Even with crowding, the absolute scale of value at stake in (3) is so much larger that marginal impact remains higher. Moreover, coordination among aligned agents in (3) could reduce redundancy.

**Rebuttal:**
The reply assumes coordination is frictionless, but the paper's own Section 3 extensively discusses coordination failures (threats, poor collective decision-making). If coordination is imperfect, crowding effects dominate. The paper cannot simultaneously argue that coordination is hard enough to make trade uncertain *and* easy enough to make crowding irrelevant.

**If true, what must change?**
The paper must model the population of aligned agents in each scenario and derive marginal impact accounting for crowding and coordination costs.

---

**Top 3 "Breakpoints":**

1. **Specify an incentive-compatible mechanism for preference revelation in trade** that survives strategic misrepresentation, self-modification, and one-shot allocation. Without this, the trade/compromise path cannot reliably hit the "narrow target."

2. **Model threat efficiency separately from axiological weight of bads.** The paper's conditional optimism ("if threats are small and bads don't weigh heavily") collapses if producing bads is cheaper than producing goods, which is an empirical question the paper ignores.

3. **Provide explicit probability estimates for Scenarios (1) vs. (3)** and derive decision recommendations from expected value across scenarios, not from conditional impact in the favored scenario. The current recommendation ("act on (3)") is only valid under implicit high confidence in (3).