# Argument Surgery: "Convergence and Compromise: Will Society Aim for Good Futures?"

## Thesis (one sentence)
Even if mostly-great futures are a narrow target, humanity might still reach one through either widespread moral convergence toward correct values (unlikely) or partial convergence combined with moral trade and compromise (more plausible but fragile), though neither path is assured.

## Load-bearing claims

1. **The Underpowering Claim**: Shared human preferences and common starting points are "underpowered" to ensure that different people's reflective processes converge on the same specific moral views required for a mostly-great future.

2. **The Trade Sufficiency Claim**: Under partial AM-convergence, moral trade and compromise between groups with different values can achieve outcomes where most views get close to their near-best futures.

3. **The Threat Vulnerability Claim**: Value-destroying threats can rob trade scenarios of most of their value, and on many moral views (bounded above, bads weigh heavily, etc.), even small fractions of executed threats eliminate most possible value.

4. **The Instrumental Agreement Breakdown Claim**: Current moral agreement is largely about instrumentally valuable goods, and this agreement will break down as technology allows optimization toward specific intrinsic goods that diverge across views.

5. **The Scenario 3 Prioritization Claim**: We should act more on the assumption of broad convergence (scenario 3) than near-zero convergence (scenario 1) because actions are higher-impact in scenario 3.

## Dependencies
```
Thesis
├── Path A (WAM-convergence) → Unlikely
│   ├── Claim 1 (Underpowering)
│   └── Claim 4 (Instrumental Agreement Breakdown)
├── Path B (Trade/Compromise) → More plausible but fragile
│   ├── Claim 2 (Trade Sufficiency)
│   └── Claim 3 (Threat Vulnerability) [undermines Claim 2]
└── Practical Implication
    └── Claim 5 (Scenario 3 Prioritization)
```

## Hidden load
- That "the correct moral view" is a coherent concept that can be meaningfully discussed across meta-ethical positions
- That resource control at the time of bargaining will be sufficiently distributed for trade dynamics to matter
- That the "free parameters" in ethics are genuinely independent rather than constrained by deeper structural features
- That the transition period to post-AGI will preserve the pluralism required for trade scenarios

---

## Claim 1: "Shared human preferences are underpowered for the task of ensuring that the idealising process of different humans goes to the same place"

### Critique 1: Countermodel
**The problem**: The paper assumes reflective processes are like random walks that diverge from shared origins. But consider a countermodel: moral reflection could be like gradient descent on a shared loss landscape with multiple local minima but one dominant global attractor. Different starting points might traverse different paths but still converge on a small set of stable equilibria because the structure of practical reason itself (consistency requirements, universalizability pressures, coherence with empirical facts about welfare) constrains the space. The paper treats "free parameters" as independently variable, but if they're correlated through deeper structural constraints, convergence could occur despite apparent underdetermination.

**Author's best reply**: Even if there are structural constraints, the paper's examples (hedonism vs. preference satisfaction, computational theories of which experiences are best) show that multiple stable equilibria exist, and there's no reason to think they collapse to one.

**Rebuttal**: The reply assumes we can distinguish "multiple stable equilibria" from "one equilibrium with measurement error." If beings with radically different starting points (aliens, AIs) would converge to the same small cluster, that's evidence for a dominant attractor. The paper dismisses this possibility without engaging with why consistency/universalizability pressures might be more constraining than assumed—particularly given that mathematical and logical truths do show such convergence across minds.

**If true, what changes**: The pessimism about WAM-convergence would need substantial revision; the paper's probability estimates (5-10% Flourishing) could be significantly too low.

### Critique 2: Parameter sensitivity
**The problem**: The paper treats "amount of reflection" as a parameter that increases divergence (the random walk diagram). But the relationship between reflection depth and divergence is not monotonic. At shallow depths, views diverge as people explore different directions. At intermediate depths, divergence may peak. At very deep depths, convergence might re-emerge as views that can't withstand scrutiny are eliminated. The paper implicitly assumes we're in the "more reflection → more divergence" regime, but post-AGI reflection could push us past a critical threshold into a convergence regime.

**Author's best reply**: This is speculative—we have no evidence of such a convergence regime, and the paper's point about "free parameters" suggests divergence continues indefinitely.

**Rebuttal**: The paper's own argument about superintelligent reflection (section 2.3.1) acknowledges that AI might "settle stubborn puzzles of ethics." If that's possible, it implies there are answers to converge toward. The paper wants to maintain that reflection helps clarify empirical disagreements but not fundamental moral ones, but this distinction may not survive at sufficient reflection depth—many apparently "fundamental" disagreements may dissolve under sufficient scrutiny.

**If true, what changes**: The paper's core pessimism about convergence rests on an empirical claim about the shape of the reflection-divergence function that could be wrong in the regime that matters most.

---

## Claim 2: "Two views can be 'resource-compatible,' meaning there is some way to almost fully satisfy both views with the same resources"

### Critique 1: Equilibrium shift
**The problem**: The paper's trade analysis assumes static preferences. But if groups know trade will occur, they have strategic incentives to *modify their stated preferences* to capture more gains from trade. A group that genuinely values hybrid goods has less bargaining power than one that credibly commits to valuing only highly specific goods. Over time, selection pressure favors groups that adopt (or genuinely develop) less resource-compatible preferences, precisely because such preferences extract more in bargaining. The equilibrium isn't "everyone trades to mutual benefit" but "preferences evolve toward mutual incompatibility."

**Author's best reply**: The paper discusses threats as a separate problem; strategic preference modification is just a form of implicit threat.

**Rebuttal**: This is categorically different from threats. Threats involve credible commitments to destroy value. Strategic preference evolution involves genuinely coming to value different things. A group that evolves to genuinely value "owning more galaxies than rivals" isn't threatening anyone—they just have preferences that make trade less beneficial. The paper's framework doesn't address how the *existence* of trade opportunities shapes preference evolution.

**If true, what changes**: The optimistic trade scenarios become unstable equilibria; the very possibility of trade creates selection pressure toward preferences that undermine trade's benefits.

### Critique 2: Quantitative cliff
**The problem**: The paper's trade analysis works when there are many groups with diverse preferences and continuous resource divisibility. But there may be critical thresholds—"quantitative cliffs"—where trade breaks down. For instance, if achieving a hedonist utopia requires controlling a minimum viable population of 10^15 minds to create the right social structures, and total resources only support 10^16 minds, then there's no room for multiple groups to each achieve their near-best outcomes. The paper assumes cosmic-scale resources make everyone's near-best achievable, but many moral views might have minimum scale requirements that create zero-sum competition.

**Author's best reply**: Cosmic resources are so vast that minimum scale requirements are unlikely to bind for most views.

**Rebuttal**: The paper itself argues that the "correct" view likely involves very specific, hard-to-achieve configurations. If the best outcomes require particular *relational* properties (e.g., certain ratios between different types of beings, specific network structures), then resource abundance doesn't help—you can't parallelize your way to the right configuration. The paper's optimism about trade assumes value is approximately separable across resource allocations, which contradicts its pessimism about the narrowness of good futures.

**If true, what changes**: The trade-based path to mostly-great futures fails even without threats, because minimum viable scale requirements create genuine resource competition.

---

## Claim 3: "Even small risks of executed threats can easily eat into the expected value of worlds where many groups with different values are able to bargain"

### Critique 1: Causal reversal
**The problem**: The paper treats threat vulnerability as an argument for pessimism about trade scenarios. But the same evidence supports an opposite conclusion: *threat vulnerability is an argument for convergence*. If groups recognize that trade scenarios are fragile to threats, they have strong incentives to converge on shared enforcement mechanisms, which requires converging on shared principles of legitimacy, which pulls toward moral convergence. The very fragility the paper identifies creates pressure toward the convergence it claims is unlikely. Historical examples (Westphalian sovereignty, nuclear deterrence norms) show that threat vulnerability can drive normative convergence.

**Author's best reply**: Such convergence would be on *procedural* norms (how to prevent threats), not *substantive* moral views (what futures are good).

**Rebuttal**: The distinction collapses under pressure. Agreeing on what counts as an illegitimate threat requires agreeing on what counts as legitimate value-creation, which requires substantive moral views. A norm against "value-destroying threats" presupposes agreement on what counts as value destruction. The paper can't have both: if views are so divergent that trade is the only path, they're too divergent to agree on threat-prevention; if they can agree on threat-prevention, they're convergent enough to make WAM-convergence more plausible.

**If true, what changes**: Threat vulnerability becomes evidence for convergence rather than against trade scenarios; the paper's two main paths (convergence vs. trade) are more interdependent than presented.

### Critique 2: Reference class failure
**The problem**: The paper's threat analysis implicitly draws on reference classes from human history (extortion, coercion, warfare). But post-AGI threat dynamics may be categorically different. In human contexts, threats work because (a) the threatener can benefit from executing the threat (reputation, deterrence), and (b) the threatened party can't verify the threatener's commitment type. With superintelligent transparency and credible commitment mechanisms, threats might become nearly impossible to make credibly—a threatener who would actually execute a value-destroying threat is one whose commitment can be verified and preemptively neutralized. The paper's pessimism assumes human-like strategic dynamics persist.

**Author's best reply**: The paper acknowledges superintelligent commitment mechanisms but notes these could enable threats as well as prevent them.

**Rebuttal**: This is symmetric only if we ignore the asymmetry between value creation and destruction. A world optimizing for mutual benefit has strong incentives to develop and deploy threat-prevention mechanisms; a world of mutual threats has coordination problems that prevent stable threat-making. The equilibrium isn't "threats enabled by commitment mechanisms" but "commitment mechanisms used to credibly commit to threat-prevention coalitions." The paper's reference class (human strategic interaction) doesn't transfer to the post-AGI regime.

**If true, what changes**: The threat vulnerability concern, which drives much of the paper's pessimism about trade scenarios, may be an artifact of projecting human-era dynamics onto a categorically different strategic environment.

---

## Claim 4: "This agreement will likely break down in the future, as we max out on instrumentally valuable goods and instead turn to providing intrinsically valuable goods"

### Critique 1: Countermodel
**The problem**: The paper assumes a sequential model: first we achieve instrumental goods, then we turn to intrinsic goods where we diverge. But consider an alternative: the *process* of pursuing instrumental goods shapes preferences toward convergence. A civilization that has cooperated for millennia on instrumental goods develops shared institutions, shared concepts, and shared habits of mind that constrain the space of intrinsic goods that seem appealing. The paper treats preferences as exogenous to the cooperation process, but preferences are endogenous to institutional history. By the time we "max out" on instrumental goods, we may have converged on intrinsic goods too.

**Author's best reply**: Section 2.2.1 addresses this—conformity pressure explains current agreement but doesn't guarantee convergence on correct views.

**Rebuttal**: The paper conflates two distinct claims: (1) conformity pressure causes agreement, and (2) conformity pressure doesn't track truth. Claim (2) doesn't follow from (1). If the *reasons* for conformity pressure include functional benefits of coordination, and if correct moral views have functional benefits (e.g., they're more stable, more conducive to cooperation), then conformity pressure could track truth. The paper needs to argue not just that agreement is explained by conformity, but that conformity is orthogonal to correctness—which it doesn't establish.

**If true, what changes**: The pessimistic trajectory (agreement now → divergence later) could be reversed; the very processes that created current agreement could deepen it.

### Critique 2: Parameter sensitivity
**The problem**: The paper's "fork in the future" argument assumes that at some point, views will "run out of points of agreement." But the timing of this fork matters enormously. If the fork occurs after lock-in events (discussed in section 2.5), then the divergence is moot—the future is already determined. If the fork occurs before any lock-in, then the paper's analysis applies. The paper treats the relationship between fork-timing and lock-in timing as a free parameter, but they may be coupled: the same conditions that enable lock-in (concentration of power, decisive technological advantages) may also prevent the fork from ever being reached.

**Author's best reply**: The next essay addresses lock-in; this essay focuses on convergence conditional on avoiding lock-in.

**Rebuttal**: The conditional analysis is misleading if the conditioning event (avoiding lock-in) is correlated with the outcome (convergence). If worlds that avoid lock-in are systematically different in ways that also promote convergence (e.g., they have better institutions, more distributed power, more time for reflection), then the paper's pessimism about convergence-conditional-on-no-lock-in could be wrong. The paper can't cleanly separate these questions.

**If true, what changes**: The paper's structure (this essay on convergence, next essay on lock-in) may create artificial separation that obscures important dependencies.

---

## Claim 5: "The best actions are higher-impact in scenario (3) than in scenario (1)"

### Critique 1: Parameter sensitivity
**The problem**: The paper's calculation assumes you can "increase the chance of Surviving by more than one part in a hundred thousand, or improve Flourishing by more than one part in a million" through non-power-seeking actions in scenario 3. But this estimate is doing enormous work without justification. In scenario 3, if convergence is likely anyway, then marginal actions have *less* impact (you're pushing on an open door). The paper assumes your actions are counterfactually pivotal in scenario 3 but not in scenario 1, but this asymmetry isn't argued for—it's assumed.

**Author's best reply**: In scenario 3, there's more total value at stake, so even small proportional improvements are absolutely larger.

**Rebuttal**: This reply assumes proportional impact is comparable across scenarios. But if scenario 3 involves robust convergence, your marginal contribution to that convergence is small (many others would have done it). If scenario 1 involves near-zero convergence, your power-seeking might be the *only* path to value. The paper compares "small proportional impact on large value" to "large proportional impact on small value" without establishing that the former dominates.

**If true, what changes**: The practical conclusion (don't power-seek, work on scenario 3) may not follow from the analysis; the paper's action-guidance depends on undefended assumptions about counterfactual impact.

### Critique 2: Causal reversal
**The problem**: The paper argues we should act on scenario 3 because actions are higher-impact there. But the same reasoning could justify acting on scenario 1: *because* scenario 1 is lower-probability and lower-value, it's more neglected, and marginal resources there might have higher impact. The paper's logic (act where impact is highest) doesn't uniquely select scenario 3 over scenario 1—it depends on the shape of the impact-per-resource curve in each scenario, which the paper doesn't establish.

**Author's best reply**: Scenario 1 has genuinely lower stakes (Will's preferences are less scope-sensitive there), so even high-impact actions matter less.

**Rebuttal**: This moves from "higher impact" to "higher stakes," which is a different argument. If the argument is about stakes (what you care about), then it's not about impact (what you can change). The paper conflates these, using impact language to argue for a conclusion that actually depends on stakes. Someone with different meta-preferences (e.g., who cares equally about all scenarios) would get different action-guidance from the same analysis.

**If true, what changes**: The paper's practical conclusion is less robust than presented; it depends on specific meta-preferences that aren't universally