# Black Swan Review: "Convergence and Compromise: Will Society Aim for Good Futures?"

---

> **Candidate Objection #1**
>
> **The "Kill Shot" Headline:** The paper's entire framework requires a God's-eye view of "the good" that, by its own anti-realist arguments, cannot exist—making "mostly-great future" a phrase with no referent.
>
> **The Deep Structure:** The paper oscillates fatally between two incompatible positions. It spends section 2.4.2 arguing persuasively that under moral anti-realism, there are no objective facts about which futures are "mostly-great"—different idealizing processes from different starting points yield irreconcilably different endpoints, and "shared human preferences are extremely underpowered for this task." Yet the entire paper presupposes we can meaningfully calculate that "Flourishing" is at "5%-10%" of some maximum, that certain futures capture "most achievable value," and that we can identify "the correct moral view." 

> If anti-realism is true (which the authors seem to find plausible), then "mostly-great future" is not a narrow target—it is no target at all. There is no fact of the matter about whether the future achieves 5% or 95% of "possible value." The paper's quantitative framing (percentages, "narrow targets," "most value") imports precisely the moral realism it elsewhere undermines. This isn't a tension to be managed; it's a contradiction that vaporizes the paper's central question.
>
> **Why this is Unsettling:** The paper cannot be "fixed" by picking a side. If the authors commit to realism, they lose their best arguments against WAM-convergence (section 2.4.2 collapses). If they commit to anti-realism, their entire evaluative framework—the thing that makes this a paper about "better futures" rather than "different futures"—becomes incoherent. The paper is load-bearing on a metaphysical fence it cannot sit on.
>
> **The Steelmanned Defense:** The authors might claim they're offering a *conditional* analysis: "If there is a correct moral view, here's what follows." They explicitly note uncertainty across meta-ethical positions.
>
> **Why the Defense Fails:** The paper doesn't read as conditional. It makes unconditional claims about expected value ("5%-10%"), offers recommendations, and treats "mostly-great" as if it picks out a real property of futures. More damningly, the conditional defense proves too much: under anti-realism, the entire research program of "better futures" reduces to "futures I happen to prefer," which is just politics dressed in philosophical clothing. The authors cannot simultaneously claim uncertainty about meta-ethics *and* assign numerical probabilities to value capture without smuggling in realism through the back door.

---

> **Candidate Objection #2**
>
> **The "Kill Shot" Headline:** The paper's "narrow target" premise makes trade and compromise *worse* than useless—it guarantees mutual destruction of value across all parties.
>
> **The Deep Structure:** The paper argues (a) mostly-great futures are narrow targets where small deviations destroy most value, and (b) trade and compromise between different moral views can help us reach mostly-great futures. These claims are in direct tension. 

> Follow the logic exactly: If View A's eutopia requires parameters set to [X₁, X₂, X₃...] within tight tolerances, and View B's eutopia requires [Y₁, Y₂, Y₃...] within equally tight tolerances, then any compromise that moves away from either set of parameters destroys most value *for both parties*. The paper's own "narrow target" framing means the space of acceptable compromises is the *intersection* of two already-tiny regions—which, for genuinely different views, is essentially empty.

> The paper gestures at "hybrid goods" and "resource-compatible" views, but this is wishful thinking dressed as analysis. If hedonism requires maximizing a specific computational structure for bliss, and objective-list theory requires a different structure for wisdom, then a "being that is both blissful and wise" is not a compromise—it's a third thing that likely fails to hit *either* narrow target. The authors even admit this: "the ways to achieve maximum value/cost on each view are both highly particular, then it's unlikely any compromise could achieve much more value (by the lights of each view) than if each view kept their resources for themselves."
>
> **Why this is Unsettling:** This is a *perverse instantiation* of the paper's own framework. The more seriously you take "no easy eutopia," the more trade and compromise become mechanisms for *mutual value destruction* rather than value creation. The paper's optimistic section 3 is not merely unconvincing—it is actively contradicted by the paper's foundational premise. The authors have built a philosophical mousetrap and walked into it.
>
> **The Steelmanned Defense:** Perhaps some views are genuinely resource-compatible, and we should focus on those cases. The paper explicitly discusses bounded vs. unbounded views and notes that easily-satiable views can be accommodated cheaply.
>
> **Why the Defense Fails:** The defense only works if the "correct" view happens to be easily-satiable or resource-compatible with dominant views—a cosmic coincidence the paper gives us no reason to expect. For unbounded, linear views (which the authors treat as plausible candidates for correctness), the defense evaporates entirely. The paper is left hoping that the correct moral view is conveniently the kind that can be satisfied with table scraps from cosmic negotiations. This is not an argument; it is a prayer.

---

> **Candidate Objection #3**
>
> **The "Kill Shot" Headline:** "Convergence" is doing no work—the paper's actual mechanism is *domination by whichever values happen to control resources at the critical juncture*.
>
> **The Deep Structure:** Strip away the philosophical apparatus and examine what the paper actually describes. Section 2.3.3 ("Long views win") argues that patient, non-discounting values will accumulate resources over time. Section 3 argues that trade outcomes depend on initial resource distribution and bargaining position. Section 3.5 acknowledges that "concentration of power" is a key blocker. 

> The paper's own analysis reveals that "convergence" is epiphenomenal. What determines the future is not whether views *converge* but whether the views that happen to control resources at the moment of lock-in are correct. The paper even states this: "the outcome of any bargaining process depends sensitively on the power distribution among the different bargainers, and on what would happen if no agreement occurs."

> This means the paper's central question—"Will society aim for good futures?"—is a distraction. The real question is: "Will the entities that control resources at the critical moment happen to have good values?" And the paper provides no mechanism whatsoever for why this should be true. "Convergence" sounds like a process that tracks truth; what the paper actually describes is a power struggle where correctness is orthogonal to victory.
>
> **Why this is Unsettling:** The paper presents itself as analyzing whether humanity will *aim* at good futures, implying agency and deliberation. But its own analysis shows that the outcome is determined by path-dependent resource accumulation and lock-in dynamics that have nothing to do with moral reasoning. The philosophical veneer of "convergence" and "trade" obscures what is actually a brute political claim: whoever wins, wins. The paper's optimism reduces to hoping the right side wins the resource race—which is not philosophy but fortune-telling.
>
> **The Steelmanned Defense:** The paper acknowledges these dynamics and treats them as "blockers" to be overcome. The point of the analysis is to identify conditions under which good outcomes are possible, not to claim they are guaranteed.
>
> **Why the Defense Fails:** If the outcome is determined by power dynamics rather than convergence, then "blockers" aren't obstacles to the paper's mechanism—they *are* the mechanism. The paper has no theory of why correct moral views would be systematically advantaged in resource competition. Section 2.3.3's argument that "non-discounting values win" applies equally to patient nihilists, patient hedonists, and patient paperclip maximizers. The paper's framework cannot distinguish between "convergence toward the good" and "domination by whatever patient values happen to exist." This isn't a gap in the argument; it's the absence of an argument.