## Critique of "Convergence and Compromise: Will Society Aim for Good Futures?"

---

**1) Unforgettable criterion chosen:** Self-Undermining Move

**2) Main conclusion (1 sentence):** The paper argues that a mostly-great future remains achievable despite "no easy eutopia" because either widespread moral convergence or partial convergence plus trade/compromise can steer humanity toward the narrow target of optimal outcomes.

**3) Load-bearing hinge (A→B because M):** If partial AM-convergence occurs and trade/compromise mechanisms function, then a mostly-great future becomes achievable, because trade allows those with correct moral views to acquire disproportionate resources relative to their population share (the "Julius Caesar coin collector" mechanism).

**4) Three candidate killer objections:**

**Candidate 1: "The Reflection Defeater"**
- **Target hinge:** Section 2.4's argument that antirealism makes convergence unlikely because subjective idealizing processes diverge
- **One-liner:** The paper's own argument for why reflection won't produce convergence undermines its optimism about "partial AM-convergence" among altruists
- **Mechanism:** If idealizing processes are subjective and diverge even among humans with similar starting points (the random walk diagram), then the subset of "altruistically-minded" people should *also* diverge upon reflection, making even partial AM-convergence implausible
- **Blast radius:** Destroys Section 3's entire trade/compromise framework; undermines the 5-10% Flourishing estimate

**Candidate 2: "The Trade Paradox"**
- **Target hinge:** Section 3.2's claim that non-discounting linear views might control resources through trade
- **One-liner:** The very properties that make a moral view correct (non-discounting, linear-in-resources) are the properties that make it worst-positioned for gains from trade with other such views
- **Mechanism:** The paper admits (3.2) that "resource-compatibility between linear views seems unlikely"; but if the correct view is linear, and selection pressures favor linear views (2.3.3), then the trading environment will be dominated by incompatible linear views, eliminating the trade advantage
- **Blast radius:** Undercuts the main optimistic pathway; makes Section 3.4's analysis self-defeating for the most plausible correct views

**Candidate 3: "The Convergence Confidence Trap"**
- **Target hinge:** Section 5's argument that scenario (3) deserves more decision-weight than scenario (1)
- **One-liner:** The paper's own arguments make scenario (3) less likely, yet it recommends acting as if (3) is true precisely *because* (3) would make actions more impactful—a form of motivated reasoning that the paper's meta-ethical discussion should have inoculated against
- **Mechanism:** The paper argues (2.4) that convergence is unlikely on both realism and antirealism; then argues (5) we should weight scenario (3) heavily because it's "higher-stakes"; but this reasoning pattern—believing what's convenient because it's motivating—is structurally identical to the internalism problem the paper identifies (2.4.1) where people avoid learning demotivating truths
- **Blast radius:** Undermines the paper's practical recommendations; reveals tension between its epistemology and its decision theory

---

**5) Chosen objection name + one-liner:** 

**"The Altruist Divergence Trap"**

The paper's own argument for why reflection produces divergence applies with equal force to the altruistically-minded subset it relies upon for partial AM-convergence, making the trade pathway self-undermining.

---

**6) Full unpacking:**

**Mechanism (numbered steps):**

1. The paper argues (Section 2.4.2) that under antirealism, subjective idealizing processes will diverge because there are "free parameters" in ethics—precise specifications of welfare, tradeoffs between goods, mathematical forms of value functions—and no objective process to resolve them.

2. The paper illustrates this with the random walk diagram: people starting close together will end up far apart after extensive reflection, because "slight differences in their orientation would lead them to end up very far apart."

3. The paper then pivots (Section 3) to argue that "partial AM-convergence" among a meaningful minority (not less than 1 in a million) could still enable a mostly-great future through trade.

4. But this minority must converge on *the same* correct moral view to trade effectively for it. The paper's own logic dictates they won't: the altruistically-minded are precisely those most likely to engage in extensive moral reflection, and extensive reflection produces divergence.

5. The paper even notes (Section 2.2.1) that "with advanced technology, this issue will get even more extreme" because people will "rely on different types of superintelligent AI advisors, trained in different ways." Altruists selecting different AI advisors will diverge faster, not slower.

6. Therefore, the "meaningful fraction" who might have AM-converged will instead fragment into many micro-factions, each holding slightly different linear-in-resources views that are (by the paper's own admission in 3.2) "unlikely" to be resource-compatible with each other.

7. The trade mechanism requires the correct-view-holders to act as a unified bloc with aligned interests. The divergence argument ensures they cannot.

**Blast radius:**

- **Section 3.1-3.2:** The entire trade framework assumes a coherent "correct view" faction exists to trade. If altruists diverge, there is no such faction.
- **Section 3.4's optimistic cases:** All require "the correct view" to control meaningful resources. But which sub-faction of diverged altruists holds "the" correct view?
- **Section 5's decision-weighting:** The argument for focusing on scenario (3) assumes partial AM-convergence is achievable. If altruists diverge, scenario (3) collapses into scenario (1).
- **The 5-10% Flourishing estimate:** This revision from <1% was based on "being exposed to some of the arguments in this essay." But if the core argument self-undermines, the revision is unjustified.

---

**7) Author's best reply → rebuttal:**

**Author's Best Reply (steelman):**

"The divergence argument applies to *fundamental* ethical views, but altruists might converge on *practical* priorities even while diverging on foundations. Just as different ethical theories agree on 'low-hanging fruit' improvements today, altruists might agree on which futures are clearly catastrophic versus clearly excellent, even if they disagree on fine-grained optimization. The trade mechanism doesn't require perfect convergence—just enough agreement to form coalitions against clearly-worse outcomes. Moreover, we explicitly note (Section 2.2.1) that agreement breaks down 'as we max out on instrumentally valuable goods.' But the trade scenario operates before that point, when altruists can still coordinate on preventing catastrophes even if they'd diverge on final optimization."

**Rebuttal:**

This reply concedes too much. The paper's own framing is that "mostly-great" means capturing most achievable value, not merely avoiding catastrophe. The paper explicitly argues (Section 2.2.1) that "getting lots of agreement isn't enough; the remaining disagreements would likely be enough to ensure that each other's eutopia involves losing most value from the other's point of view." If altruists can only coordinate on catastrophe-prevention but diverge on optimization, then the trade mechanism delivers *survival*, not *flourishing*. The paper would need to abandon its central claim that Flourishing has "notably greater scale" than Surviving, or admit that trade cannot deliver the Flourishing premium.

Furthermore, the "before max-out" timing is unavailable. The paper argues (2.3.3) that "long views win" through asymmetric growth, meaning non-discounting views will eventually dominate. But the divergence happens *during* reflection, which precedes resource accumulation. By the time altruists have resources to trade, they've already diverged through the very reflection that made them altruistic.

---

**8) Repair menu (3 options):**

**1) Minimal patch:** Add an explicit argument for why altruists specifically would converge more than the general population, despite engaging in more reflection. This would require identifying some convergence-forcing mechanism that operates *only* on altruistic reflection—perhaps that altruists are more likely to weight theoretical virtues like simplicity, or more likely to defer to each other's reasoning. The paper currently gestures at "shared human preferences" but admits these are "underpowered."

**2) Honest concession:** Weaken the claim about partial AM-convergence enabling a mostly-great future. Acknowledge that trade among diverged altruists might achieve a future that's *better than average* but not *mostly-great*. This would require revising the Flourishing estimate downward and admitting that the scale advantage of Flourishing over Surviving is smaller than claimed. The paper could still argue for working on better futures, just with reduced expected impact.

**3) Rebuild:** Abandon the convergence-plus-trade pathway and instead argue for *institutional* solutions that don't require value convergence. For instance: design collective decision-making procedures that aggregate divergent altruistic preferences into good outcomes (mentioned briefly in 3.5 but underdeveloped), or argue for meta-level convergence on *procedures* rather than *values*. This would shift the paper's focus from "will people aim at the good?" to "can we design systems that produce good outcomes from diverse aims?"—a more tractable question that doesn't self-undermine.