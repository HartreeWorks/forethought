**Load-bearing claim:**
That "shared human preferences" are underpowered to ensure convergence across different idealizing processes (supports Claim 1)

**Attack type:**
Parameter sensitivity

The paper treats the specificity required for convergence as fixed at "astronomical haystack" levels, but this parameter depends entirely on the (undefended) assumption that mostly-great futures require agreement on every free parameter in ethics. However, if value is "chunky" rather than continuous—if there are discrete attractor basins where many different parameter settings yield similarly high value—then the required precision drops dramatically. The paper cites hedonism versus preference-satisfaction as diverging under optimization, but never establishes that intermediate hybrid states (beings with meaningful preferences who also experience substantial pleasure) don't capture most value on both views. If value landscapes are chunky, the convergence problem becomes tractable even under antirealism.
