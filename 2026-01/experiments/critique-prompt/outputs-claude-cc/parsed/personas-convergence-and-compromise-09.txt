The paper's section 2.3.1 assumes that access to superintelligent reflection would help people converge on accurate moral views, but this fundamentally misunderstands how human moral cognition works. Moral judgments are not conclusions derived from reflection but post-hoc rationalizations of intuitions generated by evolutionarily ancient neural systems. Providing people with better arguments doesn't change their intuitions; it provides them with more sophisticated rationalizations for whatever they already believed. The paper's own observation that people "strongly dislike the suggestions of their more-reflective selves" points toward this, but fails to draw the obvious conclusion: superintelligent moral advisors will be used to generate more compelling justifications for existing preferences, not to change those preferences. The entire convergence-through-reflection framework assumes a model of moral cognition that decades of empirical research has falsified.