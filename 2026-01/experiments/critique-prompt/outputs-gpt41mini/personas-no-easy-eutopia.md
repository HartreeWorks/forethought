1. [The Empirical Hardliner] The paper claims that the value of the future can be modeled as a multiplicative product of many relatively independent factors (Section 2.4), leading to “eutopian fragility.” However, this claim lacks identification of specific causal mechanisms that ensure factor independence or uniform distributions, and it offers no falsifiable predictions. Without empirical evidence or a formal causal framework, this multiplicative model could be an oversimplified statistical artifact rather than a real structural property of moral value dynamics. Consequently, if the independence assumption fails, the paper’s quantitative conclusions about narrow “mostly-great” futures lose all empirical grounding, rendering its core argument speculative and unfalsifiable.

2. [The Game-Theoretic Defector] The paper assumes that society can (or must) coordinate to “aim” at the narrow eutopian target, but neglects incentive gradients that enable actors to deviate. In particular, the discussion of digital beings’ rights and resource allocation (Section 2.3.2 and 2.3.4) ignores how powerful actors will defect by hoarding resources or exploiting digital slaves to maximize short-term gain. This incentive-driven cheating will systematically shift outcomes away from the narrow “mostly-great” set toward more exploitative equilibria, undermining the paper’s implicit assumption that the narrow target can be stably reached. Thus, the fragility described might be less about moral complexity and more about unmanageable strategic incentives leading to persistent moral catastrophe.

3. [The Mechanism Designer] Throughout Sections 2 and 3, the paper relies heavily on qualitative moral reasoning and informal probabilistic statements (e.g., “value-efficiency distributions are fat-tailed”). Without formalizing these claims into explicit mathematical or computational models—i.e., no formal specifications, code, or algorithms—the arguments remain unverifiable and non-reproducible. This lack of formal rigor means we cannot systematically explore failure modes, counterexamples, or boundary cases. Consequently, the paper’s claims about “fussiness” and narrow targets are impressionistic and thus unable to serve as a foundation for mechanism design or robust policy interventions aiming to actually steer future outcomes.

4. [The Institutional Corruptionist] The paper assumes that future societies could converge on correct moral views or engage in rational deliberation to hit the eutopian target (Section 4), but this neglects pervasive principal-agent problems and regulatory capture. Political and social institutions are prone to compliance theater, entrench self-interested elites, and resist genuinely transformative change. Hence, even if ideal moral views exist, institutions will likely subvert or hollow them out, ensuring persistent moral catastrophe. The result is that the “no easy eutopia” view underestimates the extent to which institutional pathologies systematically prevent the narrow target from ever being reached, rendering the essay’s optimism about convergence naïve.

5. [The Capability Accelerationist] The paper accepts the premise that social and technological progress could enable reaching eutopia but ignores how arbitrary safety or moral “checks” that slow capability growth only serve to redistribute who reaches advanced futures first. In Section 2.3.4, the discussion of star system colonization misses that attempts to moralize early resource grabs will cause races and arms races accelerating expansion without ethical safeguards. Since capabilities are treated as exogenous and safety as an add-on, the paper’s inference that moral catastrophes can be avoided by aiming better is flawed; instead, accelerating actors will jump ahead, leading to worse outcomes regardless of moral “fussiness.”

6. [The Second-Order Catastrophist] If the paper’s “no easy eutopia” proposal succeeds—society narrows its aim to avoid moral errors and hits the eutopian target—this will compress moral diversity and experimentation, potentially causing brittle social systems with fragile homogeneity. Such homogeneity may cause systemic vulnerabilities—from loss of genetic, cultural, or epistemic diversity—triggering catastrophic collapses if unforeseen shocks arise. Thus, the proposal’s success paradoxically elevates the risk of second-order catastrophes, undermining the assumed long-term gain from focusing narrowly on “mostly-great” futures.

7. [The Adversarial Red-Teamer] The argument that a mostly-great future requires near-perfect moral decisions across many dimensions (2.4–2.5) overlooks the inevitability that sophisticated adversaries—whether malicious AIs, state actors, or ideological minorities—will exploit any moral or institutional gap. These adversaries will intentionally inject moral error or sabotage consensus to gain advantage, making the eutopian target not just narrow but actively targeted for disruption. Hence, the paper’s narrow target is not merely hard to hit by accident, but infeasible under persistent adversarial attack, threatening failure modes unseen by the authors.

8. [The Moral Parliament Dissenter] The paper’s framing of value aggregation (Section 3) assumes the existence of a single, consistent betterness relation and uses cardinal expected utility axioms that implicitly privilege consequentialist aggregation of goods and bads. This excludes pluralist, incommensurable, or kantian value frameworks that reject full comparability and numerical aggregation. Because many credible moral systems resist these assumptions, all conclusions about “fussy” versus “easygoing” views rely on a biased ethical framework that marginalizes legitimate dissent. Thus, the paper fails to anticipate objections from essential complexity in ethical value pluralism.

9. [The Historical Parallelist] The paper’s optimism about potential convergence on correct moral views or stable compromise (Section 4) overlooks countless historical analogies where seemingly stable moral or political orders crumbled or ossified amid narrow ideals. For instance, religious schisms, revolutions, and regime collapses repeatedly invalidated claims of near-best moral orders. The historical record suggests that attempts to “aim” at a singular narrow moral future tend to provoke conflict, factionalism, or innovation instability, indicating the “no easy eutopia” is not just difficult but likely systematically unattainable due to recurring cycles of moral failure absent unprecedented institutional reinvention.

10. [The Complexity Theorist] The paper models future value as a product of independent factors and analyzes boundedness of value functions assuming structured aggregation (Section 2.4 and Section 3), but it neglects the emergent, nonlinear interactions between social, technological, ecological, and moral factors. Complex adaptive systems theory shows that interactions can generate unforeseen feedback loops, tipping points, and path dependencies that invalidate multiplicative or linear assumptions. Consequently, the “fussy” target sets may not even be well-defined attractors in the complex system of the future, making the entire analytic framework overly simplistic and unable to capture true dynamics of value emergence or collapse.