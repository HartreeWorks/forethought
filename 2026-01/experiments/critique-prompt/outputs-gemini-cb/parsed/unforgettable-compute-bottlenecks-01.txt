**"The Phase Transition Blindspot"**
The paper argues that AI R&D can be accelerated by replacing massive compute runs with many "smaller scale experiments" extrapolated to larger models. This infers that algorithmic insights scale linearly or predictably from small to large models. However, the defining characteristic of recent AI progress (e.g., grokking, in-context learning) is that capabilities are emergent and discontinuousâ€”they only appear *after* a specific scale threshold. If the most valuable algorithmic breakthroughs only manifest at scale, you cannot find them with small experiments, no matter how many superintelligent researchers you have. The substitute for compute is not "more small experiments," but "predictive theory," and if the domain is chaotic or emergent, that theory is computationally irreducible.