**"The Inference-Training Blur"**
The paper draws a sharp line between "Cognitive Labor" (inference) and "Compute" (training capital). But during an SIE, "thinking harder" (Chain of Thought, search, scaffolding) effectively turns inference into a compute-heavy process. If the "smart researcher" needs to run a massive tree-search to solve a coding problem, the "labor" input itself becomes compute-bound. The paper argues we can trade compute for labor, but if high-quality labor *is* compute (in the form of massive inference costs), the substitution is illusory. You aren't escaping the compute bottleneck; you are just moving it from the training cluster to the inference cluster.