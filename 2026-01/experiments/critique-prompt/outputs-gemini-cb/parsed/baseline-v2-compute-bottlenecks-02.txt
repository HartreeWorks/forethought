"Resource Contention Between Inference and Training" â€” The argument posits that an abundance of "software intelligence" (AI researchers) can optimize R&D, yet it treats these digital workers as distinct from the compute constraint ($K$). In a fixed-hardware scenario, the AI researchers themselves require significant compute for inference ("thinking") to generate ideas or write code. Therefore, $L$ and $K$ are not independent inputs; increasing the "cognitive labor" ($L$) necessarily cannibalizes the available compute ($K$) for experimental training runs. This internal competition for the bottlenecked resource suggests the ceiling for progress may be much lower than the paper anticipates.