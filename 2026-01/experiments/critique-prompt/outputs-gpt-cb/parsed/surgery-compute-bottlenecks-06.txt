> Even trillions of AI researchers might not speed things up much if the real bottleneck is compute-hungry evaluation of rare, brittle improvements rather than generating ideas.

The paper argues that economic ρ values imply “implausibly low” max speeds (e.g., <10×), and uses that implausibility to push ρ into −0.2<ρ<0. **Countermodel:** suppose AI R&D has a heavy-tailed idea distribution where most candidate improvements are worthless, and the binding resource is not coding time but evaluating rare, brittle gains across many tasks and safety-critical edge cases—evaluation that is itself compute-hungry and hard to shortcut. Then even “trillions of superintelligent researchers” don’t yield big speedups because the pipeline is dominated by high-fidelity training/eval cycles, not human-style brainstorming. If this critique holds, “low max speed” stops being implausible, so the argument that “most economic estimates must be wrong for AI” no longer supports the conclusion.