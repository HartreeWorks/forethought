> Efficiency gains don't necessarily mean more experiments—labs tend to reinvest savings into bigger, harder-to-evaluate runs, which could actually tighten the bottleneck rather than loosening it.

**Load-bearing claim:**
“*when your AI algorithms become twice as efficient, you can run twice as many experiments… This completely pulls the rug out… which assumed an essential input was held fixed*” (Counterargument 5)

**Attack type:**
Reversal

**Break mechanism:** The same mechanism can imply the opposite dynamic: efficiency gains frequently get spent on pushing the frontier to larger models (capability-seeking labs scale up), keeping the *effective* “near-frontier experiment count” roughly constant or even *reducing* it because each run becomes longer and more complex to evaluate. In that world, algorithmic efficiency doesn’t relax the bottleneck; it intensifies complementarity by making “insight” more valuable only when paired with massive, scarce runs (ρ more negative). Your “rug pull” requires assuming labs bank efficiency as “more shots on goal” rather than reinvesting it into bigger bets. **If this holds, you’d need to model the equilibrium allocation rule for compute under competitive scaling (how efficiency translates into run size vs run count) and show conditions where run-count truly increases at the relevant margin.**
