**"Algorithmic efficiency doesn’t give ‘more experiments’; it makes each experiment more expensive in information terms."** The paper claims that because algorithms can become more compute-efficient, you can run more experiments at fixed compute, undermining the skeptic’s “compute is fixed” premise. But the quantity that matters isn’t “number of runs,” it’s the information gained per unit compute about near-frontier behavior—and as you approach the frontier, the signal-to-noise of cheap proxies typically collapses (distribution shift, emergent behaviors, scaling-law breaks). In other words, making models cheaper often forces you into smaller, less faithful regimes, and the marginal value of each added cheap experiment can fall faster than linearly, restoring a hard ceiling on *effective* experimentation even if raw run-count increases. This is a structural reversal: the very move proposed to escape compute bottlenecks (shift to smaller experiments) is exactly what makes you blind to the phenomena that determine frontier capability. If the author defends with “we can extrapolate,” they’ve exposed an unstated crux: that extrapolation remains reliable through regime changes—the one thing a compute bottleneck skeptic denies.