The post relies on the claim that “long-run estimates push ρ upward (toward Cobb–Douglas), and AGI could quickly reconfigure production so AI R&D behaves like the long run.” **Reference class failure:** the Jones-style “long run” in macro comes from *accumulating or redesigning capital* and reorganizing production, but in this paper’s SIE setting hardware compute is explicitly held fixed, and most “reconfiguration” options (bigger batch sizes, more parallelism, more elaborate evaluators, more synthetic data generation) themselves consume more compute rather than substituting it away. Treating “fast-thinking AGIs” as a substitute for the real-world time needed to build/retrofit capital conflates organizational redesign with physical capacity change. If this critique holds, the paper’s main pathway from “short-run complementarity” to “ρ≈0 quickly” is blocked, strengthening the original compute-bottleneck objection rather than weakening it.