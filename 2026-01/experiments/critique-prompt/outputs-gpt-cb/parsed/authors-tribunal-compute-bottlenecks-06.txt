**“Reconfiguration Still Costs Compute”** — The paper leans on a Jones-style story: short-run complementarity may be high, but with time (and fast AGIs) the R&D process can be reconfigured so ρ rises toward 0 quickly. The failure mechanism is that “reconfiguration” in ML R&D—new training recipes, new eval suites, new architectures, automated interpretability, robustifying pipelines—typically requires substantial iterative experimentation and validation, i.e., the very compute the bottleneck restricts. Fast thinking alone doesn’t bypass the need to run trainings, ablations, stress tests, and deployment-like evals, especially as models become more capable and safety-critical. If this holds, the paper must model the *compute cost of escaping the bottleneck*; otherwise it assumes the conclusion (high substitutability) by positing an easy transition to methods that allegedly remove complementarity.