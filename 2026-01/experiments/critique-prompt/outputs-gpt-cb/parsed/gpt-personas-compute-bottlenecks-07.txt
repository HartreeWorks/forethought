[The Moral Parliament Dissenter] **Target claim:** defining an SIE as “≥5 OOM increase in effective training compute in <1 year without needing more hardware,” then using that to discuss “AI takeover” and other harms. **Failure mechanism (normative incoherence / value aggregation contradiction):** you’re collapsing “effective training compute” into “intelligence” into “danger,” but your own list of risks (takeover, coups, dangerous tech) depends on agency, deployment, and objectives—none of which are monotonically linked to training efficiency. A world can hit your 5-OOM metric via architectural efficiency and data tricks while remaining mostly non-agentic, and a different world can get catastrophic agentic planning with far less “effective training compute” if scaffolding and tool access dominate. **Consequence:** your headline probability (10–40%) is attached to a proxy that doesn’t track the thing you’re warning about, so the paper can mislead readers into preparing for “compute-free training efficiency explosions” while missing the pathways that actually generate the catastrophic scenarios you cite.