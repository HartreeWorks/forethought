> SIE-level expectations trigger security lockdowns that destroy the broad information access automated R&D actually needs, creating a self-inflicted productivity collapse the paper never accounts for.

**“Security Clampdown Feedback”** — By arguing compute bottlenecks wouldn’t bite early and that rapid SIE-like acceleration was plausible, the paper nudged labs and states toward an assumption of imminent decisive advantage from automated R&D. That belief drove aggressive secrecy and internal security: tighter compartmentalization, air-gapped training, restricted logs, and heavy monitoring of agent activity to prevent model theft and sabotage. The mechanism that broke was that these controls sharply reduced the effective substitutability the paper relied on—agents lost access to data, tooling, and cross-team context, and humans became the slow approval chokepoints again. The cascade was self-inflicted stagnation: productivity fell, bug rates rose because fewer eyes could inspect systems, and a major breach still occurred via a supplier, after which restrictions tightened further and collapsed collaboration across the field, delaying safety standards and interoperability. The paper missed that “more cognitive labour” is only productive under broad access and information flow, but SIE expectations themselves predictably trigger security regimes that destroy that condition.