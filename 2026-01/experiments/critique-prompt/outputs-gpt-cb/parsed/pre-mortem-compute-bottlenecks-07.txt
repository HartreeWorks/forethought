> Beyond a certain scale, adding more AI research agents backfires because the coordination overhead—merge conflicts, duplicated work, chasing regressions—itself eats the scarce compute, inverting productivity gains.

**“Coordination Overhead Singularity”** — The paper’s framing implicitly treated added cognitive labour (more AGI researchers) as mostly additive and substitutable with compute, supporting very large parallel researcher counts. Labs operationalized this with massive agent swarms generating code changes, experiment specs, and literature reviews in parallel, expecting near-linear speedups until late-stage compute limits. The mechanism that broke was coordination scaling: merge conflicts, duplicated work, inconsistent assumptions, and evaluation debt grew superlinearly, and the overhead itself consumed the scarce compute slots (CI, test matrices, regression suites, safety evals). The cascade was a productivity inversion: beyond a threshold, adding agents reduced net progress because the organization spent most cycles reconciling outputs and chasing regressions; a critical training-stack bug introduced by an “approved” agent patch went unnoticed amid noise and invalidated months of results across multiple labs. The paper missed that in AI R&D the “experiment loop” includes heavy shared-state coordination, and that this coordination is itself compute- and attention-intensive in ways that CES-style smooth substitution does not capture.