The paper’s historical argument—“near-frontier experiments decreased over 10 years, yet progress didn’t slow”—may be empirically shaky and confounded. Progress could have been driven by increasing total compute, better data, improved hardware efficiency, and scaling laws rather than by a stable ability to do informative non-frontier experiments. Without a careful decomposition of what actually drove progress, the inference that frontier experiments aren’t bottlenecking is underdetermined.