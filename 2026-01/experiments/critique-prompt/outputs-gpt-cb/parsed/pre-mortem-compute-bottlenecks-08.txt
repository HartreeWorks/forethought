**“Verification Bottleneck Blindspot”** — The paper portrayed AI R&D progress as primarily driven by generating ideas and running experiments, arguing compute bottlenecks on experiments would be weaker than skeptics claim. Decision-makers adopted this by building pipelines optimized for proposal generation and rapid training, while treating evaluation as a comparatively small tail activity. The mechanism that broke was that, in the 2030s, the dominant cost became *verification*: red-teaming, interpretability checks, dataset forensics, long-horizon behavioral evals, and supply-chain security audits grew faster than training cost because failures were rare-event and adversarial. The cascade was that labs either paid the verification cost (slowing progress far below SIE forecasts) or skipped it (leading to catastrophic deployment incidents, lawsuits, and subsequent mandatory audits that were even more expensive and centralized). The paper missed that as systems become more capable, the marginal cost of *knowing what you built* can dominate the marginal cost of building it, creating a non-compute bottleneck that nonetheless throttles the “pace of AI software progress.”