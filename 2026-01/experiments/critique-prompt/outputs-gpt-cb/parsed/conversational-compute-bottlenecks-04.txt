> Efficiency gains don't loosen the compute bottleneck—labs reinvest them to push the frontier harder, so fixed hardware still caps progress regardless of algorithmic improvements.

**"Software progress can increase compute demand, not reduce it"**  
The paper emphasizes algorithmic efficiency improvements that allow more experiments at fixed compute. A strong counterpoint is that many software advances *increase* appetite for compute: longer training to squeeze out capability, more extensive RL, larger context windows, heavier test-time compute, larger synthetic-data pipelines, and more elaborate agent scaffolds. In practice, labs often reinvest efficiency gains into pushing the frontier rather than banking them as spare experimental throughput. If the competitive equilibrium is “use all available compute,” then fixed hardware still caps progress because each “step” in capability keeps expanding to fill the budget. This undermines the idea that compute efficiency automatically loosens the compute bottleneck during the key phase where you’re racing up the capability curve.