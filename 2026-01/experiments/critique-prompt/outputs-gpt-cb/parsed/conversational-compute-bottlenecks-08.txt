> The "implausibly low max speed" objection is more vibes than evidence—it never pins down what "progress" means or accounts for the fact that many proposed speedups still bottleneck on running large experiments.

**"The ‘implausibly low max speed’ claim rests on intuition, not measurement"**  
The paper argues that economic elasticities imply max speeds (e.g., 2–10×) that feel implausibly low given what abundant cognitive labor could do. But this is largely an intuition pump, not an empirical estimate, and it risks double-counting: many proposed speedups (better ideas, better experiments, early stopping) still require running enough large experiments to validate and integrate them. Moreover, “max speed” depends on how you define “software progress” (loss, benchmarks, capability thresholds, or economically relevant performance), and different definitions can have very different ceilings. A skeptic can accept that “a lot of smart labor helps” while still claiming that without more compute you cannot cross certain capability thresholds quickly. Without operationalizing “progress” and grounding the speedup distribution in data, the “low max speed is implausible” objection is not decisive.