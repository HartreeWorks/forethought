**“The ‘Strongest-Link’ Escape Routes Are Compute-Entangled”** (attacks **Pivot P4: “There are multiple possible routes… scaffolding, data flywheel, better experiments… compute bottleneck only works if all routes are compute-bottlenecked.”** This pivot is load-bearing because it claims there will exist at least one high-ρ route.) The proposed routes are not independent of compute in the way the argument needs: scaffolding quality depends on base-model capability (trained with large compute), data flywheels require massive inference and filtering (still bounded by fixed hardware-time), and “designing better experiments” ultimately needs executed runs to validate generalization. If all candidate routes converge on a shared need for high-trust, high-scale validation, then “pick the most favorable ρ” doesn’t help—the frontier-validation complementarity reappears across routes. In that case, the paper’s “compute bottlenecks don’t slow early stages” conclusion fails because the strongest-link still runs through the same compute gate. What would need to change is a concrete pathway to large capability gains that is demonstrably dominated by compute-light work (e.g., formal methods/theory or guaranteed-transfer modular improvements) and an argument that it can compound to superintelligence without frequent frontier-scale checks.