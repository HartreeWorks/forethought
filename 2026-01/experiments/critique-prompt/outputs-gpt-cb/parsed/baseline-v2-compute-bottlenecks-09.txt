"Neglecting Non-Compute Physical and Organizational Bottlenecks" — The paper frames the debate as “compute vs cognitive labor,” but in real AI R&D the bottlenecks often include data availability/quality, experiment management infrastructure, memory bandwidth, communication overhead, hardware utilization, energy, and human-in-the-loop evaluation or red-teaming. If those factors bind, then raising “cognitive labor” does not translate into proportionate increases in effective experimentation or reliable progress, even if compute in FLOPs is constant. This matters because the paper’s claim is that compute bottlenecks “don’t slow an SIE until late stages,” yet other bottlenecks can produce early-stage plateaus or slowdowns that look compute-like in effect. The CES simplification hides multi-input complementarity: even if labor substitutes for compute somewhat, it may be strongly complementary with other scarce inputs (high-quality data, secure deployment feedback, scarce expert oversight). By excluding these, the paper risks overstating how much acceleration is available “without any additional hardware,” because “hardware” is not just training accelerators but the whole experimental and deployment stack.