> When your "extra researchers" are themselves AI models consuming inference compute, scaling labour automatically drains the compute budget the argument assumes is held fixed.

The paper’s argument leans on the load‑bearing claim that “cognitive labour (L) and compute (K) are separable inputs in AI R&D,” so that you can hold K fixed while scaling L arbitrarily. **Countermodel:** imagine a lab where “adding researchers” means instantiating additional copies of a frontier model that each require substantial inference compute to read papers, write code, run verifiers, and even just stay interactive; in that world L is largely *implemented by* K, so scaling L necessarily consumes the same fixed compute pool. All the paper’s premises about automation and smarter researchers can hold, yet the conclusion (“compute bottlenecks won’t bite until late”) fails because the “extra labor” draws down the very K assumed fixed. If this critique holds, the CES framing in the post is mis-specified for AI: you can’t infer late-stage compute non-bottlenecking from a model that treats AI researchers as compute-free labor.