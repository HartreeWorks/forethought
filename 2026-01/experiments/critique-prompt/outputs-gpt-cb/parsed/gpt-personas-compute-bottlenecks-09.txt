[The “Local-First” Policymaker] **Target claim:** “Over the past ten years, the number of near-frontier experiments… decreased… If near-frontier experiments were truly a bottleneck, algorithmic progress would have slowed down.” **Failure mechanism (measurement/identification failure):** you’re treating a loose historical narrative as an identification strategy, but “near-frontier experiments” is a moving target (largest run size, lab consolidation, changing % of compute, changing algorithmic scaling laws, and shifting datasets). The last decade also featured massive *increases* in global compute and engineering improvements that confound your inference: progress can continue even if near-frontier experiments per lab decrease, because the world’s frontier K increased and the identity of “the frontier” shifted across actors. **Consequence:** your main rebuttal to the “near-frontier is fixed” reply doesn’t actually isolate the causal effect you need (constant-K, frontier-only constraint), so the paper fails at the specific point where it claims to have “pulled the rug out” from the skeptic.