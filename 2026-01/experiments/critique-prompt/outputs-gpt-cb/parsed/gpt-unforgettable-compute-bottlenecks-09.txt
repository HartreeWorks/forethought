"The Endogenous Complementarity Flip" — Your main conclusion (“compute bottlenecks won’t slow an SIE until late stages”) depends on treating \(\rho\) as roughly stable as \(L\) grows by orders of magnitude. But the structure of AI R&D makes complementarity *increase* with more cognitive labor: more researchers generate more candidate changes, which increases the need for empirical filtering, making compute *more* gating as \(L\) rises. Mechanism: candidate idea volume scales with researcher-thought ⇒ false-positive rate accumulates ⇒ to maintain decision quality you must run more confirmatory experiments ⇒ experiment compute grows with \(L\) rather than being substitutable; that is the opposite of the CES picture you lean on. If this objection holds, you must incorporate a selection/verification stage into the production model (ideas → tests → accepted improvements) and show that verification cost doesn’t scale up with automated research output.