> Route diversity doesn't help if every alternative path still runs through the same compute-heavy gatekeeper—training and evaluation—so having many routes may actually reinforce the bottleneck rather than route around it.

The paper’s “strongest link” framing (multiple routes to superintelligence; we’ll use whichever has favorable ρ) is load-bearing for arguing compute bottlenecks must bind across *all* routes to matter. **Reference class failure:** many “alternative routes” listed (scaffolding, data flywheel, better experiments) still depend on large-model training/evaluation as the selection mechanism that tells you which scaffold or dataset actually works, and that selection pressure is compute-intensive in a way that doesn’t disappear with more cognitive labor. In other words, route diversity does not imply input substitutability; it can just mean many paths all share the same compute-heavy gatekeeper (high-fidelity training and eval). If this critique holds, the “strongest link” move doesn’t undercut the compute bottleneck objection; it may even strengthen it by highlighting that selection/evaluation compute is a common bottleneck across routes.