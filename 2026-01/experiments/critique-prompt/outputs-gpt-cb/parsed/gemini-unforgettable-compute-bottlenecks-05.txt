**"Your ‘near-frontier experiments are declining yet progress continued’ point supports the skeptic, not you."** The paper argues that since near-frontier experiment count has decreased over the past decade while progress continued, near-frontier experiments can’t be the bottleneck. But the skeptic’s story is precisely that researchers *respond to compute scarcity by reallocating effort toward algorithmic tricks, scaling-law exploitation, and better engineering*—i.e., progress becomes dominated by whatever is feasible under a compute constraint. Observing continued progress under tightening frontier-experiment budgets is evidence of adaptation under constraint, not evidence the constraint is irrelevant; it’s compatible with a world where compute is still the binding resource that shapes the research agenda. This is a reversal result: your observation is exactly what you’d expect if compute bottlenecks are real and researchers are forced into a narrower, compute-compatible path. If the author defends by saying “adaptation can be fast in an SIE,” that concedes the skeptic’s core point: compute scarcity dictates the feasible research frontier; it doesn’t disappear.