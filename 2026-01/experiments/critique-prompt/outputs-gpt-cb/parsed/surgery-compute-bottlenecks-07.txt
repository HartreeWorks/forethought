A prominent move is the claim that “in the absolute limit, cognitive labour can fully substitute for compute (AGIs do the math in their heads), so ρ<0 is flawed in principle.” **Quantitative cliff:** any “do the math in your head” substitution requires that the cognitive system itself instantiate the computation, which—if it’s an AI—still cashes out as physical compute somewhere, and for state-of-the-art training dynamics the relevant computations (matrix multiplies over huge tensors, optimizer states, long sequences) scale so steeply that the substitution becomes astronomically inefficient. This isn’t just “impractical”; it collapses the inference that complementarity must break down near the levels relevant to an SIE, because the regime where substitution is “possible” may be many orders of magnitude beyond what a fixed-compute world can realize. If this critique holds, the “ρ can’t be <0 in the limit” point doesn’t meaningfully weaken the compute-bottleneck objection at the scales that matter to the paper’s 1-year / 5-OOM definition.