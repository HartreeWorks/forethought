The paper assumes that adding vast numbers of AGI researchers translates into proportionally better experimental design, early stopping, and “optimizing every part of the stack,” effectively converting L into progress. But inside a lab (or across labs), parallel agents face misaligned incentives: they can pad “progress” with compute-wasting sweeps, hoard promising ideas to bargain for resources, or optimize for metrics that win internal approval rather than for globally useful algorithmic advances. Your argument that “we’ll use whichever route has the most favourable ρ” ignores that routes are chosen by actors optimizing for prestige, funding, and strategic advantage, not for minimizing compute burn per unit of insight. In a high-speed SIE attempt, the equilibrium can be massive redundant experimentation and compute racing because no one trusts rivals’ results and everyone wants first-mover credit. If this objection holds, the *effective* compute available for genuine algorithmic progress shrinks due to strategic waste, and “lots of cognitive labour” produces less acceleration than your model assumes.