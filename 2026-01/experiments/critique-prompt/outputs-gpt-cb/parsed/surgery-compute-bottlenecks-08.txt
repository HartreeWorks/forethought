> Labs will rationally shift toward more compute-hungry methods as AI labour gets cheaper, pushing the system into a compute-bound regime right when automation arrives rather than only late in the trajectory.

The conclusion “compute bottlenecks likely don’t slow an SIE until late stages” depends on treating ρ as roughly stable over the SIE trajectory (or at least not getting more negative early). **Equilibrium shift:** as AI R&D becomes faster and more automated, labs rationally shift toward more compute-intensive search methods (larger sweeps, more self-play, more automated red-teaming, more elaborate synthetic data pipelines) because the opportunity cost of compute falls relative to cheap cognitive labor, making the effective production process *more* complementary in compute. That is, strategic optimization can drive ρ downward endogenously, even if today’s ρ is mild, because actors choose methods that cash out as “burn compute to buy certainty.” If this critique holds, the paper’s “early stages look similar across −0.2<ρ<0” sensitivity story breaks: the process can move into a compute-bound regime precisely when automation arrives, not only “late.”