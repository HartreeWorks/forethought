[The Technical Hardliner] Target claim: “We can apply the CES formula to AI R&D… L is cognitive labour, K is compute, Y is the pace of AI software progress.” Failure mechanism: you’re mapping a scalar macro-production function onto a multi-stage stochastic pipeline (data → training → evals → deployment feedback → safety gating) where “pace of progress” isn’t even a well-defined observable, so your ρ isn’t a parameter of anything real. Agent A (a lab) changes evaluation protocols, research goalposts, or release criteria, causing System B (“Y = progress speed”) to change without any underlying algorithmic improvement, which means your inferred ceiling/max-speed is non-identifiable. Consequence: every numerical statement like “ρ=-0.2 implies ~32× max speed” is numerology, not an estimate, and the paper’s “late-stage bottleneck” conclusion isn’t wrong so much as undefined.