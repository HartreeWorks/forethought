> Cheaper training doesn't actually free up compute for more experiments—labs just raise their ambitions to match, so the frontier's price tag keeps pace with efficiency gains.

**"The Frontier Moves When You Save Compute"** — The paper argues that **algorithmic efficiency improvements** imply **more experiments and therefore less compute-bottlenecking**, because **each improvement lets you run more experiments at the same capability level** (pulling the rug out from “compute is fixed”). The hidden crux is that the relevant object for an SIE is not “# experiments at fixed capability,” but the *rate of discovering improvements that matter at the moving frontier*, and the frontier itself shifts endogenously in response to efficiency gains. When training becomes cheaper, labs usually respond by increasing model size, context length, agentic rollout depth, or data volume—so the “near-frontier” target expands to absorb the saved compute, keeping the marginal experiment expensive. That means “more experiments” does not translate into “more frontier information per unit time,” and compute can remain binding even while efficiency improves. If this holds, the paper would need a model where the frontier’s compute demand is an increasing function of algorithmic efficiency (an induced-demand effect), rather than treating frontier cost as exogenous.