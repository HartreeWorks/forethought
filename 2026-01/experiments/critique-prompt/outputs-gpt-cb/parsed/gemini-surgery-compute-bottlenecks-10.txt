A core simplification is treating \(L\) (cognitive labour) and \(K\) (compute) as independently scalable inputs during an SIE—e.g., “in the early stages… total cognitive labour is 1–3 OOM bigger than the human contribution” while “holding compute constant.” But in AI, “more cognitive labour” typically means “more AGI instances running,” which consumes inference compute and memory bandwidth drawn from the same fixed hardware pool, making \(L\) a function of \(K\) rather than an independent axis. Counter-model: with fixed hardware, spinning up 100× more AGI researchers forces each to run 100× slower or at much smaller model size; the net researcher-seconds per wall-clock may not increase much, and may even decrease if smaller/slower models are less effective per FLOP for research tasks. Then the predicted early-stage acceleration from 1–3 OOM more \(L\) evaporates, and compute bottlenecks bite immediately through the coupling \(L(K)\). If this holds, the author must revise the production model so \(L\) is bounded by an inference-compute budget (and interacts with training-compute needs), and re-derive whether any early-stage “software-only” acceleration survives once researcher compute competes directly with experiment compute.