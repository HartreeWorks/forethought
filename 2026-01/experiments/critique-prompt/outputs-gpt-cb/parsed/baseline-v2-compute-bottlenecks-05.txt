> The "no bottleneck" argument mistakes "progress hasn't visibly slowed" for "compute isn't constraining," ignoring that a few massive frontier runs or better sub-frontier transfer could mask a real binding constraint.

"Selective Use of ‘Near-Frontier Experiments’ to Infer No Bottleneck" — The paper argues that if near-frontier experiments were a binding bottleneck, algorithmic progress would have slowed because “the number of near-frontier experiments… has significantly decreased” as training runs scaled faster than total compute. That is a shaky empirical inference: progress could be driven by a small number of near-frontier runs (still increasing in absolute compute), by better transfer from sub-frontier experiments, by data/engineering improvements, or by reallocating budgets toward fewer but higher-quality frontier runs. Also, “near-frontier” is not operationalized—whether 1% of a lab’s compute is the right threshold depends on the curvature of scaling laws and the kind of hypothesis being tested. The paper treats “not obviously slowing” as evidence against bottlenecks, but it provides no measurement of progress rate, no control for increased spending, and no counterfactual about what progress would have been with more near-frontier capacity. As a result, this rebuttal risks being an argument from anecdote, and it doesn’t decisively show that compute cannot become binding during an SIE.