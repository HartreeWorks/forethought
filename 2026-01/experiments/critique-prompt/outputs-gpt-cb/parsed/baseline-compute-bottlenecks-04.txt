The Jones-style move (“in the long run, processes reconfigure so ρ rises toward 0”) is asserted to apply to AI R&D but the paper doesn’t show that such reconfiguration is feasible without additional compute. Many proposed reconfigurations—better architectures, better training methods, better evaluations—still require empirical testing, and the time-to-reconfigure may itself be compute-limited. If reconfiguration is bottlenecked by the same scarce input, invoking it to dissolve the bottleneck risks circularity.