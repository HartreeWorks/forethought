> The paper treats multiple routes to superintelligence as independent options, but nearly all of them still funnel through the same expensive bottleneck: frontier-scale compute to validate which approach actually works.

**"Strongest-Link Mirage (Everyone Shares the Same Validator)"** — The paper argues that **multiple routes to superintelligence** imply **compute bottlenecks are unlikely**, because **we can choose whichever route has the most favorable ρ (strongest-link framing)**. The hidden commonality is that nearly all routes still require a shared, compute-intensive validator: large-scale training/evaluation to confirm generalization, robustness, and frontier capability—especially once you’re beyond regimes where toy scaling is predictive. You can propose a million alternative paradigms, scaffolds, and data flywheels with abundant cognitive labor, but selecting among them requires running the same kind of expensive discriminating tests, so the “strongest link” collapses back into a “weakest link” at the validation stage. This makes the paper’s route-diversity argument much easier to overcount: it treats routes as independent when they couple through the same bottleneck. If this holds, the paper would need to identify at least one route whose *discriminating evidence* can be obtained without frontier-scale compute, not merely a route whose *idea-generation* is less compute-heavy.