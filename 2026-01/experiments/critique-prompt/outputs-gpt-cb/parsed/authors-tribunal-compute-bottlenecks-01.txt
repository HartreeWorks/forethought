> Using a static production function to model the pace of AI progress ignores that today's research output reshapes tomorrow's production function, so the complementarity parameter ρ can't stay fixed across stages.

**“The CES Category Error”** — The paper’s key inference is that a CES production function with inputs **cognitive labour (L)** and **compute (K)** can be used to bound the *pace of algorithmic progress* (Y) via a “max speed” ceiling when ρ<0. This breaks because CES is a model of *static output from factor inputs*, while “pace of progress” is a dynamic, path-dependent object: the mapping from (L,K) to marginal research progress changes endogenously as methods, tooling, and baselines improve. In AI R&D, today’s “output” is tomorrow’s production function (e.g., better optimizers, better evaluation harnesses), so assuming a time-invariant ρ is doing the load-bearing work without justification. If this objection holds, the paper can’t treat any particular ρ-range (e.g. −0.2<ρ<0) as informative about early-vs-late SIE stages without a separate model linking factors to *knowledge accumulation*.