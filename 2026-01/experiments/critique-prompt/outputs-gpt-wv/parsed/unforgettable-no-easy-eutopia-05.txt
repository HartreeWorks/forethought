> Historically, the worst moral errors got corrected precisely when societies gained the abundance and capability the paper assumes for its "common-sense utopia," so the examples may actually evidence self-correction rather than persistent fragility.

**“Attractor Evidence Reversal”** — The paper argues that *historical and cross-view moral catastrophe shows eutopia is fragile and not reached by default* **(B)** from the claim that *most people historically lived amid grave moral wrongs that weren’t obvious even to victims* **(A)**, because *non-obvious severe flaws seem easy to introduce and persist* **(M)**. But that same evidence also supports a different mechanism: large moral errors often become *legible* and politically contestable as technology and coordination improve, suggesting an attractor toward expanding moral circles and reducing suffering once constraints loosen. The paper’s own “common-sense utopia” stipulates abundance, peace, and high capability—exactly the conditions that historically accelerated abolitionist, feminist, and humanitarian reforms—so the analogy cuts against the conclusion that errors persist “by default.” If moral learning is an attractor in high-capability regimes, then the relevant distribution conditional on survival is not “random drift among fussy dimensions,” but “biased drift toward correcting the biggest, most salient harms,” which widens the eutopian target. This is hard to route around with a paragraph because it challenges the direction of the core evidential arrow in Section 2.1–2.3: your motivating examples may be evidence *for* self-correction under the very conditions you later assume. If it holds, the paper needs a model of why future moral learning stalls or misfires *specifically in abundant, epistemically empowered societies*, rather than extrapolating from eras dominated by scarcity, violence, and limited information.