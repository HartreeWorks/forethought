> The paper's "best feasible" benchmark is drawn from worlds without deliberate optimization, then used to argue deliberate optimization is needed—a self-defeating ceiling that rises once you act on the advice.

**“Self-Referential Best-Feasible”** — The paper argues that *a mostly-great future is a narrow target even conditional on survival* **(B)** from the claim that *“best feasible” is the 99.99th percentile of outcomes under a well-informed distribution conditional on no serious de dicto optimization* **(A)**, because *we can then ask what fraction of that same distribution exceeds \(v>0.5\) or \(v>0.9\)* **(M)**. The problem is that the definition of the benchmark (“best feasible”) bakes in the very steering variable the paper later treats as explanatory: what counts as “feasible” at the 99.99th percentile depends on institutional and epistemic dynamics, which are endogenously affected by the presence/absence of de dicto optimization pressure. In other words, you are sampling “best feasible” from a world where nobody tries very hard, and then using that as the ceiling against which “trying hard” is judged necessary—creating a ceiling that shifts upward precisely when the paper’s recommended response (deliberate optimization) is introduced. This can flip the diagnosis: the target can appear “narrow” because you defined the mountain peak using a map drawn from a society that never builds climbing gear. If this holds, much of Section 1–3’s framing (“we’re far from the ceiling of flourishing”) becomes underdetermined by the paper’s own setup. Fixing it would require defining “best feasible” in a way that is policy-invariant (e.g., conditional on an explicit class of governance/optimization regimes) or else modeling feasibility as a function of optimization effort rather than holding it fixed.