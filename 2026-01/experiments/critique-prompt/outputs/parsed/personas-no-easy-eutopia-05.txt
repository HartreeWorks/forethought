The paper's entire framing of "no easy eutopia" assumes that humanity has meaningful choice about how the future unfolds, but capability development is largely exogenous to the moral deliberation the authors imagine. If one AI lab, nation, or posthuman entity achieves recursive self-improvement or space settlement capability first, they determine the trajectory regardless of what moral framework humanity converges upon. The authors' discussion of space resource allocation—"whoever was most-willing and most-able to grab them"—inadvertently concedes this point, but fails to recognize its implication: any delay introduced by "deliberation" about correct population ethics or digital welfare simply cedes the future to actors who don't deliberate. The paper treats moral progress and capability progress as separable, when in fact the latter will select which moral frameworks propagate. The consequence is that the paper's framework for thinking about eutopia is irrelevant to the actual selection dynamics that will determine the future's character.