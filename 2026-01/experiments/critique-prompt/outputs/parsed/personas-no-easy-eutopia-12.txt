[The Cognitive Scientist] The paper's framework assumes that human moral beliefs can "converge" through "truth-seeking deliberative processes" toward correct views, but this ignores extensive evidence that human moral cognition is adaptation-shaped, context-dependent, and systematically biased in ways that preclude such convergence. The "hedonic treadmill" effect the authors invoke actually undermines their argument—if preference adaptation continuously resets subjective welfare, then any specification of "wellbeing" sufficient for eutopia becomes a moving target that deliberation cannot stabilize. More fundamentally, human moral intuitions about scope, probability, and counterfactuals—precisely the domains the paper's framework requires reasoning about—are demonstrably unreliable. The authors' own acknowledgment that psychological effects make "mostly-great futures seem just about attainable" applies equally to their readers' evaluation of the paper's arguments. The consequence is that the paper proposes a deliberative path to eutopia using cognitive machinery that cannot reliably perform the required computations.