The paper frames the challenge of achieving eutopia as an epistemological problem—identifying correct moral views and steering toward them—while systematically ignoring that the actual constraints are distributional conflicts over power and resources. When the authors discuss space resource allocation, they list possible "allocation systems" as if the choice were a seminar exercise, rather than recognizing that whoever controls early space infrastructure will design allocation rules that entrench their position. The paper's repeated invocation of "society" making choices obscures that there is no such unified agent—there are competing factions whose material interests diverge. The discussion of digital being rights entirely omits that the owners of AI infrastructure have massive financial incentives to resist any framework that grants their assets independent moral claims. The consequence is that the paper's sophisticated moral philosophy floats above the actual political-economic dynamics that will determine the future, offering a framework that is irrelevant to the power struggles through which these questions will actually be decided.