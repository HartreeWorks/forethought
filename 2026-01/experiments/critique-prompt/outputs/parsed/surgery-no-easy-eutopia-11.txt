The unbounded linear view argument faces **equilibrium shift** problems regarding what future civilizations would actually do. The paper assumes that without "deliberate optimization towards" best outcomes, civilizations would fail to hit the narrow target. But advanced civilizations capable of spreading across galaxies would presumably also be capable of reasoning about value, and competitive dynamics might select for civilizations that effectively capture value. Just as market competition tends to discover efficient resource uses even without central planning, cosmic-scale civilizations might converge on high-value configurations through evolutionary or competitive mechanisms that don't require anyone to deliberately "optimize for value de dicto." If so, the conditional probability distribution used to define fussiness—outcomes "assuming no serious optimisation pressure"—describes a scenario that's cosmically unlikely to obtain.