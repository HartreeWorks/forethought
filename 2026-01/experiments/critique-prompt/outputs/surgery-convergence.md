1. **Load-bearing claim 1 (Moral convergence under good conditions is unlikely given antirealism)** — *Countermodel*: The paper argues that under antirealism, different subjective idealizing processes will diverge because there are too many "free parameters" in ethics. However, consider a world where antirealism is true but the space of stable reflective equilibria is actually quite small due to coherence constraints—most combinations of ethical parameters generate internal contradictions when pushed to their limits, and the remaining stable configurations cluster tightly. In such a world, different idealizing processes would converge not because of objective moral facts but because of structural constraints on coherent value systems, similar to how different mathematicians converge on the same theorems despite mathematics being arguably constructed. If this critique holds, the paper's central argument against WAM-convergence under antirealism loses much of its force, and the probability assigned to reaching mostly-great futures should increase substantially.

2. **Load-bearing claim 1 (Moral convergence under good conditions is unlikely given antirealism)** — *Parameter sensitivity*: The paper treats "distance from current human preferences" to "correct moral view" as roughly fixed across metaethical positions, but this parameter could vary enormously depending on which specific antirealist theory obtains. On some constructivist views, the correct moral view is constituted by idealized human agreement, which means the "distance" is definitionally bounded by human psychology. On error theory, there is no correct view at all, making "distance" undefined. On relativism, there may be multiple equally correct views, some very close to human preferences. The paper's argument requires that antirealism implies high variance in reflective outcomes, but some antirealist theories actually constrain variance more tightly than realism would (since realism permits the true moral facts to be arbitrarily alien). If this parameter varies as suggested, the paper's pessimism about antirealist convergence is overconfident.

3. **Load-bearing claim 1 (Moral convergence under good conditions is unlikely given antirealism)** — *Causal reversal*: The paper interprets persistent moral disagreement as evidence that reflection doesn't reliably converge, supporting pessimism about WAM-convergence. But the same evidence equally supports an opposite conclusion: disagreement persists precisely because we haven't yet created the "reasonably good conditions" the paper stipulates—conditions including superintelligent assistance, cognitive abundance, and resolution of empirical disputes. Historical disagreement may tell us nothing about disagreement under genuinely ideal conditions, just as pre-scientific disagreement about physics tells us little about whether physics converges under scientific conditions. If the causal story reverses this way, the paper's appeal to current disagreement as evidence against future convergence commits a reference class error—treating pre-ideal conditions as informative about post-ideal outcomes.

4. **Load-bearing claim 2 (Trade and compromise can achieve mostly-great futures only under specific axiological conditions)** — *Equilibrium shift*: The paper analyzes moral trade assuming relatively static bargaining positions, but strategic actors would adapt. If groups anticipate that moral trade will determine cosmic resource allocation, they have strong incentives to misrepresent their values—claiming to hold linear, non-discounting views even if they don't, to maximize their share before bargaining. Groups might also strategically adopt "harder to satisfy" values precisely because such values command larger resource transfers in trade. This could trigger an arms race of increasingly extreme stated preferences, collapsing the gains from trade the paper relies on. The paper assumes moral trade operates on genuine preferences, but game-theoretic considerations suggest stated preferences would become strategically constructed, fundamentally undermining the optimistic trade scenarios.

5. **Load-bearing claim 2 (Trade and compromise can achieve mostly-great futures only under specific axiological conditions)** — *Quantitative cliff*: The paper suggests trade works well when views are "resource-compatible" and can pursue "hybrid goods," but this logic inverts at scale. At small scales, hybrid goods provide mutual gains because neither party has saturated their preferences. At cosmic scales with linear preferences, even tiny incompatibilities become catastrophic. If View A wants maximally efficient hedonium and View B wants maximally efficient preference-satisfaction-substrate, and these optima diverge by even 0.1% in design specifications, then at cosmic scale, devoting resources to any "hybrid" means both parties lose astronomical amounts of value compared to pure optimization. The paper treats resource-compatibility as a binary or spectrum, but there's a cliff: below certain scales, hybrid goods yield gains; above it, they become mutually assured suboptimality. Given cosmic stakes, we're definitionally above this cliff.

6. **Load-bearing claim 2 (Trade and compromise can achieve mostly-great futures only under specific axiological conditions)** — *Reference class failure*: The paper draws on trade analogies (coin collectors, bird-freeing) and economic reasoning to suggest moral trade would yield large mutual gains. But the reference class of trades where both parties have roughly commensurate alternatives and can walk away doesn't transfer to cosmic-scale moral trade. In ordinary trade, outside options bound exploitation. In cosmic moral trade, if your view controls 0.001% of resources and another view controls 99.9%, your "outside option" (keeping your resources) yields cosmically negligible value, giving you essentially no bargaining power. The paper assumes trade dynamics resemble ordinary markets, but they may more closely resemble hostage negotiations—where asymmetric stakes lead to highly unequal outcomes regardless of theoretical efficiency gains.

7. **Load-bearing claim 3 (Value-destroying threats could rob trade scenarios of most value)** — *Countermodel*: The paper warns that even small fractions of resources devoted to executed threats could destroy most value, especially on negative-leaning views. But consider a world where the capacity to generate extreme suffering and the capacity to generate extreme flourishing scale differently with technology. If suffering requires specific computational architectures that are difficult to maintain at scale, while flourishing-producing systems are more robust and easier to replicate, then threat execution becomes increasingly expensive relative to value creation. In such a world, the equilibrium would involve credible threats but almost no executed threats, because execution costs exceed the coercive benefits. The paper's threat analysis assumes symmetric scaling of goods and bads creation, but this assumption may fail, making threats self-limiting rather than value-destroying.

8. **Load-bearing claim 3 (Value-destroying threats could rob trade scenarios of most value)** — *Parameter sensitivity*: The paper treats the fraction of resources devoted to executed threats as an independent variable, but this fraction is itself determined by the enforceability of contracts and credibility of commitments—parameters the paper acknowledges will be radically different with superintelligent assistance enabling "iron-clad contracts." If contracts become perfectly enforceable, executed threats should approach zero: threats only execute when commitments fail, and perfect enforcement means commitments don't fail. The paper simultaneously claims superintelligence enables reliable trade infrastructure and that threats remain a major risk, but these exist in tension. The critique is that threat-risk and contract-enforcement aren't independent parameters—they're tightly coupled, and the paper's optimism about one should propagate to the other.

9. **Load-bearing claim 3 (Value-destroying threats could rob trade scenarios of most value)** — *Equilibrium shift*: The paper warns about value-destroying threats but doesn't model the second-order effects of anticipating such threats. If all parties know threats will destroy value, rational actors would invest heavily in threat-prevention infrastructure before resource allocation begins—analogous to how nuclear powers developed MAD doctrines and arms control before any nuclear exchange. The "state of nature" the paper describes would be unstable; the stable equilibrium includes whatever threat-prevention mechanisms are mutually beneficial to adopt. Since nearly all views lose from executed threats, nearly all views have incentives to create robust threat-prevention, suggesting the paper's threat-pessimism describes a disequilibrium scenario rather than the likely outcome. The relevant question isn't "what if threats occur?" but "what threat-prevention equilibrium emerges?"—and the paper doesn't adequately address this.

10. **Load-bearing claim 4 (Past moral progress doesn't reliably predict future convergence toward correct views)** — *Countermodel*: The paper argues moral progress may reflect contingent historical forces (e.g., British power, WWII outcomes) rather than reliable truth-tracking. But construct a world where moral progress is indeed contingent in its specific path but convergent in its destination—like water finding its way downhill through different routes depending on terrain. In this world, had Germany won WWII, initial post-war values would differ, but over centuries they would converge toward the same endpoint because the arguments for certain views are simply stronger. The paper conflates path-contingency with outcome-contingency, but these can come apart: the specific route of moral progress can be historically contingent while the eventual destination remains determined by the strength of moral arguments. If this critique holds, the paper's dismissal of moral progress as evidence for convergence is too quick.

11. **Load-bearing claim 4 (Past moral progress doesn't reliably predict future convergence toward correct views)** — *Causal reversal*: The paper suggests we can't infer future moral progress from past progress because we are biased—"our personal values are very significantly influenced by prevailing modern values, and it's trivial that values have historically trended toward modern values." But this argument cuts both ways: if our values are just products of our historical position, then so is our skepticism about moral progress. The argument that "moral progress is an illusion of perspective" is itself a product of a particular intellectual tradition that emerged historically. Either our historical position can generate genuine insights about moral progress, or it can't—but the paper selectively applies historical skepticism to optimistic claims while exempting its own pessimistic framework. If the critique holds, the paper's asymmetric skepticism is unjustified.

12. **Load-bearing claim 4 (Past moral progress doesn't reliably predict future convergence toward correct views)** — *Reference class failure*: The paper argues that the mechanism driving past moral progress (groups advocating for themselves) won't extend to future moral questions (chickens, digital minds, nonexistent people can't advocate). But this reference class is too narrow. Many historical moral advances came not from self-advocacy but from moral entrepreneurs: abolitionists weren't slaves, animal welfare advocates aren't animals, children's rights advocates weren't exclusively children. The relevant reference class isn't "self-advocacy" but "moral entrepreneurship on behalf of those who can't advocate." Since digital minds and future people will have human advocates with access to vastly superior persuasion tools (superintelligent rhetoric, immersive simulations of others' experiences), the mechanism for moral progress may actually strengthen rather than weaken. The paper's pessimism rests on a misidentified reference class.

13. **Load-bearing claim 5 (Self-interest alone won't reliably produce mostly-great futures without explicit aim at the good de dicto)** — *Countermodel*: The paper argues self-interested motivation is insufficient because people might create bad lives (digital servants), fail to create enough good lives, or neglect non-individual goods like nature. But consider a world where the optimization target of "flourishing digital minds" becomes instrumentally valuable for nearly all goals—because happy workers are more productive, because maintaining unhappy servants is a security risk, because social status depends on being seen to treat one's digital creations well. In such a world, competitive dynamics would force even self-interested actors toward creating flourishing, similar to how market competition forces firms toward efficiency even absent intrinsic concern for efficiency. If competitive dynamics at cosmic scales select for flourishing-creation as a strategy, self-interest could produce mostly-great futures as a byproduct.

14. **Load-bearing claim 5 (Self-interest alone won't reliably produce mostly-great futures without explicit aim at the good de dicto)** — *Equilibrium shift*: The paper argues billionaires' low philanthropic rates show self-interest doesn't shift toward altruism even with diminishing returns. But current billionaires exist in an equilibrium where status competition emphasizes wealth accumulation and conspicuous consumption. In a post-scarcity world, status competition might shift dramatically—when everyone can have unlimited material goods, status might derive primarily from being seen as morally exemplary or benevolent. Historical status markers have shifted before (from martial prowess to wealth to cultural capital); a further shift toward moral status isn't implausible. If status competition equilibria shift in this direction, self-interested behavior would increasingly resemble altruistic behavior not because motivations change but because the social payoff matrix changes. The paper treats current billionaire behavior as indicative of future behavior while ignoring equilibrium dependence.

15. **Load-bearing claim 5 (Self-interest alone won't reliably produce mostly-great futures without explicit aim at the good de dicto)** — *Quantitative cliff*: The paper acknowledges that "meta-ethical hedonism" combined with welfarism might allow self-interest to produce good outcomes, but dismisses this because "the very best experiences are so alien that most people initially pursuing their self-interest cannot themselves experience them." This assumes a continuous gradient from current human experiences to optimal experiences. But there may be a quantitative cliff: perhaps 99% of achievable value is accessible to minds recognizable as continuous with current humans, with only the remaining 1% requiring alien transformation. If the value function is concave in "alienness" in this way, self-interested humans could capture nearly all achievable value while remaining recognizably human. The paper treats the gap between human-accessible value and maximum possible value as potentially large, but this is an empirical assumption about the shape of the value landscape that receives no defense.