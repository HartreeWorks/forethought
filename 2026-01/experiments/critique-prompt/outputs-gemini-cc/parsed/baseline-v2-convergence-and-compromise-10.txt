"Contradiction in Instrumental Convergence" â€” In section 4.2, the authors argue that "instrumentally valuable" goods (like knowledge or complexity) are insufficient to ensure a mostly-great future because they are merely means to an end. This conflicts with the concept of "instrumental convergence" in AI safety, which suggests that almost any final goal requires a standardized set of intermediate resources (peace, truth-seeking, cognitive enhancement). If 90% of the trajectory involves building these universally good instrumental structures, the "future" (as defined by the infrastructure and state of the world for eons) will look indistinguishable from a "good" future for the vast majority of time, regardless of the divergent final goals.