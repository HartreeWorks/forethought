> Future intelligent agents who value good outcomes will actively widen the target by solving coordination problems, so the probability of success isn't fixed by today's static aimâ€”it self-corrects.

**Equilibrium shift (Instrumental Convergence)**
The paper treats the "target" of a near-best future as a passive island that humanity must randomly drift into or perfectly navigate toward. This ignores *Equilibrium shift*: if agents in the future value these outcomes, they will actively reshape the probability space to widen the basin of attraction for those outcomes. For example, if "digital rights" are crucial for value, advanced agents have instrumental reasons to solve cooperation and rights-management problems to avoid conflict. The difficulty of the target cannot be calculated by static independent probabilities of "getting it right" today; it must account for the convergent instrumental drives of future intelligent actors who will actively error-correct the trajectory.