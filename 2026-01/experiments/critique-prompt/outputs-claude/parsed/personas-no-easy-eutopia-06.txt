[The Cognitive Scientist] The paper claims we should "hope for a 60–40 gamble between eutopia and extinction rather than a guarantee of many futures that intuitively seem truly wonderful," but treats the resulting intuitive resistance as something to be explained away rather than as evidence against the framework. The authors invoke "hedonic treadmill" effects to explain why eutopia "seems" achievable when it isn't, but this same reasoning undermines their entire methodology: if human moral intuitions systematically misjudge value comparisons at cosmic scales, then the von Neumann-Morgenstern axioms they use to generate cardinal value functions are calibrated on cognitively distorted inputs. The paper acknowledges that scope insensitivity affects how we perceive future value, yet proceeds to build a formal apparatus on scope-sensitive comparisons between galaxies and solar systems. This is incoherent—either our value intuitions are reliable enough to anchor the formal framework, or they're systematically biased in ways that invalidate the framework's conclusions about what counts as "mostly-great."