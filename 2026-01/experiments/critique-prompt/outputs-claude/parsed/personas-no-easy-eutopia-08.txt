[The Capability Accelerationist] The paper treats the question of whether humanity reaches eutopia as if it depends on our collective moral choices, but completely ignores that the relevant capabilities for shaping long-term futures are being developed competitively by multiple actors with incompatible goals. If the authors' own framework is correct that "initial periods of settlement and resource appropriation" will determine cosmic-scale outcomes, then the key variable is who develops transformative AI and space settlement technology firstâ€”not what moral framework they endorse. Safety-oriented actors who spend resources on moral deliberation will be systematically outcompeted by actors focused purely on capability development. The paper's entire premise that we can choose between "safety-focused" and "upside-focused" options assumes a coordination capacity that doesn't exist; in reality, the actors who shape the future will be selected for speed rather than correctness. The "no easy eutopia" conclusion is therefore true but for the wrong reasons: it's not that the target is narrow, but that the selection pressure on who gets to aim is orthogonal to whether they're aiming well.