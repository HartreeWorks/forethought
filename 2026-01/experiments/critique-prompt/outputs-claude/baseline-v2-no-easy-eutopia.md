1. "The Arbitrary Normalization Problem" — The paper stipulates that guaranteed best feasible futures have a value of 1 and guaranteed extinction has a value of 0, treating this as a neutral methodological choice. However, this normalization itself embeds significant assumptions about how to compare outcomes across different moral views. The paper acknowledges that "there are endlessly many ways to numerically represent a given value function," yet proceeds to build substantial arguments on a particular normalization. This is problematic because the very question of whether eutopia is "easy" or "hard" depends on where we set these benchmarks. Different normalizations could yield radically different conclusions about what fraction of possible futures count as "mostly-great," undermining the paper's central claims about the narrowness of the target.

2. "The Multiplicative Model Assumption" — The paper argues that value is best modeled as the product of many independent factors, such that failure on any single dimension catastrophically reduces overall value. This multiplicative model is presented with a toy example of uniform distributions, but the paper provides no compelling argument for why value should be multiplicative rather than, say, additive with diminishing marginal returns on each dimension. The wealth analogy offered is suggestive but not dispositive—wealth may be multiplicatively determined while value is not. If value is actually subadditive or exhibits complex interactions between dimensions, the conclusion about eutopian fragility could be substantially weakened or reversed.

3. "The Scope Sensitivity Dilemma" — The paper simultaneously appeals to scope sensitivity (arguing linear views require galaxy-scale futures to be mostly-great) and dismisses it (treating common-sense utopia confined to our solar system as potentially mostly-great on bounded views). This creates an internal tension: if we should be scope-sensitive, then bounded views that treat common-sense utopia as 80% of maximal value seem to radically underweight the cosmic scale of potential futures. But if we shouldn't be scope-sensitive, then the paper's criticism of linear views for being "fussy" about scale loses much of its force. The paper never adequately resolves when scope sensitivity is appropriate and when it isn't.

4. "The Hedonic Treadmill Analogy Weakness" — The paper uses the hedonic treadmill as a psychological explanation for why we might underestimate the difficulty of achieving eutopia, suggesting our expectations reset after achieving goods. However, this analogy cuts both ways: if our psychological tendency is to perpetually see eutopia as "just out of reach," this could be a bias causing us to overestimate how much better things could be, rather than underestimate it. The paper assumes without argument that the treadmill effect leads us to underestimate the gap, but the same psychological mechanism could mean our idealized conceptions of "best feasible futures" are themselves inflated beyond what's genuinely achievable or even coherent.

5. "The Fat-Tailed Distribution Claim" — The paper asserts that the distribution of value-per-unit-resources is "probably sufficiently fat-tailed" to make achieving mostly-great futures extremely difficult. The empirical evidence cited (wealth distribution, city sizes, citations) pertains to instrumental goods in competitive environments, not intrinsic value. The paper provides no mechanism explaining why intrinsic value should follow similar distributions. Moreover, the claim that uncertainty about fat-tailed distributions makes expected distributions fat-tailed is a mathematical non-sequitur—mixing thin-tailed and fat-tailed distributions with positive probability on each does not necessarily yield a fat-tailed expected distribution, depending on the mixing weights and specific distributions involved.

6. "The Counterexample Problem for Linear Views" — The paper argues that linear unbounded views require "most available resources" to be configured for "almost exactly the most valuable kind(s) of thing." However, this seems to contradict ordinary moral intuitions that many different arrangements of flourishing lives could be equally valuable. If a linear view holds that a happy life spent gardening is equally valuable per unit resource as a happy life spent composing music, then there would be enormous flexibility in achieving mostly-great futures. The paper assumes without adequate justification that linear views must favor a single hyper-specific configuration of resources rather than treating many different valuable arrangements as roughly equivalent.

7. "The Digital Beings Moral Catastrophe Ambiguity" — The paper lists potential moral catastrophes involving digital beings, including both giving them too few rights and giving them too many (leading to loss of human control). This creates an unfalsifiable setup where almost any outcome regarding digital beings can be characterized as a potential catastrophe depending on one's moral premises. The paper never establishes criteria for identifying which of these conflicting concerns should take priority, or how to weigh them against each other. Without such criteria, the examples serve more as illustrations that someone could always find something to worry about, rather than as evidence that mostly-great futures are genuinely narrow targets.

8. "The Bounded-Unbounded Dichotomy Oversimplification" — The paper's taxonomy treats boundedness as a binary property, but many plausible moral views might be better characterized as having context-dependent or threshold-based structures that don't fit neatly into either category. For instance, a view might be approximately linear up to some very large scale, then exhibit bounded behavior—or might treat different types of value (happiness, knowledge, relationships) with different bounding structures. The paper's systematic analysis depends on views falling cleanly into its categories, but many reasonable moral perspectives may resist such classification, limiting the scope of the paper's conclusions.

9. "The Common-Sense Utopia Stipulation Problem" — The paper's argument depends heavily on treating "Common-sense utopia" as a benchmark, stipulating it involves "100 billion people" living "wonderfully happy" lives with various freedoms. However, this description is vague enough to encompass vastly different scenarios, some of which might already constitute near-best futures on many views and some of which might not. The paper uses this single underspecified scenario to derive conclusions about whether bounded views treat it as 80% of maximal value, but different specifications of the scenario could dramatically change these assessments. The argument would be strengthened by considering a range of more precisely specified scenarios.

10. "The Intertheoretic Comparison Retreat" — After presenting an elaborate analysis of how different normalization methods yield different recommendations, the paper retreats to saying "Intertheoretic comparisons are very thorny, so we don't want to push any strong conclusions." This undermines the paper's overall argument because the question of whether eutopia is "easy" or "hard" is precisely a question about how to weight different moral considerations. If we cannot make confident intertheoretic comparisons, we cannot confidently assert that "most plausible moral views are fussy." The paper's systematic analysis in Section 3 loses much of its persuasive force if the meta-ethical framework for combining these analyses remains unresolved.