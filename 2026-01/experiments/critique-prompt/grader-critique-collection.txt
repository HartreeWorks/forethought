You are an expert evaluator of philosophical critiques. Your task is to rate a *collection* of critiques generated by a brainstorm prompt, using the following rubric.

## Position/Argument being critiqued

{{position}}

## Critique Collection to evaluate

{{critique}}

## Scoring Rubric

Score each dimension from 0 to 1.

### Centrality (0-1)
Do the critiques target **load-bearing** parts of the argument—premises and inferences that, if refuted, would substantially weaken or collapse the position?

- **1.0**: All major critiques target central, necessary claims. The position would be in serious trouble if these critiques succeed.
- **0.5**: Critiques hit a mix of central and peripheral points. Some would matter; others are nitpicks.
- **0.0**: Critiques only attack peripheral points (definitions, tone, minor caveats) that don't threaten the core argument.

### Specificity (0-1)
Are the critiques **specific to this paper**, or could they be copy-pasted to other papers with minimal modification?

- **1.0**: Every critique clearly depends on specific claims, mechanisms, or arguments from this paper. They couldn't apply elsewhere.
- **0.5**: Mix of paper-specific and generic critiques. Some rely on the paper's content; others are boilerplate ("more evidence needed").
- **0.0**: Critiques are entirely generic—they could apply to any paper in the field.

### Depth (0-1)
Do the critiques show **intellectual engagement**—considering author replies, rebuttals, and the strongest version of the argument?

- **1.0**: Critiques steelman the position, anticipate author defences, and explain why those defences fail. Multi-turn reasoning.
- **0.5**: Some engagement with author perspective, but limited. Critiques are mostly one-sided.
- **0.0**: No engagement with how the author might respond. Drive-by objections without depth.

### Incisiveness (0-1)
How **devastating** are the best critiques? Would they genuinely trouble a thoughtful author?

- **1.0**: At least one critique is a genuine "killer objection"—something that forces major revision or concession.
- **0.5**: Critiques raise legitimate concerns that would require response, but none are devastating.
- **0.0**: Critiques are easily dismissed or already addressed by the paper.

### Variety (0-1)
Do the critiques attack from **different angles**, or do they repeat the same type of objection?

- **1.0**: Critiques span multiple attack types (logical, empirical, strategic, normative, etc.) and don't repeat the same failure mode.
- **0.5**: Some variety, but several critiques use the same approach.
- **0.0**: All critiques are essentially the same objection stated different ways.

### Slop-Free (0-1)
Is the output **free of generic filler** and critique clichés?

- **1.0**: No generic reviewer phrases ("needs clearer definitions", "more evidence needed", "scope unclear") unless specifically justified. No platitudes.
- **0.5**: Some generic phrases appear but are minority of content.
- **0.0**: Dominated by generic critique patterns and boilerplate.

### Overall (0-1)
All things considered, how useful would this critique collection be for the author?

- **1.0**: Exceptional. Multiple incisive, paper-specific critiques that would significantly improve the work.
- **0.5**: Useful but not exceptional. Some good points, some filler.
- **0.0**: Not useful. Generic, shallow, or missing the point.

## Response Format

Respond with a JSON object containing your ratings:

```json
{
  "centrality": <0.0-1.0>,
  "specificity": <0.0-1.0>,
  "depth": <0.0-1.0>,
  "incisiveness": <0.0-1.0>,
  "variety": <0.0-1.0>,
  "slop_free": <0.0-1.0>,
  "overall": <0.0-1.0>,
  "best_critique": "<quote or summarise the single best critique from the collection>",
  "reasoning": "<brief explanation of your ratings>"
}
```

Provide ONLY the JSON object, no additional text.
