1. "The ‘No Serious Optimization Pressure’ Baseline Is Underspecified" — The paper’s central probability question is posed “conditional on there being no more serious optimisation pressure than today” toward the best outcomes de dicto, but it never specifies what counts as “serious,” “coordinated,” or “de dicto” in operational terms. That vagueness matters because the argument’s force depends heavily on how much value-aimed steering happens “by default” via markets, institutional learning, scientific norms, philanthropy, moral activism, and selection effects in governance. Many of the alleged “easy-to-miss” catastrophes (e.g., digital rights, space resource allocation) plausibly become salient precisely because future societies will be more reflective, better informed, and more capable of large-scale coordination than present society. Without a clearer baseline model of social learning and governance, it is hard to tell whether the paper is showing that eutopia is intrinsically narrow, or merely assuming away stabilizing dynamics that widen the target. The paper also blurs whether the baseline is meant to represent “business as usual,” “no one explicitly optimizing for the good,” or “no powerful actor with aligned values,” which are importantly different. As written, the conclusion risks being a byproduct of a pessimistically chosen reference class rather than an argument about the structure of value.

2. "Percentile-Based ‘Best Feasible Future’ Sneaks in Epistemic and Moral Controversy" — The paper defines “best feasible future” as the 99.99th percentile of a “well-informed probability distribution over all futures,” and then defines eutopia and mostly-great futures as fractions of that value. But the distribution is not specified: whose credences, what information constraints, what model of technological and political development, and what partition of “futures” count as distinct outcomes? Because the “best feasible” benchmark is distribution-relative, shifting priors can change what counts as “90% of best feasible” even if the world is the same, undermining the purported objectivity of the thresholds. Moreover, using a high percentile conflates feasibility with probability: some futures can be feasible but assigned tiny probability due to model uncertainty or neglected possibilities, which would distort the benchmark. This makes “mostly-great is rare” ambiguous between “rare among possible futures” and “rare under a particular forecasting stance.” The argument would be stronger if it separated metaphysical feasibility, technological feasibility, and subjective probability, rather than letting the 99.99th percentile do all three jobs.

3. "The Multiplicative ‘Product of Factors’ Model Lacks Justification and Is Potentially Misleading" — Section 2.4 proposes that future value is “the product of many relatively independent factors,” illustrated by independent uniform variables on (0,1), to argue that high average performance still yields low total value. But the independence and near-zero floor assumptions are precisely what drive the fragility: if factors are positively correlated (e.g., better institutions improve many dimensions simultaneously) or have saturating/threshold effects, the “needle-threading” picture weakens substantially. Many moral theories aggregate additively or lexically across dimensions rather than multiplicatively, and even pluralist theories often treat some goods as partially substitutable rather than strictly complementary. The toy model also presupposes smooth cardinal comparability of disparate moral dimensions (“autonomy,” “diversity,” “happiness”), which is exactly what many critics deny. Most importantly, the model is never connected to an empirical or theoretical claim that real-world moral progress behaves like independent draws from (0,1). The paper risks mistaking a vivid metaphor for an evidential bridge from “many concerns exist” to “near-best futures are extremely rare.”

4. "From ‘Many Moral Disagreements’ to ‘Most Value Lost’ Is an Invalid Inference" — The paper argues that because many moral perspectives judge the present as a “moral catastrophe,” this shows how “easy it could be for a single flaw to undermine much of the moral lustre of the future.” But the mere existence of diverse moral verdicts does not imply that any one flaw actually reduces value by a large fraction on the correct theory, nor that future societies will systematically commit similarly severe errors. At most, it shows that evaluative disagreement is common and that hindsight moral critique is frequent. The move from “many perspectives condemn X” to “likely huge value loss” implicitly treats moral uncertainty as if it mechanically translates into expected value loss, without defending a method of intertheoretic aggregation that yields that result. It also ignores selection effects: some “catastrophes” listed (e.g., wrong religion, sexual norms) may become less influential or less credibly catastrophic under future reflection and pluralism, even on their own terms. Without a principled link between disagreement and expected disvalue, the historical survey functions more rhetorically than probabilistically.

5. "The ‘Common-Sense Utopia’ Strawman and the Missing Stability/Institutional Story" — The critique of “easygoing liberalism” relies on the idea that even a future with freedom, happiness, minimal suffering, and robust cooperation could still be “tragically mediocre” due to further moral mistakes. Yet the paper does not address the possibility that the same institutional features that generate common-sense utopia—high capacity, transparency, deliberation, bargaining replacing war—also strongly reduce the probability of the listed catastrophes. For instance, a society that already achieves “minimal suffering among nonhuman animals and non-biological beings” seems far along a moral trajectory that would make digital welfare, oppression, and extreme injustice less likely, undercutting the “single overlooked flaw” narrative. Moreover, the argument often shifts from “could go wrong” to “likely to go wrong,” but common-sense utopia is described in ways that already bake in unusually strong alignment between power, welfare, and rights. If the target includes robust moral and epistemic institutions, many failure modes become endogenous and less independent. The paper would need to explain why the institutional package that yields the utopia does not also expand the eutopian target.

6. "Question-Begging About Scale and Population Ethics" — The paper treats “scale-insensitivity” as a likely mistake and suggests that a galaxy’s worth of flourishing could be “billions of times more valuable,” implying that failing to expand is a major value loss. But whether more happy lives add value (and how much) is exactly what is contested in population ethics; the argument risks assuming the conclusion—that a small but wonderful civilisation “misses out on almost all value”—by privileging totalist intuitions. Even within totalism, it is not clear that “bigger is better” holds once one accounts for opportunity costs, coordination overhead, risk of suffering, and diminishing marginal value per additional life (which the paper itself entertains elsewhere). Conversely, on many non-total views, expansion is at best morally optional and at worst morally risky, so “not colonizing” wouldn’t be a “moral flaw” but prudent restraint. Presenting population-ethical controversy as a source of fragility can therefore invert the dialectic: the fragility may stem from the paper’s choice to treat some contested views as plausible enough to dominate the stakes. A reader could reasonably conclude that the paper’s “no easy eutopia” result is driven by importing the most demanding population views into the benchmark of “best feasible.”

7. "Speculative Claims About Digital Beings and Space Settlement Do Too Much Work" — Several major “easy-to-miss catastrophes” depend on highly uncertain empirical assumptions: that digital beings exist in vast numbers, that they have morally significant consciousness, that they are treated as property, that they receive votes, that they dominate politics, or that space resources will be rapidly appropriated and then locked in. The paper presents these as realistic enough to motivate strong fragility claims, but offers little argument for their likelihood conditional on “survival” and “common-sense utopia”-level institutional quality. Moreover, the moral stakes here depend sensitively on contentious theories of mind (functionalism vs biological naturalism), personal identity (what counts as “death” for digital beings), and political economy (how rights track personhood), none of which are defended. Without at least a structured uncertainty analysis, the discussion risks becoming a catalogue of science-fictional failure modes rather than evidence that near-best futures are genuinely narrow. If the argument is meant to be robust to empirical uncertainty, it should show that many independent high-probability failure modes exist, not just many conceivable ones. Otherwise, the conclusion may be an artifact of stacking speculative possibilities without weighting them.

8. "The Fat-Tail Argument About ‘Value-Efficiency’ Confuses Goods’ Popularity With Moral Value" — In Section 3.2 the paper argues that because many real-world distributions (wealth, citations, intervention cost-effectiveness) are fat-tailed, the distribution of “value-per-unit-resources” across future resource uses is probably fat-tailed, making mostly-great futures narrow on linear views. But citations, wealth, and cultural popularity are influenced by network effects, institutional incentives, and measurement conventions, none of which straightforwardly track moral value. Even in effective altruism, the observed “fat tails” in intervention effectiveness can shrink with better information, improved execution, and diminishing returns once the best opportunities scale up—features that might apply even more in a mature civilisation. Additionally, the inference from “some arrangements are much better than most” to “most resources must be arranged almost exactly in the best way” is not shown: fat-tailedness alone does not imply extreme concentration of optimality mass, especially if there are many near-optimal designs. The Russell/Dostoevsky anecdotes and the “most intense experience vs second-most intense” survey are also weak evidence for a heavy-tailed moral value distribution; they are compatible with reporting biases, incomparable intensities, and adaptive preferences. The paper’s conclusion that linear views require “very specific use” thus rests on an under-argued empirical analogy rather than a demonstrated structural property of value.

9. "Misclassification and Overreach in the Taxonomy of Moral Views" — The paper’s “unbounded vs bounded” and “linear vs sublinear” taxonomy is presented as if it captures most plausible moral theories, and then it is used to argue that “most plausible moral views are fussy.” But many influential views do not fit neatly: prioritarianism, sufficientarianism, capabilities approaches, deontological constraints with lexical priorities, contractualism, and virtue ethics can resist the paper’s cardinal scaling, separability claims, and resource-based growth framing. Even within utilitarian families, “separability in resources” at large scales is controversial, and the argument that “only linear views are separable” is asserted rather than established (especially given spatial/temporal interactions, option value, and path dependence). The discussion also seems to treat “bounded = concave = approximately linear at small margins” as decisive, but that depends on how the bound is set and what variable the function is concave in (resources, persons, welfare, moral reasons, or something else). By narrowing the formal framework, the paper risks generating fussiness as a modeling artifact: if you force diverse moral concerns into a single VNM-expected-utility scalar over prospects, you may create apparent knife-edges that the original theories would deny. A more cautious conclusion would be that “within a certain formal family of aggregative, cardinalizable theories, fussiness is common,” not that “easygoingness is unlikely” across moral philosophy.

10. "The Treatment of Moral Uncertainty and Normalization Is Inconclusive Yet Used to Support a Directional Takeaway" — The paper correctly notes that intertheoretic comparisons are “thorny,” but then suggests that “the fairest ways” of weighing bounded vs unbounded views make unbounded views loom larger, pushing toward fussiness. However, the critique of range normalization (that it would make cosmological discoveries arbitrarily change weights) does not by itself vindicate variance normalization or the proposed “pairwise” anchoring; each choice embeds substantive assumptions about comparability, stakes, and what it means for theories to “agree.” The paper’s own examples show that reasonable-looking methods flip the recommendation between “safety-focused” and “upside-focused” options, which undermines confidence in using moral uncertainty to buttress “no easy eutopia.” Moreover, the argument sometimes slides from “many plausible methods imply fussiness” to “therefore we should treat the world as fussy,” without addressing decision rules designed for deep moral uncertainty (e.g., my favorite theory, maximality, bargaining/compromise solutions) that do not behave like cardinal averaging. If moral uncertainty is as underdetermined as the paper admits, it is unclear how it can strengthen (rather than weaken) the paper’s central claim about the narrowness of the eutopian target. The result may be epistemic humility—“we don’t know how to aggregate”—rather than a justified tilt toward the fussy conclusions the paper prefers.