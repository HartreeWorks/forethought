1. **“The Independence Mirage”** (attacks **Pivot P2: “the value of the future is well-described as a *product* of many relatively independent factors… so doing poorly on any one dimension loses most value”**). The essay’s toy model assumes near-independence across dimensions like digital welfare, population ethics, resource allocation, diversity, etc., but many of these are plausibly *causally and normatively coupled* in the same direction by underlying institutions (e.g., better deliberation/rights norms simultaneously improve treatment of digital beings, reduce extreme suffering, and improve governance of expansion). If the dimensions are positively correlated rather than independent uniforms, the distribution of overall value becomes far less skewed—high scores “come together” instead of being multiplicatively rare. In that world, “mostly-great” futures can be common even if each dimension is imperfect, because competence in one area is evidence of competence in others. If this objection holds, the paper’s core inference—“fragility ⇒ narrow target ⇒ no easy eutopia”—stops following from the product model. The authors would need to justify independence (or show robustness under empirically grounded correlation structures), not just illustrate skew with an independence toy case.

2. **“Multiplication Is a Choice, Not a Discovery”** (attacks **Pivot P2: “we can capture eutopian fragility by seeing the value of the future as the *product* of many factors”**). A product aggregator bakes in a very specific normative claim: that being 10% wrong on one dimension discounts *all* other dimensions proportionally, which is much stronger than the essay’s earlier “single flaws can matter a lot” intuition. Many plausible moral views instead use additive/separable structures with thresholds (e.g., “avoid extreme suffering” as a constraint, then aggregate goods), or maximin/leximin for certain bads, which can make the set of “mostly-great” outcomes *larger* than the product model implies. Under additive-with-thresholds, you can miss some speculative goods (acausal trade, infinite value, perfect population axiology) without collapsing overall value anywhere near the median. If the aggregator is not multiplicative, the quantitative punchline from the N-dimensions graph (top quartile at 0.034 when N=5) is not evidence that mostly-great futures are rare. If this objection holds, the authors would need either (i) an argument that most “plausible” moral theories approximate multiplicativity at relevant scales, or (ii) to replace the product story with one that survives across aggregator families.

3. **“Non-Obvious Flaws Don’t Imply Big Value Loss”** (attacks **Pivot P1: “single moral errors… are sufficient for the future to lose at least a significant fraction of its value… even in a world everyone approves of”**). The historical list (slavery, disenfranchisement, animal farming) establishes that moral error is common, but it does not establish that each error knocks out *most* of attainable value rather than, say, 5–20% on many views—especially once the future contains astronomically large quantities of broadly recognized goods (health, freedom from coercion, knowledge, joy). For example, even if future society mishandles digital rights, it could still realize enormous human (and biological) flourishing plus robust moral pluralism—yielding a future that many views rate above the paper’s 0.5 “mostly-great” threshold. The essay repeatedly slides from “some plausible views would call this catastrophic” to “there is no safe option where a great outcome is guaranteed on most reasonable moral perspectives,” which is a much stronger claim. If the typical magnitude of value loss from foreseeable “single flaws” is moderate rather than massive, then the paper’s “no easy eutopia” conclusion is severely weakened because the target ceases to be narrow. To fix this, the authors would need a model (or elicitation) tying specific flaw-types to cross-theory value decrements large enough to push futures below 0.5, rather than relying on exemplars that merely show disagreement.

4. **“Correctability Breaks Fragility”** (attacks **Pivot P1: “future catastrophes are easy… lasting moral errors… capturing essentially all resources that will ever be available to us”**). The argument relies heavily on *irreversibility*: early mistakes in digital personhood, space appropriation, or governance “lock in” and permanently forfeit most value. But many of the essay’s own examples (misguided wellbeing theory, scale-insensitivity, wrong equality norms, banned goods) are plausibly *revisable* under continued reflection, bargaining, and institutional evolution—especially in a stable, wealthy, non-warring “common-sense utopia” that preserves freedom of inquiry. Even for space resources, the strong irreversibility premise (“initial periods… capturing essentially all resources that will ever be available”) is contestable if expansion is gradual, if property rights are renegotiable, or if technical limits prevent permanent appropriation/defense of cosmic assets. If mistakes are often corrigible, then “mostly-great by default” becomes much more plausible: you can be temporarily wrong without permanently losing most value. If this objection holds, the paper would need to shift from “easy to accidentally introduce a single flaw” to “easy to introduce an *uncorrectable* flaw before reflection catches up,” and defend that timing/lock-in story with concrete mechanisms.

5. **“Fat Tails Don’t Equal Needle Targets”** (attacks **Pivot P4: “the distribution of value/cost… is probably sufficiently fat-tailed… so unless most resources are configured for the almost exactly most valuable kind(s) of thing, most achievable value is lost”**). The paper moves from “fat-tailed value efficiency exists in many domains” to “future value efficiency is so fat-tailed that only a tiny fraction of resource-uses are within 50% of optimum,” but that second step is doing the load-bearing work and is not established. In many combinatorial design spaces, you get *many* near-optima (broad plateaus) even when the top is extreme—meaning the tail can be fat while the set of “pretty close” configurations remains large. If there are lots of high-value architectures for minds, communities, art, discovery, and wellbeing, then unbounded-linear views would not imply a razor-thin target; “use resources for broadly flourishing lives and knowledge” could already land you above 0.5. If this objection holds, the paper’s claim that linear views are intrinsically “fussy” collapses, and with it a major plank of “only narrow slices of views are easygoing.” The authors would need to argue for *uniqueness* or *extreme sparsity* of near-optimal value-per-resource configurations in the relevant future design space, not just cite generic fat-tail prevalence.

6. **“Separable ≠ Single Blueprint”** (attacks **Pivot P4: “linear views… are separable… so there must be some single ‘value-efficient’ arrangement of resources such that… you need to recreate as many of those arrangements as possible”**). Even if a moral theory is approximately linear/separable in resources, it does not follow that there is one canonical arrangement to replicate; separability only implies additivity across parcels, not uniqueness of the maximizing parcel-type. There could be a large set of parcel-level optima (or near-optima) that are incommensurately diverse—many different flourishing civilizations, arts, relationships, contemplative states, or discovery processes that each score similarly per unit resource. If so, then “aiming at a very specific use” is not required to hit “mostly-great”; broad competence plus pluralism could suffice, making the target much bigger than the essay claims. Denying the “single blueprint” inference lets an author accept linearity while rejecting fussiness—directly undercutting the route from linear unboundedness to “no easy eutopia.” If this objection holds, the paper must either prove a strong concentration result (most value in a tiny set of parcel-types) or weaken its central conclusion about narrowness for linear views.

7. **“The VNM Filter Pre-Decides ‘Fussy’”** (attacks **Pivot P3: “we’ll only consider views where the betterness relation satisfies VNM axioms… representable with a cardinal value function v… then mostly-great is v>0.5”**). The paper’s “fussiness” diagnosis is built inside a framework where (i) completeness and (ii) independence enable the kind of fine-grained, high-stakes tradeoffs that make tiny probabilities of extreme outcomes dominate—precisely the dynamic that often generates “fussiness.” But many moral views that people find plausible reject one or both in the relevant domain: they allow incomparability across radically different futures, or they reject independence for moral “options” vs “constraints,” which blocks the paper’s own pivotal comparisons (e.g., “60–40 eutopia/extinction vs guaranteed wonderful future”). If such views are on the table, the conclusion “most plausible views are fussy” no longer follows, because the paper has excluded a major route by which “easygoingness” could be formalized (e.g., satisficing, constraint-first, or incomparability-tolerant theories that do not treat near-best as a narrow numerical band). The main conclusion then becomes conditional: “given VNM-style cardinal comparability, many views are fussy,” not “easygoingness is unlikely.” If this objection holds, the authors need either to defend the VNM restrictions as capturing “plausible” morality in this context, or to re-run the argument under alternative decision formalisms where the narrow-target result might not appear.

8. **“Cosmology Does the Work (and Might Be Wrong)”** (attacks **Pivot P5: “if the view is bounded with respect to the value of the universe as a whole… the difference humanity makes is tiny… so concave bounded functions are approximately linear in practice… and linear views are fussy”**). This pivot depends on a stack of empirical assumptions: that the universe is vastly larger than the observable region, that alien civilizations with moral status are abundant, and that their value contribution dwarfs ours, making our marginal impact “small enough” to linearize any concavity. But if the Great Filter is ahead, if moral-value-bearing life is rare, or if future light-cone control makes our influence a non-negligible fraction of morally relevant value, then bounded-concave views would not be approximately linear in practice—and could genuinely be easygoing (diminishing returns make “most value” achievable without extreme scale or perfect allocation). If the “aliens everywhere / our impact tiny” premise fails, the paper loses a primary route from boundedness to fussiness and therefore loses much of its claimed coverage (“most bounded views are fussy too”). If this objection holds, the authors must either (i) condition their conclusion on a specific cosmological/life-abundance worldview, or (ii) show that even in sparse-life cosmologies, bounded concavity still yields narrow targets at human-relevant scales.

9. **“The 10^22 Thought Experiment Smuggles a Disvalue Geometry”** (attacks **Pivot P5: “on separate aggregation bounded views… if as little as one resource in 10^22 is used toward bads… we don’t reach a mostly-great future”**). The star-by-star reasoning presumes that “one part in 10^22 bad” aggregates into “a star system’s worth” of bad that sits at ~50% of the disvalue bound—i.e., it assumes a near-linear mapping from “fraction of cosmic resources used badly” to “where we are on the bounded disvalue curve.” But that mapping is exactly what’s in dispute: many separate-aggregation bounded functions would treat dispersed, low-intensity bads very differently from concentrated horrors, and would not equate “one star system’s worth of bad” with “half the disvalue bound” unless the disvalue function is tuned to make any nontrivial bads nearly saturating. If you instead model bads as (a) avoidable/local, (b) diminishing in marginal disvalue at scale, or (c) heavily sensitive to intensity rather than resource share, then the “almost no bads allowed” conclusion does not follow, and separate-aggregation bounded views can be substantially more easygoing than the essay claims. Since the essay uses this result to argue that even the “least implausible bounded views” are fussy, breaking it re-opens a large class of plausible easygoing theories. If this objection holds, the authors would need to specify a defensible disvalue functional form (and an intensity/resource mapping) that yields the 10^22 fragility across reasonable parameterizations, rather than relying on the illustrative cosmic-fraction arithmetic.

10. **“Moral Uncertainty: The Conclusion Depends on a Normalization Bet”** (attacks **Pivot P3: “on the most plausible approaches to intertheoretic comparisons… unbounded views loom larger… so the fairest ways to evaluate options are themselves fussy”**). The essay’s final synthesis leans on a substantive claim about intertheoretic value comparison—variance normalization or the proposed pairwise scaling—yet also admits that normalization choices swing the ranking between “safety-focused” and “upside-focused” options dramatically. If a reader instead endorses a normalization that dampens unbounded tails (or treats bounded ‘common-sense utopia’ stakes as comparable to unbounded stakes), then easygoing views can dominate the aggregate, and “no easy eutopia” no longer has decision-theoretic bite under uncertainty. In that case, even granting the paper’s taxonomy of fussy vs easygoing theories, we cannot infer that we should expect a narrow target in the all-things-considered sense that motivated the paper (the initial “surviving vs flourishing” framing). If this objection holds, the authors would need to either (i) provide a principled, widely acceptable justification for the particular intertheoretic scaling that makes fussiness loom largest, or (ii) restate the main conclusion as conditional on contested metaethical machinery rather than as a robust upshot about the future being hard to make mostly-great.