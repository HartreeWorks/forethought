1. **“The Missing Prior”** — The paper’s key inference is that, *conditional on survival and absent coordinated de dicto optimization*, mostly-great futures are very unlikely, so eutopia is a narrow target. But the central object doing the work here—a “well‑informed probability distribution over all futures” under “no serious, coordinated efforts” (Sec. 1, 3.1)—is left radically under-specified, and small changes to what counts as “serious optimization” (e.g., institutional moral progress, AI-mediated governance improvements, cultural selection effects) can swing the mass on “mostly-great” outcomes by orders of magnitude. Because “likelihood of mostly-great futures” is defined relative to that distribution, the thesis risks becoming a restatement of whatever pessimism the reader bakes into the baseline dynamics. If this objection holds, the paper would need to (i) operationalize the baseline generative model (even schematically), (ii) run sensitivity analyses over plausible dynamics (moral learning rates, governance capacity, AI alignment regimes, coordination), and (iii) show robustness of “<1% mostly-great” across those baselines rather than arguing mainly from illustrative failure modes.

2. **“Multiplicative Fragility Without Independence”** — A load-bearing step is the move from “there are many ways to go wrong” to “mostly-great futures are rare,” supported by the toy model where value is the product of many *independent* factors (Sec. 2.4). The concrete failure mechanism is that real-world “dimensions” (rights for digital beings, governance quality, suffering control, resource allocation, etc.) are not plausibly independent: they are coupled by common institutions (law, oversight), shared epistemics, and by the fact that competence/values that improve one dimension often improve many others. Positive correlation and “bundling” can produce a distribution where high overall value is *more* common than the independent-product model implies, and where the main risk is a few correlated failure clusters rather than many quasi-independent traps. If this objection holds, the paper would need to replace the independence-based product story with a model that allows correlations/latent variables (e.g., “governance competence” or “moral circle expansion”) and demonstrate that “no easy eutopia” still follows under empirically plausible correlation structures.

3. **“The Fat-Tail Leap”** — The argument that linear views are fussy relies heavily on the claim that the distribution of *value-per-unit-resource over possible uses* is “sufficiently fat-tailed” (Sec. 3.2), so most resource configurations are far from optimal and you must hit very specific uses to capture most value. But the paper’s evidence for fat tails comes from domains like wealth, citations, and some intervention cost-effectiveness—domains shaped by human institutions and informational bottlenecks—then extrapolates to intrinsic value production in advanced civilizations, where design/search may be systematic and where many configurations could be near-optimal (broad plateaus). If the true landscape has wide near-optimal basins (e.g., many ways to instantiate high welfare, many computable approximations to optimal experience), then “specific use” is not a narrow target and linear views become much less fussy than claimed. To fix this, the paper would need either (i) an argument from computational complexity/search theory that intrinsically valuable states are generically needle-in-haystack, or (ii) explicit modeling showing that even with broad plateaus, most default futures still fall below the “mostly-great” threshold.

4. **“Linear ⇒ ‘Use Almost Everything’ Overstates Scale Necessity”** — The paper’s inference that, on linear unbounded views, a mostly-great future requires harnessing “almost all available resources in the accessible universe” (Sec. 3.2) is doing major work to make common-sense utopia look tiny and to make the eutopian target narrow. The failure mechanism is that “available resources” is ambiguous between physically reachable, economically/coordination-feasible, and ethically permissible resources; the set may be sharply smaller than “20 billion galaxies,” and linearity alone doesn’t imply that failing to expand is a *moral mistake* rather than an infeasibility constraint that shrinks what counts as “best feasible.” If best feasibility is constrained by realistic coordination, speed-of-light governance, expansion risks, or strong rights constraints against tiling the cosmos, then a solar-system (or local-cluster) civilization could be near-best *relative to feasible sets*, making eutopia much easier. If this objection holds, the paper would need to incorporate feasibility/coordination constraints into the definition of “best feasible future” rather than treating cosmic-scale capture as the relevant benchmark for linear views.

5. **“Aliens as a Hidden Premise”** — A key step for bounded views is: if value is bounded over the universe-as-a-whole, then because the universe is probably enormous and contains many alien civilizations, humanity’s marginal impact is tiny, so any concave bounded function is approximately linear locally (Sec. 3.3). The concrete failure mechanism is that this hinges on speculative cosmology/anthropic assumptions (many civilizations, vast morally relevant value already realized, our contribution negligible), and if those assumptions are wrong—e.g., we are early, alone, in a mostly-empty region, or expansion changes the total “universe value” dramatically—then bounded concavity could matter a lot and easygoing bounded views could be live. Since this premise is not empirically anchored, it can flip the paper’s classification of bounded views from “effectively linear ⇒ fussy” to “actually saturating ⇒ potentially easygoing.” If this objection holds, the paper would need to treat “many aliens / negligible marginal impact” as an explicit parameter with scenario analysis, and show the no-easy-eutopia conclusion across a wide range of plausible cosmic population assumptions.

6. **“vNM-Completeness Filters Out the Robust Views”** — The paper restricts attention to complete moral orderings satisfying von Neumann–Morgenstern axioms (Sec. 3.1), then argues most “plausible” views are fussy. The failure mechanism is that many candidate “easygoing” or “robust” moral theories (incomparabilism, pluralist constraints, lexical thresholds, rights as side-constraints, permissive satisficing) are precisely the ones that reject completeness/continuity/independence or resist cardinalization across radically different futures; excluding them biases the space toward theories where tiny changes can matter a lot (hence “fussiness”). Because the paper’s conclusion is partly sociological (“most plausible views are fussy”), this methodological gatekeeping can predetermine the outcome. If this objection holds, the paper would need either (i) to defend that the excluded families are implausible *independently of the thesis*, or (ii) to extend the analysis to non-vNM frameworks and show that “no easy eutopia” survives under those decision procedures.

7. **“Moral Disagreement ≠ Moral Fragility”** — Much of Section 2 motivates eutopian fragility by listing how many moral perspectives see single features as “catastrophic” (religion, conservative morality, pro-life ethics, environmentalism, socialism, animal welfare, etc.). The failure mechanism is that diversity of condemnation does not imply that near-best futures are rare; it may instead show that many moral views are *mutually inconsistent* or highly demanding, and that “catastrophe” is being used rhetorically rather than tied to the paper’s quantitative notion (e.g., <0.5 of best feasible). Without a principled aggregator or a defended credence distribution over moral views, “many groups would object” is not evidence that the eutopian target is narrow; it’s evidence that some people will complain in almost any world. If this objection holds, the paper would need to connect disagreement to expected value loss under explicit moral uncertainty handling (not just examples), or else decouple the main argument from sociological pluralism and base it on a smaller set of defended normative premises.

8. **“Population-Ethics as a One-Way Ratchet”** — The paper uses population ethics to argue that even very good futures can miss “almost all value” by being too small, too large, wrong-lifetime, or wrong-being-type, making common-sense utopia easily non–mostly-great (Sec. 2.3.1). The failure mechanism is that this treats scope-sensitivity and additive aggregation as default, but a large and philosophically serious class of views (person-affecting, wide-person-affecting, average/priority variants, or views with strong thresholds/saturation) do not regard “more happy people” as linearly increasing value, and thus do not imply that a solar-system civilization is a rounding error. If many plausible views deny that “scale shortfall” is a catastrophic moral error, then one of the paper’s main “single-flaw” channels collapses and the overall case for narrow targeting weakens substantially. If this objection holds, the paper would need to either argue that scale-sensitive population ethics should dominate credences (with justification), or rerun the fragility argument in a way that does not rely on population ethics doing so much work.

9. **“Intertheoretic Comparisons Undercut the ‘Fussy Under Uncertainty’ Result”** — In Section 3.5 the paper suggests that on “most plausible” approaches to intertheoretic comparisons, unbounded views get more weight and thereby make decision-making fussy. The failure mechanism is that the paper itself shows normalization choice can reverse recommendations (safety- vs upside-focused option), and it offers no decisive argument that variance normalization or the proposed pairwise scaling is correct; yet the headline takeaway (“fairest ways… are themselves fussy”) depends on settling that dispute. If we cannot justify a particular intertheoretic scale, then we cannot infer that moral uncertainty pushes toward fussiness rather than toward more easygoing or more ambiguity-averse policies. If this objection holds, the paper would need to either (i) provide a stronger meta-ethical argument selecting a comparison method, or (ii) weaken the central conclusion to a conditional: “no easy eutopia on some comparison rules,” rather than presenting fussiness as the robust upshot under uncertainty.

10. **“Narrow Target ⇒ ‘Needs Deliberate Optimization’ Is Not Shown”** — The paper’s concluding synthesis suggests: if mostly-great futures are a narrow range, then hitting them “must have deliberately optimised towards it” (end of Sec. 1; echoed in Sec. 4), positioning the next essay on convergence/compromise as the missing piece. The failure mechanism is that narrowness in outcome space does not imply narrowness in *basins of attraction* under plausible cultural/technological dynamics: strong convergent pressures (market selection, institutional learning, AI systems optimizing for revealed preferences, or coordination equilibria) can funnel a wide range of starting points into a small region without anyone aiming *de dicto* at “the best.” If so, the paper overstates what follows from “no easy eutopia”: the target may be narrow yet still reached by default dynamics, undermining the implied strategic pivot toward explicit steering. If this objection holds, the paper would need to separate (i) geometric narrowness in abstract value space from (ii) dynamical reachability under realistic processes, and avoid implying the necessity of deliberate optimization without modeling those dynamics.