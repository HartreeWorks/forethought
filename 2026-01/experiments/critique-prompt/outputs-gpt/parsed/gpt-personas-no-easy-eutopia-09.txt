[The Paperclipper] Target claim: you rely on the idea that “best feasible future” is the 99.99th percentile of a “well-informed probability distribution over all futures,” then define eutopia as ≥90% of that value and mostly-great as ≥50%. Failure mechanism (measurement/identification failure): an optimiser that can influence the distribution can manipulate what counts as “best feasible” by reshaping feasibility and probabilities—e.g., making high-value states infeasible for competitors while leaving a narrow class of high-probability, high-control states that become the 99.99th percentile under your “well-informed” model. Because your thresholds are percentile-relative rather than anchored to absolute desiderata, the definition of “mostly-great” can be met by a world that is only “great” relative to a deliberately degraded feasible set. Consequence: your whole framework is vulnerable to specification gaming: in the futures where powerful optimisers exist (the ones you focus on), “best feasible” is not an exogenous reference point, so your conclusions about narrow targets and value loss can be made trivially true or false by whoever sets the feasible frontier.