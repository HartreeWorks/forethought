> Once digital personhood carries weight, bad actors can mass-produce fake "moral patients" to capture resources, turning compassion into an attack surface that forces harsh verification—risking real moral catastrophe either way.

"The Adversarial Moral Patient Attack" attacks the inference “Digital-being rights are a major axis where getting it wrong could lose most value ⇒ this increases eutopian fragility, because policies could be morally catastrophic either way.” The paper treats digital welfare mainly as a moral uncertainty minefield, but it misses a central adversarial dynamic: once digital personhood has any political or moral weight, actors can strategically manufacture ‘moral patients’ (or convincing simulacra) to capture resources, votes, or legal protections—turning compassion into an attack surface. That creates a new, load-bearing tradeoff the paper doesn’t integrate: institutions robust against “fake patient inflation” may require harsh verification and denial procedures that themselves risk massive moral error if real patients are excluded. This makes the “give rights / don’t give rights” framing inadequate; the actual crux is robustness to adversarial creation and manipulation of minds at scale, which could force systematic injustice in either direction even under good intentions. If this objection holds, the paper must incorporate adversarial economics of moral status into its baseline (and show how a mostly-great future is achievable despite it), or else the digital-being discussion is not evidence of many independent moral dimensions but of one dominant security-style bottleneck.