"The ‘No Serious Optimization Pressure’ Baseline Is Underspecified" — The paper’s central probability question is posed “conditional on there being no more serious optimisation pressure than today” toward the best outcomes de dicto, but it never specifies what counts as “serious,” “coordinated,” or “de dicto” in operational terms. That vagueness matters because the argument’s force depends heavily on how much value-aimed steering happens “by default” via markets, institutional learning, scientific norms, philanthropy, moral activism, and selection effects in governance. Many of the alleged “easy-to-miss” catastrophes (e.g., digital rights, space resource allocation) plausibly become salient precisely because future societies will be more reflective, better informed, and more capable of large-scale coordination than present society. Without a clearer baseline model of social learning and governance, it is hard to tell whether the paper is showing that eutopia is intrinsically narrow, or merely assuming away stabilizing dynamics that widen the target. The paper also blurs whether the baseline is meant to represent “business as usual,” “no one explicitly optimizing for the good,” or “no powerful actor with aligned values,” which are importantly different. As written, the conclusion risks being a byproduct of a pessimistically chosen reference class rather than an argument about the structure of value.