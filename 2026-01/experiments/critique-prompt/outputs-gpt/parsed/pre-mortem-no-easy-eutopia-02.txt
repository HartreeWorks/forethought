> When you give institutional power to the "fussiest" moral views, fussiness stops being a neutral property and becomes a power-amplifying rule that rewards maximalism and erodes the coalitions needed for stable governance.

"Fussy-View Capture" — The paper argues that *most plausible moral views are fussy*, so steering toward near-best futures requires deliberate optimization, and this was adopted as justification for creating “Eutopia Steering Councils” that privileged the most demanding theories (linear unbounded, bads-sensitive bounded) in national AI objectives. The mechanism that broke was the assumption that “plausibility” tracks governance legitimacy: in real politics, giving institutional power to the fussiest views created a predictable selection effect where the most absolutist factions (and their preferred metrics) dominated because they could always argue that compromise “loses most value.” Step by step, councils moved from advisory bodies to gatekeepers of compute licenses, to arbiters of acceptable culture and research, because any dissent could be framed as risking massive value loss under some fussy theory. That sparked sustained civil resistance and legitimacy crises, causing repeated constitutional emergencies and eventually the dismantling of checks needed for AI oversight. The paper missed that “fussiness” is not just a descriptive property of moral theories; when embedded in institutions it becomes a *power-amplifying rule* that rewards maximalism and erodes coalition stability.