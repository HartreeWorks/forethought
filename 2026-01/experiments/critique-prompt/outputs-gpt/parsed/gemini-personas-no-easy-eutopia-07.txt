[The Adversarial Red-Teamer] Target claim: giving digital beings “full rights… including voting rights” could lead to them “control[ling] most aspects of how society is run,” which might be catastrophic on “human values” perspectives—treated as a plausible branch in your moral fragility list. Failure mechanism: you ignore the obvious adversarial route: malicious actors will create fake “digital beings” (or instrumentally-aligned shallow agents) as votes-on-demand to capture governance, and they will wrap it in your own rights discourse to preempt scrutiny. Attack vector: Agent A (a corporation/state) spins up trillions of “citizens” that meet whatever weak tests are used for moral status, then uses “digital voting rights” to legally seize control; System B (democracy) collapses into Sybil attacks at civilizational scale. Consequence: by presenting “AI rights with voting” as a symmetric moral risk rather than an adversarial security nightmare, you normalize a catastrophic attack surface and undercut the case for robust identity and personhood verification.