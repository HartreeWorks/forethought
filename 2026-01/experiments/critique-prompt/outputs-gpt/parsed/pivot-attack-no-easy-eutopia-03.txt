**“Non-Obvious Flaws Don’t Imply Big Value Loss”** (attacks **Pivot P1: “single moral errors… are sufficient for the future to lose at least a significant fraction of its value… even in a world everyone approves of”**). The historical list (slavery, disenfranchisement, animal farming) establishes that moral error is common, but it does not establish that each error knocks out *most* of attainable value rather than, say, 5–20% on many views—especially once the future contains astronomically large quantities of broadly recognized goods (health, freedom from coercion, knowledge, joy). For example, even if future society mishandles digital rights, it could still realize enormous human (and biological) flourishing plus robust moral pluralism—yielding a future that many views rate above the paper’s 0.5 “mostly-great” threshold. The essay repeatedly slides from “some plausible views would call this catastrophic” to “there is no safe option where a great outcome is guaranteed on most reasonable moral perspectives,” which is a much stronger claim. If the typical magnitude of value loss from foreseeable “single flaws” is moderate rather than massive, then the paper’s “no easy eutopia” conclusion is severely weakened because the target ceases to be narrow. To fix this, the authors would need a model (or elicitation) tying specific flaw-types to cross-theory value decrements large enough to push futures below 0.5, rather than relying on exemplars that merely show disagreement.