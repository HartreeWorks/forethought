> Surviving existential risks probably requires exactly the kind of coordinated, value-laden governance that would also steer us toward good outcomes, so the paper's "survive but don't optimise" baseline may be self-undermining.

**"The ‘no serious optimization pressure’ baseline is unstable and arguably incoherent"**  
The key probability distribution is “conditional on survival” but also “conditional on no serious coordinated efforts to optimize toward the best outcomes de dicto.” Yet survival itself—especially through transformative AI, biosecurity, and high-stakes governance—may require strong coordination, foresight, and explicit value-laden institutional design. If we condition on successfully navigating existential dangers, we may already be conditioning on a world with unusually capable governance and unusually intense moral/political optimization. That undermines the paper’s attempt to separate “survive by default” from “flourish only with deliberate aiming,” because the traits that drive survival may also drive high-quality moral outcomes. A critic could argue the conditionalization bakes in a pessimistic selection of worlds where we survive without acquiring the competencies that would also help us steer.