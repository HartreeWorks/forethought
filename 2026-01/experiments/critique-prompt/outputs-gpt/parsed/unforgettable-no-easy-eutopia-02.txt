"Percentile Poisoning" attacks the inference “Define ‘best feasible’ as the 99.99th percentile ⇒ ‘mostly-great’ (≥50% of best) is a useful, action-guiding threshold, because value is ratio-scaled between extinction (0) and best-feasible (1).” The 99.99th-percentile anchor makes the whole framework extremely sensitive to tail structure: if the best-feasible region is driven by one exotic, low-probability-but-feasible construction (e.g., astronomical numbers of ultra-high-value digital experiences), it stretches the scale so that almost everything else becomes <0.5 by definition. That creates an artifact where “no easy eutopia” becomes nearly tautological whenever there’s any fat-tail upside, because the denominator is set by the most extreme feasible realizations rather than by what counts as “great” in any ordinary sense. This is paper-specific because the conclusion depends on the percentile-based normalization and the 0.5/0.9 cutoffs rather than on any single moral premise. If this objection holds, the author must defend why the 99.99th percentile is not smuggling in “fussiness by construction,” perhaps by adopting a scale anchored to robust central tendencies or by showing the conclusion is invariant under reasonable alternative anchors.