The paper’s optimism leans on the load-bearing claim that **partial AM-convergence at the level of “not less than ~1 in a million (power-weighted)” is plausible**, enabling meaningful moral bargaining. **Attack type: Countermodel.** Consider a world where exactly that fraction of agents are sincerely motivated by “the good de dicto,” but almost all *decision-relevant* power is mediated through tightly-coupled institutions (compute providers, security apparatuses, launch infrastructure) whose operators adopt “values-as-constraints” compliance regimes that treat de dicto-moral agents as reliability risks and systematically exclude them from control loops. In that world, the premise (there exist AM agents at the stated frequency) holds, but they never become bargaining-relevant counterparties, so the trade/compromise pathway doesn’t activate and the conclusion (“significantly more optimism than the initial impression”) fails. If this critique holds, the paper needs a model of **how AM agents acquire *bargaining leverage*** (not just existence rates), or the compromise story stops bearing weight.