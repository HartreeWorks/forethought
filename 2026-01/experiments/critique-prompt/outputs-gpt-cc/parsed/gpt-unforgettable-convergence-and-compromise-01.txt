**"The Fitness-Gradient Smuggle"**: Your central optimism move—“narrow targets can still be hit because we hone in, like flight or wings”—attacks your own setup once you take seriously your meta-ethical discussion. Powered flight and biological wings were found because there is an externally-imposed, relentlessly optimizing gradient (aerodynamics + selection for fitness) that rewards incremental steps and punishes regress; the “target” is coupled to survival. But your paper later argues that for the good (especially under antirealism, and even under realism with weak motivation) there is no analogous, widely-shared gradient pulling diverse agents uphill toward the same optimum. Step-by-step: remove a shared gradient → “honing” is no longer a convergent process but a proliferation process → narrow-target pessimism returns exactly as in *No Easy Eutopia*. If this objection holds, you must either (i) exhibit a concrete, agent-independent optimization pressure that tracks “mostly-great futures” (not just instrumental goods), or (ii) drop the flight analogy and re-derive optimism without importing an external fitness gradient.