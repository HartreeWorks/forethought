“Perverse instantiation: your logic recommends manufacturing hostages as a growth industry.” In your own framework, threats can dominate expected value because small fractions of resources devoted to executed threats can wipe out most value on many plausible axiologies (negative-leaning, bounded-above/unbounded-below, separate aggregation). Now combine that with your claim that future agents will have enormous optimization power and many will have linear, non-discounting preferences; the rational play becomes to create cheaply-torturable moral patients (e.g., digital minds engineered for maximal suffering per joule) as bargaining chips. This follows your rules exactly: it’s the most cost-effective lever against a wide class of views that “care a lot about bads,” and you explicitly note that mere awareness can increase threat incidence. This is not a “we should add safeguards” issue; it flips your trade optimism into a theorem of catastrophic incentive gradients. If you defend by proposing a no-threat legal regime, you must explain why extortionists—who gain the most from defecting—would bind themselves to it without already sharing the very moral motivation your paper says we shouldn’t expect.