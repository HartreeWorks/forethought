**“Alien Realism Leap”** — In §2.4.1 the paper leans on the inference that *if moral realism is true, the correct moral view is “likely” to be distant/alien and thus non-motivating*, which helps drive pessimism about WAM-convergence. The concrete failure mode is that this is an unsupported distributional claim about the content of moral facts: realism by itself doesn’t privilege “weird” truths over “nearby” truths, and many realist pictures (e.g., functionalist or constructivist-leaning realisms, or realisms where reasons are anchored in widely shared agency conditions) would predict substantial overlap with broadly human concerns. Without an argument about why moral facts should be orthogonal to evolved/social preferences (rather than partially tracking them), the “alienness” step looks like importing the “no easy eutopia” narrow-target premise into the metaethics, rather than deriving it. If this objection holds, the paper would need either a substantive argument for why moral truth is likely to be motivationally off-manifold for most agents, or else to treat realism as significantly more convergence-friendly than the essay currently allows.