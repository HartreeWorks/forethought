> Cheap commitment technology doesn't guarantee cooperation—it can fuel "commitment races" where agents precommit to hardline stances, making credible threats more rational than compromise.

The paper’s optimism about compromise relies on the idea that agents with different values will voluntarily implement mutually beneficial trades once contracts are “iron-clad” and compute is abundant (3.1), but it ignores that the dominant strategy in many bargaining games is to invest in credible commitment to being uncooperative. The failure mechanism is simple: if “being the type that won’t concede” improves your bargaining position across many interactions, then selection favors agents (and delegated AIs) that precommit to hardline policies, even when cooperation is Pareto-improving. That dynamic is intensified by the paper’s own assumption of linear, non-discounting utilities (3.2–3.4), where small concessions scale to astronomical opportunity costs and thus hardline stances become more rational, not less. The concrete consequence is that instead of galaxy-splitting compromises, you get “commitment races” where factions burn resources to make threats and refusal credible, shrinking the feasible set of deals and increasing conflict probability. If this holds, the trade pathway is not the default in a compute-rich world; it’s the equilibrium exception.