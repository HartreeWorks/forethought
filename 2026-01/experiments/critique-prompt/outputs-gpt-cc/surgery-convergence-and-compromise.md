1. The paper’s optimism leans on the load-bearing claim that **partial AM-convergence at the level of “not less than ~1 in a million (power-weighted)” is plausible**, enabling meaningful moral bargaining. **Attack type: Countermodel.** Consider a world where exactly that fraction of agents are sincerely motivated by “the good de dicto,” but almost all *decision-relevant* power is mediated through tightly-coupled institutions (compute providers, security apparatuses, launch infrastructure) whose operators adopt “values-as-constraints” compliance regimes that treat de dicto-moral agents as reliability risks and systematically exclude them from control loops. In that world, the premise (there exist AM agents at the stated frequency) holds, but they never become bargaining-relevant counterparties, so the trade/compromise pathway doesn’t activate and the conclusion (“significantly more optimism than the initial impression”) fails. If this critique holds, the paper needs a model of **how AM agents acquire *bargaining leverage*** (not just existence rates), or the compromise story stops bearing weight.

2. A central pillar of the anti-WAM argument is: **under moral realism, the correct view is likely “alien,” so even if discovered it won’t be motivational (and internalists may avoid learning it).** **Attack type: Causal reversal.** “Alienness” can rationally increase rather than decrease motivation in a post-AGI setting because agents can treat moral truth as a coordination Schelling point: the *more* objective and “not just my tribe’s preferences” it seems, the more it becomes a focal basis for legitimacy, institutional design, and stable bargaining—especially when superintelligent advisors can certify arguments as robust across reflective procedures. The same evidence (“this conclusion is weird and not parochial”) can therefore support *stronger* uptake and compliance, not avoidance. If this critique holds, the realism branch no longer supports pessimism about motivational convergence; the paper’s overall downgrade of WAM-convergence would need to be conditional on a much more specific story about why “alien but certified” moral truths fail to become coordination anchors.

3. The antirealism branch relies on the load-bearing claim that **without objective moral facts, “free parameters” in ethics make convergence across reflective processes very unlikely, so WAM-convergence is improbable.** **Attack type: Reference class failure.** The paper implicitly treats “ethical reflection” as unconstrained exploration in a huge possibility space, but in a post-AGI world the relevant reflective procedures may be *heavily regularized* by shared architectures: common decision-theoretic requirements (time consistency, dynamic stability), common bargaining solution concepts, and common safety constraints against self-modification pathologies. Those constraints are not “moral facts” yet still prune the space sharply, making convergence plausible even under subjectivism (e.g., convergence on broadly similar impartial aggregation rules because they are uniquely stable under reflection plus bargaining). If this critique holds, antirealism does not robustly imply divergence at the level needed for the paper’s pessimism, weakening the inference from “no objective truth” → “no WAM-convergence” → “trade is the main hope.”

4. The trade pathway leans on the claim that **large gains from moral trade remain available in technologically mature societies, aided by low transaction costs and “iron-clad contracts.”** **Attack type: Parameter sensitivity.** This implicitly treats “contract completeness/enforceability” as near-binary (either iron-clad or not), but the feasibility of iron-clad contracts is highly sensitive to parameters the paper doesn’t integrate into the optimism: verifiability of internal states (did you really instantiate happy digital minds?), detectability of side-channels (did you create hidden suffering elsewhere?), and the cost of continuous auditing across light-speed-separated domains. Small degradations in verifiability can flip trade from positive-sum to adverse-selection-dominated, where only agents willing to cheat accept “moral” contracts. If this critique holds, the paper’s compromise optimism needs to be re-grounded in a **specific enforcement/auditing architecture**; otherwise “low transaction costs” is not a stable support for expecting realized gains from trade.

5. The paper’s “split-the-galaxies” intuition depends on the load-bearing claim that **resource-compatibility and partitioning make near-best outcomes simultaneously achievable for divergent views.** **Attack type: Quantitative cliff.** Partitioning works only before certain scale thresholds: once expansion produces many semi-autonomous, fast-replicating actors, the value of *strategic depth* (buffer zones, denial capability, monitoring shells) grows superlinearly, so groups rationally demand more than “their fair share” of resources just to feel secure. Past some expansion/replication rate, the bargaining set collapses because every additional galaxy has security externalities, so “give utilitarians other galaxies” stops being a clean Pareto improvement and becomes a contested arms-race variable. If this critique holds, the paper’s headline compromise examples are not representative; optimism should be conditioned on staying below a **security externality threshold** or on strong global security institutions (which the paper also treats as questionable under value plurality).

6. The threats section leans on the load-bearing claim that **even a small fraction of resources devoted to executed value-destroying threats can wipe out most value on many plausible moral views.** **Attack type: Countermodel.** Consider a world where actors are highly capable but cannot make *credible, targeted* threats because commitment is legible and punishable: any agent observed instantiating “threat modules” triggers immediate coalition formation and pre-commitment to disable them (since everyone fears being the next extortion target), and this norm is cheap to enforce due to ubiquitous monitoring. In that world, value pluralism and bargaining still exist, but executed threats are endogenously rare because “being a threatener” is a dominated reputational strategy. If this critique holds, threats may be less load-bearingly central than the paper suggests; the recommended prioritization (“try hard to prevent threats even if costly”) would need to be justified against equilibria where **threat deterrence emerges naturally** without heavy institutional overhead.

7. The paper also implies the load-bearing claim that **if threats are feasible, they meaningfully undermine trade because extortion can systematically transfer resources away from the correct view, even absent execution.** **Attack type: Equilibrium shift.** In bargaining environments with sophisticated agents, the ability to threaten changes what counts as a “resource”: agents will invest in threat-capability as a primary asset class, and then—crucially—*trade itself* selects for those who can credibly menace, because they extract better terms and compound power. That dynamic can turn the “partial AM-convergence + trade” story into a selection mechanism *against* AM agents (who the paper notes may be less willing to threaten), making their initial minority share shrink over time even if they start with leverage. If this critique holds, compromise is not merely “fragile to threats”; it is potentially **anti-correlated with moral quality** via selection effects, and the paper’s optimism about trade needs to incorporate this endogenous drift toward coercive bargaining equilibria.

8. A key action-guiding inference is that **preventing executed threats is a top priority, potentially more important than many other considerations, because threats can annihilate value across many axiologies.** **Attack type: Causal reversal.** Many plausible “threat-prevention” implementations (credible global enforcement, omnipresent monitoring, centralized sanction capacity) increase the payoff to capturing that enforcement layer, which can accelerate zero-sum competition over the very institution meant to suppress extortion and thereby raise the probability of catastrophic conflict or oppressive lock-in. In such a world, stronger anti-threat institutions *increase* expected disvalue by making the control point more pivotal, even if they reduce baseline extortion. If this critique holds, the paper’s recommendation to heavily prioritize threat prevention is not monotone; it requires an explicit comparison between “extortion disvalue avoided” and “centralization/contestability risk introduced,” otherwise the proposed lever may worsen the outcome it targets.

9. The “which scenarios are highest-stakes” section leans on the load-bearing claim that **one should act more on scenario (3) (broad convergence) than scenario (1) (almost no AM-convergence), because marginal actions are higher impact in (3) than personal power-seeking is in (1).** **Attack type: Parameter sensitivity.** This argument is extremely sensitive to the assumed elasticity of “Surviving” and “Flourishing” to individual action (the paper uses illustrative one-part-in-100k / one-part-in-a-million comparisons), but in worlds with high institutional inertia or fast takeoff, the true elasticities may be orders of magnitude lower—while the elasticity of “who holds pivotal power” may be higher because small early advantages compound. Under that parameterization, the dominance flips: power-seeking in (1) can outrun marginal improvements in (3), and the paper’s practical upshot (“don’t infer power-seeking”) no longer follows from its own toy arithmetic. If this critique holds, the paper needs to justify its **comparative elasticities** with a model of takeoff timing, leverage points, and compounding dynamics, not just illustrative ratios.

10. The opening move against “extreme pessimism” relies on the analogy-driven load-bearing claim that **even if mostly-great futures are a narrow target (“no easy eutopia”), deliberate honing (like flight design/evolution) can still make them reasonably likely.** **Attack type: Reference class failure.** In the flight and natural selection analogies, the optimizing process has a dense, local feedback signal tightly coupled to the target (lift, reproduction); but for “mostly-great futures,” the paper itself emphasizes that the target is metaethically contested, high-dimensional, and may lack shared evaluative feedback—so the search process is more like optimizing a proxy under distribution shift than like aerodynamics. In such domains, optimization commonly converges on **Goodharted attractors** (stable proxy-maxima) rather than the narrow “true objective” set, which undermines the very lesson the analogy is meant to teach. If this critique holds, the paper’s initial deflation of the “expected value barely above 0” inference loses its main intuitive support, and the subsequent optimism would need to rest on concrete mechanisms (institutions, bargaining, enforcement) rather than on the general claim that “narrow targets can still be hit.”