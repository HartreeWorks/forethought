1. "The ‘Narrow Target’ Premise Is Under-Argued" — The entire paper leans heavily on the inherited claim from “No Easy Eutopia” that “mostly-great futures are a very narrow target,” and then treats this as a stable background assumption across sections 2–5. But in this essay the author rarely re-defends that premise, even though many later inferences (e.g., that small residual disagreements “ensure” massive value loss) are only as strong as the narrow-target claim. The paper oscillates between “narrow in the space of policies/designs” and “narrow in the space of moral views,” yet those are different notions of narrowness with different implications for convergence and trade. If “mostly-great” is instead wide in practice because many institutional/technological trajectories robustly realize large fractions of value, then the pessimism about partial disagreement becomes overstated. Without a clearer metric of “distance from best” and a justification that value cliffs are common, the argument risks being driven by an undefended framing choice.

2. "Overextended Analogies to Flight and Natural Selection" — The introduction uses powered flight and convergent evolution as evidence that humans/future agents might “hone in” on a mostly-great future even if it is a narrow target. But those examples work because there is an externally enforced selection criterion (aerodynamic lift; reproductive fitness) that reliably penalizes failure and rewards incremental improvement. The paper later acknowledges that ethics lacks a comparable feedback signal, yet it still relies on the motivational pull of “design” and “honing in” as a live possibility. This is a weak inference: the existence of narrow targets that are routinely hit under strong selection pressure does not support hitting narrow targets without such pressure. The analogy therefore risks smuggling in precisely what is disputed—an effective, shared optimizing criterion for “the good.”

3. "Ambiguity About ‘Accurate’ and ‘Correct’ Moral Views" — WAM-convergence is defined as convergence on an “accurate understanding” of what makes the future good, plus motivation, but the paper does not settle what accuracy amounts to under the metaethical uncertainty it later foregrounds. In realist contexts, “accurate” means tracking mind-independent moral facts; in antirealist contexts, it becomes unclear whether “accuracy” means coherence, idealization, endorsement, or something else. The argument in 2.4 sometimes treats “correct view” as a single determinate target, yet in 2.4.2 it admits subjectivist targets are agent-relative, undermining the unified notion of “accuracy.” Because “accurate” shifts meaning across the paper, claims like “if WAM-convergence, we will reach a mostly-great future” become difficult to evaluate: convergence to what, and by whose standard? This conceptual slippage weakens the central inference that convergence failures predict low flourishing.

4. "A Non Sequitur from Realism to ‘Weirdness’ and Demotivation" — In 2.4.1 the author argues that if moral realism is true, the correct moral view is “likely” to be alien and distant from human preferences, which then makes widespread motivation unlikely. That step is not established: realism does not entail that moral truth is far from human motivational structures, and many realists (e.g., certain naturalist or neo-Aristotelian views) would predict substantial overlap between moral facts and human flourishing psychology. Moreover, the move from “could be motivationally demanding” to “most will avoid learning or believing it” relies on speculative psychology about information avoidance that is not defended. Even if some people avoid moral information, it does not follow that the relevant future decision-makers (who may be selected for curiosity, reflectiveness, or institutional role morality) will do so. The paper’s pessimism here depends on contestable empirical and philosophical assumptions about the content of moral truths and the dynamics of moral motivation.

5. "Misuse of Internalism/Externalism and Motivation to Believe" — The discussion of internalism suggests that if moral judgment is intrinsically motivating, then people may choose not to learn moral facts that would motivate them against self-interest. But internalism is typically a thesis about the link between sincerely judging “I ought to φ” and being motivated to φ, not about a general aversion to forming moral beliefs. The inference from internalism to strategic ignorance also overlooks that agents can be motivated by second-order commitments (e.g., wanting to be moral, wanting to be the kind of person who responds to reasons), which internalism arguably supports rather than undermines. Conversely, under externalism the paper claims convergence on correct beliefs may not translate to action; yet institutions can harness belief without intrinsic motivation via incentives, reputation, and delegation to aligned systems. As written, the internalism/externalism fork functions more like a rhetorical squeeze than a careful argument, because it ignores well-known intermediate positions (hybrid internalism, reasons externalism, Humean theories with strong moral desires) that complicate the pessimistic conclusion.

6. "The Antirealism-to-Divergence Argument Overstates ‘Free Parameters’" — In 2.4.2 the author claims that absent objective moral facts, idealization is “underpowered” and convergence is unlikely because ethics has many free parameters (welfare theory, aggregation, experience ranking, etc.). But the paper treats the space of idealization procedures as if it were almost unconstrained, when in practice reflective equilibrium processes can be strongly shaped by shared cognitive architecture, shared social-functional needs, bargaining constraints, and shared desiderata like impartiality, coherence, and avoiding arbitrariness. The argument also assumes that high-dimensional parameter spaces imply divergence, yet many complex systems show attractors where diverse starting points converge due to structural constraints. Additionally, the paper’s “astronomical haystack” metaphor presumes that most value functions are extremely “spiky,” but that is precisely the narrow-target assumption in another guise. Without showing that reflective procedures lack robust attractors, the antirealist pessimism risks being an argument from intuitive vastness rather than a demonstrated improbability.

7. "Empirical Claims About Wealth and Altruism Don’t Support the Extrapolation" — The paper uses current billionaire philanthropy rates to suggest that even massive future wealth may not increase proportional altruistic spending. But present-day philanthropy is a noisy proxy for altruistic motivation because it is entangled with taxation, reputational incentives, legal constraints, political capture, and the fact that most ‘spending’ by the rich takes the form of investment rather than consumption. More importantly, the inference from “today’s marginal giving patterns” to “post-AGI cosmic resource allocation” is a drastic extrapolation across radically different choice architectures, governance regimes, and agent types (uploads, AIs, modified humans). The argument also neglects that some models predict altruism increases with security and moral circle expansion, even if raw charitable donations do not. Because the empirical base is thin and the causal mechanisms are underspecified, the paper’s use of these data points risks functioning as mood music rather than evidence.

8. "Assumptions About Moral Trade and Contracting Are Too Optimistic" — The trade story in section 3 relies on future agents being able to identify Pareto-improving moral deals, enforce them (via “iron-clad contracts”), and avoid breakdown from mistrust and strategic behavior. But even with strong enforcement, bargaining outcomes depend on baselines, outside options, and the distribution of coercive power—features the paper acknowledges later but does not integrate into its optimism about “enormous gains from trade.” Many moral views are not representable as stable, tradeable utility functions (e.g., deontological constraints, sacred values, lexical priorities), making “compromise” conceptually incoherent rather than merely difficult. The paper also assumes separability of resource domains (e.g., “you take galaxies A–Z, we take the rest”), but in many plausible futures, values depend on global properties (total population, uniqueness, coordination, avoiding certain kinds of beings anywhere), which defeats spatial partitioning. If those complications are common, then the paper’s main “more realistic and promising” route to mostly-great futures becomes far less robust.

9. "The Threats Discussion Is Both Central and Underdeveloped" — Section 3.3 admits the authors have “not particularly dug into” threats, yet later conclusions give threats a decisive role in whether trade yields a mostly-great future (and even whether futures are worse than extinction). This is a methodological weakness: a key variable is treated as largely unanalyzed, while being used to drive major conditional verdicts in 3.4 and the conclusion. The paper also slides from “threats are possible” to “even small risks can easily eat into expected value” without modeling threat prevalence, credibility, commitment mechanisms, or equilibrium selection effects in multi-agent settings. In many bargaining theories, credible threats are limited by commitment costs, reputation effects, coalition formation, and mutually assured retaliation—none of which are seriously incorporated. Because the threats claim is doing heavy argumentative work, its current speculative treatment undermines the reliability of the overall optimism/pessimism balance.

10. "Section 5’s Decision-Theoretic ‘Focus on Scenario (3)’ Is Dubious" — The paper argues we should act more on the assumption of broad convergence (scenario 3) because actions are higher-impact there and because the author “cares more” about what happens in that scenario. But higher impact conditional on a scenario does not by itself justify prioritizing that scenario; what matters is expected value across credences, and the paper does not provide a principled rule for scenario-weighting under deep uncertainty. The second reason—caring more about scenario (3)—looks like an unstable preference that risks double-counting optimism: it makes the stakes endogenous to the scenario classification, which can rationalize ignoring pessimistic possibilities precisely when they are most concerning. Moreover, the illustrative power-seeking calculation assumes linearity between “fraction of power” and “fraction of value controlled,” a highly contestable mapping in lock-in and winner-take-all dynamics. As a result, the practical upshot section risks offering strategic advice that is not actually supported by the preceding analysis.