1. “The Billionaire Filter” (attacks Pivot 1: that “some meaningful fraction” of power-holders will exhibit partial AM‑convergence—i.e., converge on the correct moral view and be motivated to spend most resources on the good *de dicto*). The paper’s trade-based optimism requires that at least ~10⁻⁶ of *power-weighted* agents both (a) care about the good *de dicto* and (b) survive competitive selection long enough to matter at the bargaining moment. But many real selection mechanisms for power (ruthlessness, coalition-management, secrecy, willingness to take extreme risks, and tolerance for value drift in pursuit of influence) systematically screen out agents who would later hand resources to “the good overall,” especially once AGI systems can optimize for influence acquisition. If the AM‑convergent tail is drastically thinner among those who control pivotal assets (compute, enforcement, launch capacity) than among the general population, then the “moral trade minority” is absent where it counts, and the expected flourishing reverts toward the “no easy eutopia ⇒ near-zero” baseline the essay is trying to escape. If this objection holds, the paper would need an argument that *institutions or AI alignment* make moral motivation positively correlated with winning (or at least with retaining veto/exit options), rather than negatively correlated.

2. “Bargaining Happens After the Land Grab” (attacks Pivot 5: that power will be sufficiently diffuse at the relevant time for trade/compromise to operate, rather than concentrated via early lock-in). The essay acknowledges concentration of power as a blocker, but its main optimistic update implicitly uses a world where enough semi-independent actors reach a bargaining table with meaningful outside options. In many plausible post-AGI trajectories, the highest-leverage step is a short, early “capture window” (control of frontier compute, enforcement infrastructure, replication, and space launch) that strongly favors winner-take-most dynamics before any stable, pluralist bargaining institutions exist. If the future is decided during that window, then “trade across value systems” becomes mostly counterfactual: there aren’t multiple sovereign value blocs to trade with, just a dominant coalition and compliant remnants. In that case, the argument that partial AM‑convergence plus trade makes mostly-great futures plausible collapses, and the paper’s conclusion that flourishing is plausibly 5–10% (rather than ~0) loses its main mechanism. To survive this objection, the paper would need to defend a specific governance/tech story where decisive strategic advantage is *prevented* or *delayed* until after enforceable pluralist bargaining norms are in place.

3. “Galaxies Aren’t Divisible Like Coins” (attacks Pivot 2: that moral trade can approximate “you take these galaxies, we take those,” delivering near-best outcomes for multiple views). The paper’s flagship intuition—partition resources or find hybrid goods—quietly assumes separability: that one group’s optimal use of its share doesn’t impose large negative externalities on others’ value functions. But in spacefaring settings, many actions are non-separable: (i) security races (preemption, surveillance, weapon placement) create cross-border risk; (ii) irreversible cosmological engineering (star lifting, black-hole computing, conversion to dense substrates) changes the shared environment; and (iii) moral views that care about “what exists anywhere” (e.g., no suffering anywhere, preservation anywhere) are violated by the other bloc’s local choices, not merely by “taking some resources.” If separability fails, then trade cannot simply “split the cosmos,” and compromise stops being a route to mostly-great futures—because each bloc’s pursuit creates global disvalue for the other, shrinking the feasible Pareto frontier. If this holds, the paper must replace its partition/hybrid-goods optimism with a detailed account of which high-stakes goods/bads are actually separable under physics, enforcement, and epistemic constraints.

4. “Anti-Compromise Values Dominate the Menu” (attacks Pivot 2: that voluntary exchange will realize large mutual gains because many moral views are resource-compatible or can accept compromise). The essay’s trade story works best when values are smooth, tradable, and locally satisfiable (“give me X resources, I’ll let you do Y”). But many of the very moral disagreements the paper itself highlights as future-critical—digital suffering, coercion, “creating beings designed to enjoy servitude,” population ethics, threats—often generate *lexical* or *constraint-like* preferences (no amount of bliss elsewhere compensates for forbidden acts; some acts must not occur anywhere). In those cases, the surplus that makes trade possible vanishes: the “price” of allowing the other side’s project is infinite, so the Nash-style compromise the paper relies on is infeasible except via coercion or deception. If anti-compromise values are common among the powerful, then the paper’s main pro-optimism channel (partial AM‑convergence + trade) breaks, and the paper’s updated flourishing estimate should drop sharply (or become bimodal: rare win/mostly loss). To address this, the paper would need to model the distribution of “constraint vs. tradable” moral psychologies post-AGI, and show why tradable ones dominate *at the margin that matters for cosmic resource allocation*.

5. “Iron-Clad Contracts Don’t Survive Light-Cone Constraints” (attacks Pivot 2: that superintelligence enables “iron-clad contracts” and low transaction costs, making moral trade reliably implementable). The argument leans on future tech making enforcement cheap and trust easy, but many relevant enforcement problems are not computational—they are physical and relativistic: you can’t verify or punish defections across interstellar distances on timescales that keep incentives aligned, and you can’t maintain a shared adjudicator without granting it decisive power (reintroducing concentration). Moreover, “contracting” over moral performance (e.g., “don’t run suffering simulations,” “don’t deploy threats”) is notoriously non-verifiable even locally, because the relevant actions can be hidden in compute or embedded in opaque systems. If enforcement is weak where stakes are largest, then rational agents will discount promised concessions, reducing realized gains from trade and pushing outcomes toward preemptive control rather than compromise—undercutting the paper’s central optimism lever. If this objection holds, the paper would need a concrete mechanism for verifiable compliance (e.g., auditable compute substrates, credible mutual monitoring, or constrained architectures) that doesn’t itself require a hegemon.

6. “Extortion Is the Equilibrium, Not the Exception” (attacks Pivot 3: that executed value-destroying threats are likely to be small, or preventable enough that trade remains net-positive). The threats section admits thin literature and limited analysis, yet the essay’s optimistic update depends on threats not scaling to swallow most value—especially given the paper’s own admission that many axiologies are highly threat-sensitive. In bargaining games with commitment-capable agents, threats can be strategically *selected for*: an actor that can credibly precommit to “burn value you care about unless paid” can extract surplus, and competitive dynamics may favor adopting threat policies even if nobody intrinsically likes them (arms-race logic). If so, threats become pervasive not because agents are sadists, but because “being the kind of agent who threatens” is instrumentally rewarded, and superintelligence makes commitment and targeted harm cheaper. Once threats are common, the paper’s conclusion flips: partial AM‑convergence plus trade doesn’t yield mostly-great futures; it yields a future where large fractions of resources are diverted to hostage-taking and defensive spending, potentially driving expected flourishing toward zero or negative on the very moral-uncertainty grounds the essay emphasizes. To withstand this, the paper would need a more equilibrium-driven argument (not just plausibility talk) that stable norms/institutions can make “no threats” a robust attractor against unilateral deviations by commitment races.

7. “Anti-Threat Law Becomes a Hegemon or a Joke” (attacks Pivot 3: that a legal system preventing value-undermining threats could be “mutually agreeable and stable”). The essay gestures at the difficulty here, but its optimism implicitly assumes a workable middle: enough enforcement to suppress threats, without granting a single authority so much power that we’re back to the lock-in/concentration problem. In practice, anti-threat enforcement with teeth requires (i) broad surveillance/audit powers, (ii) credible sanctions, and (iii) jurisdiction across competing value blocs—each of which either centralizes authority (creating a de facto hegemon) or invites evasion (making the system toothless against the highest-stakes, most hidden threats). If enforcement centralizes, then the trade-based pluralist route to flourishing is replaced by “who aligns the enforcer,” reintroducing the narrow-target problem and undermining the paper’s optimism. If enforcement is toothless, then threats return and eat the gains from trade as in the previous objection. If this holds, the paper would need to argue for a specific institutional design (e.g., distributed, auditable enforcement with minimal discretionary power) that is stable under strategic adaptation by agents who benefit from reintroducing threats.

8. “Resource-Compatibility Is Doing Hidden Work” (attacks Pivot 4: that many views are “highly resource-compatible” or “easily-satiable,” so small transfers can buy near-best outcomes for many moral perspectives). The essay’s optimism under moral uncertainty leans on the idea that, in cosmic terms, it may be cheap to satisfy lots of views by giving them a small slice—suggesting a large Pareto surface and hence high expected flourishing. But many of the paper’s own “fork in the future” examples are precisely cases where views are *not* cheaply satiable (they demand control over the same domains, prohibit the other’s projects, or care about global properties like “no exploitation anywhere”). If the marginally common post-AGI moral views are global, non-local, and identity/ontology-sensitive (e.g., “only biological humans count,” “no digital minds,” “no value in wireheading,” “no coercion”), then “small slices” don’t buy peace or near-best outcomes; they buy isolated enclaves whose existence is still unacceptable to others. If resource-compatibility is rarer than the argument assumes, then trade cannot generally rescue us from the narrow-target problem, and the paper’s optimism should be revised downward or made conditional on a demonstrated compatibility distribution. The paper would need to operationalize compatibility (what constraints count, what global properties matter) and argue empirically/theoretically that compatible views dominate among future power-holders.

9. “Axiological Uncertainty Should Make You *More* Pessimistic Here” (attacks Pivot 3/4 combination: that, despite high uncertainty about boundedness/aggregation/negative-leaningness, the trade story still supports a substantial flourishing probability). In section 3.4 the essay itself notes that many plausible axiologies make even small executed-threat fractions catastrophic (bounded above but unbounded below; separate aggregation; heavy bad-weighting), and it also concedes deep uncertainty about which axiology is correct. But then the paper’s overall update still lands at “not near zero,” largely because trade seems promising—yet trade is exactly the scenario that creates many interfaces for threats and extortion, and thus is disproportionately punished by threat-sensitive axiologies. If you take the paper’s axiology menu seriously, adding trade may *increase* downside risk relative to simpler centralized or homogeneous-value worlds, because it multiplies strategic antagonists and threat channels. If that’s right, the argument “trade makes mostly-great futures plausible under moral uncertainty” fails: moral uncertainty pushes expected value back down (or makes it dominated by tail risks), undermining the paper’s core “anti-0% flourishing” conclusion. To fix this, the paper would need to explicitly compute (even qualitatively) how moral-uncertainty weights interact with the threat-proneness of pluralist bargaining worlds, rather than treating trade as broadly value-positive.

10. “The ‘10 in N’ Guess Breaks the Mechanism” (attacks Pivot 1/2: the paper’s implicit quantitative step that the correct view will control a nontrivial share of resources among linear/non-discounting agents, enabling meaningful bargaining outcomes). The essay offers a rough heuristic (“if 1 in N are altruistic, maybe ~10 in N among linear preferences”), but the trade-rescues-flourishing story is extremely sensitive to this share: in Nash bargaining with poor outside options, a tiny minority gets squeezed toward zero when opponents have linear, non-satiating preferences and can coordinate. Moreover, the paper itself argues that abundance pushes *more* agents toward linear, non-altruistic objectives (collector’s items, positional goods, ideology), which can massively dilute the AM‑convergent share right when bargaining power matters most. If the correct moral view’s power share is orders of magnitude smaller than the heuristic (because power selection disfavors it, and linear self-interested views explode in number), then “partial AM‑convergence + trade” no longer yields mostly-great futures; it yields token concessions at best, returning expected flourishing toward the low baseline. If this objection holds, the paper would need either (i) a model where even vanishing minorities can secure large concessions (credible exit, veto, or enforcement), or (ii) a stronger argument that moral truth/motivation correlates with strategic advantage so the correct view captures a large initial endowment rather than bargaining for scraps.