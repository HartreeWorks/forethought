1. **Is the paper’s implied “default” distribution over post-survival futures (with no serious de dicto optimisation) empirically grounded, and what does it predict about the probability mass on mostly-great outcomes?** — The central claim that mostly-great futures are a “narrow target” depends on what futures are realistically likely absent coordinated steering, but the paper does not operationalize or estimate this distribution. If real-world dynamics (institutional evolution, markets, cultural selection, AI deployment patterns) systematically push toward high-value regions, the no-easy-eutopia conclusion could weaken substantially.

2. **How accurate is the multiplicative “value as the product of many factors” model, including its independence assumptions, when tested against structured moral theories and realistic correlations among dimensions (e.g., freedom, welfare, moral reflection, institutional quality)?** — The argument for eutopian fragility leans heavily on multiplicativity and quasi-independence to make high-value outcomes rare. If key dimensions are positively correlated (or if value aggregates more additively/saturatingly), then “single-flaw ruins most value” may be much less common, making mostly-great futures less fragile than claimed.

3. **Do plausible moral views actually imply a fat-tailed distribution of value-efficiency over resource uses at advanced capability levels, and how sensitive are the conclusions to alternative tail shapes (lognormal, bounded, multimodal, etc.)?** — The paper’s claim that most resource configurations waste most value on linear views relies on extreme concentration of value in rare “best uses.” If value-efficiency is not fat-tailed (or if there are many near-optimal basins), then the target may be much larger, changing whether linear/unbounded views are necessarily “fussy” in practice.

4. **How robust is the “fussiness” result to relaxing the von Neumann–Morgenstern completeness/continuity/independence framework (e.g., incomparability, lexical priorities, deontic constraints, or non-expected-value decision rules)?** — The paper’s quantitative thresholds (eutopia ≥0.9, mostly-great ≥0.5) and many comparisons depend on representing moral views with a single cardinal vNM utility function. If many reasonable views resist such representation, the notion of “narrowness of target” may not be well-defined or may behave very differently, undermining the generality of the conclusion.

5. **What is the realistic likelihood that future societies create vast numbers of morally considerable digital beings, and what tractable indicators could determine their moral status and welfare range (including the prevalence of extreme suffering or “AI death”)?** — Several of the paper’s strongest “single-flaw” scenarios hinge on digital minds being both numerous and morally significant, yet this is an empirical/technical uncertainty about AI architectures and deployment incentives. If digital beings are unlikely to be conscious, or if welfare can be reliably bounded/monitored, the expected fragility from this domain could drop sharply.

6. **How does uncertainty about cosmology (e.g., finite vs effectively infinite universe, prevalence of alien civilisations, and what we can causally affect) quantitatively change whether bounded views become “approximately linear in practice” and therefore fussy?** — A key step claims that if the universe is vast and already value-filled, humanity’s marginal impact is small, making concave-bounded views locally linear and thus fussy. If the accessible/affectable region is smaller than assumed, or if cosmic value outside our influence is irrelevant on many views, bounded views might remain non-linear in practice, reopening space for genuinely easygoing ethics.

7. **Which method of intertheoretic comparison under moral uncertainty is defensible enough to guide action, and how often do candidate methods flip the paper’s implied priority between “survival-focused” versus “upside/steering-focused” strategies?** — The paper shows that different normalisations (range, variance, pairwise) can reverse which prospects dominate, but it does not resolve the dispute or quantify robustness across realistic option sets. If a defensible aggregation method systematically amplifies either upside-seeking or downside-avoidance, it could substantially change the practical implication of “no easy eutopia” for what we should do now.