**What is the probability that digital beings both (i) have moral status and (ii) become numerically/politically dominant (e.g., via “faster-growing … majority of voting power”), making “AI rights” decisions a primary determinant of future value?**  
   - **Paper anchor:** “there may be vast numbers of digital beings … dramatically outnumber biological beings” and “they soon become the large majority of voting power” (Sec. 2.3.2).  
   - **The flip:** If \(P(\text{digital moral patients} \land \text{dominant}) \gtrsim 50\%\), then **prioritise digital welfare/rights frameworks and preventing exploitation/lockout (including governance that handles voting/power transitions)**; if \(\lesssim 10\%\), then **prioritise other value dimensions (human welfare, space allocation, population ethics, etc.)** over digital-rights-centric strategy.  
   - **What would answer it:** A combined program of (a) empirical consciousness research tied to likely AI architectures, (b) scaling-law projections for economically valuable digital labor/agent replication, and (c) institutional analysis of enfranchisement/power transfer mechanisms under scenarios where digital agents become most of the workforce/population.