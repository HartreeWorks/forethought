1. **To what extent do agents with diverse starting values actually converge in their *endorsed* “idealized reflection” outputs when given superintelligent assistance under controlled conditions (varying meta-ethical assumptions, reflection procedures, and time/compute budgets)?** — The paper’s pessimism about WAM-convergence under antirealism and only-weak optimism under realism hinges on a largely untested empirical claim about how reflection behaves at superhuman capability. Direct evidence about convergence/divergence patterns would substantially shift the paper’s bottom-line probabilities for “mostly-great” futures via convergence rather than bargaining.

2. **How often would powerful actors choose *not* to learn, believe, or internalize conclusions from moral reflection/advice when those conclusions predictably conflict with their interests or identities (i.e., “motivational avoidance” of moral truth)?** — A central step in the paper’s argument is that even if correct moral beliefs are available (especially on realism), they may fail to motivate or may be strategically avoided. If avoidance is rare (or preventable), WAM-convergence becomes much more plausible; if it is common, many optimistic governance-by-advice stories collapse.

3. **What is the real distribution (not just possibility) of future preference types regarding diminishing returns—specifically, how prevalent are approximately linear-in-resources objectives (altruistic or not) among the agents likely to control most resources in post-AGI worlds?** — The trade/compromise story’s promise and limits depend heavily on whether the future is dominated by easily-satiable agents versus linear maximizers. If linear objectives are widespread, gains from compromise may be small and conflict/threat incentives larger; if rare, small “moral minorities” could buy near-best outcomes cheaply.

4. **In realistic post-AGI bargaining environments, how large are the achievable gains from moral trade once strategic behavior, contract design limits, coordination costs, information asymmetries, and heterogeneous risk beliefs are modeled explicitly rather than assumed away?** — The paper relies on an intuition that superintelligence enables “iron-clad contracts” and near-frictionless positive-sum bargaining, but it does not quantify how robust this is. If frictions remain large, then partial AM-convergence may not translate into mostly-great outcomes, weakening the paper’s main optimistic pathway.

5. **How common and how resource-intensive are “value-destroying threats” at equilibrium in multi-agent settings with commitment capabilities, and what institutional designs (if any) are stable against them without creating worse forms of lock-in or coercion?** — The paper flags threats as potentially dominating expected value but acknowledges limited analysis and literature. If threats are rare or containable, trade-based optimism strengthens; if they are hard to prevent or are equilibrium behavior, then even small threat probabilities could drive the paper’s forecast toward net-negative futures.

6. **What mechanisms determine whether “early lock-in” happens before reflection and bargaining mature, and what empirical indicators can forecast the timing of irreversible commitments relative to moral deliberation capacity?** — Many arguments assume “reasonably good conditions” without specifying how often conditions allow later correction rather than path dependence. If lock-in typically precedes broad reflection/trade, then both WAM-convergence and compromise routes become far less relevant, shifting recommended action toward early governance and constraint-setting.

7. **How sensitive are the paper’s conclusions to the implicit “narrow target” premise—i.e., what is the best-supported estimate of the measure/robustness of high-value futures under plausible models of value, feasibility constraints, and optimization errors?** — The entire framing (no easy eutopia, need for convergence or compromise) depends on high-value futures being both rare and fragile. If the target is wider—because many different value realizations are “good enough,” or because mistakes are corrigible—then the expected value of the future and the urgency of the paper’s proposed mechanisms change substantially.