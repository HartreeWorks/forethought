**How often do decision-makers (or representative samples) *act on* “good de dicto” recommendations when those recommendations conflict with identity, loyalties, or preferred lifestyles?**  
   - **The branch point:** *“Moral realism (or strong arguments) + motivation: WAM-convergence path”* vs *“Correct-seeming views are alien/non-motivating or actively avoided: motivation failure”*  
   - **Paper anchor:** Section 2.4.1 (realism may yield correct beliefs but weak motivation; avoidance of motivating truths) and 2.3.1 (people choose constrained advisors rather than open-ended reflection).  
   - **Indicators:** If Branch A is more likely, we’d observe high rates of stable preference revision and costly follow-through after AI-guided argumentation (e.g., policy choices, spending, personal modifications) even when it violates parochial commitments; if Branch B, we’d observe strong selection for “values-confirming” advisors, systematic refusal to run unconstrained reflection, and minimal costly behavior change despite acknowledging arguments’ validity.  
   - **Time sensitivity:** **Within 12–24 months**, before “advisor ecosystems” and default reflection products become entrenched and shape longer-run moral trajectories.