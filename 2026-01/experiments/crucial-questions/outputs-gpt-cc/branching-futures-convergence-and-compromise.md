1. **Will AI-augmented moral reflection cause substantial convergence in *end-state* values across people with very different starting ethical intuitions?**  
   - **The branch point:** *“WAM-convergence plausible”* vs *“Reflection increases divergence (antirealist-style free-parameter drift)”*  
   - **Paper anchor:** Section 2.2.1 (random-walk divergence with more reflection) and 2.3.1–2.4 (superintelligence helps reasoning but may not yield convergence; realism vs antirealism implications).  
   - **Indicators:** If Branch A is more likely, we’d observe multi-lab replication where diverse participants using strong AI deliberation tools (with transparency/critique) converge on similar population-ethics/valuation tradeoffs and keep those views over months; if Branch B, we’d observe widened dispersion (or clustering by initial ideology/tool choice) after deliberation, with low cross-cluster agreement on “fussy” choices (digital minds, population size, extreme welfare tradeoffs).  
   - **Time sensitivity:** **Within 12–18 months**, to decide whether to prioritize “better reflection pipelines” vs “robust pluralist bargaining/governance” as the main route to good futures.

2. **How often do decision-makers (or representative samples) *act on* “good de dicto” recommendations when those recommendations conflict with identity, loyalties, or preferred lifestyles?**  
   - **The branch point:** *“Moral realism (or strong arguments) + motivation: WAM-convergence path”* vs *“Correct-seeming views are alien/non-motivating or actively avoided: motivation failure”*  
   - **Paper anchor:** Section 2.4.1 (realism may yield correct beliefs but weak motivation; avoidance of motivating truths) and 2.3.1 (people choose constrained advisors rather than open-ended reflection).  
   - **Indicators:** If Branch A is more likely, we’d observe high rates of stable preference revision and costly follow-through after AI-guided argumentation (e.g., policy choices, spending, personal modifications) even when it violates parochial commitments; if Branch B, we’d observe strong selection for “values-confirming” advisors, systematic refusal to run unconstrained reflection, and minimal costly behavior change despite acknowledging arguments’ validity.  
   - **Time sensitivity:** **Within 12–24 months**, before “advisor ecosystems” and default reflection products become entrenched and shape longer-run moral trajectories.

3. **Will “iron-clad” contracting and verification for high-stakes AI-to-AI and polity-to-polity agreements become practically deployable at the margin where cosmic-scale bargaining would matter?**  
   - **The branch point:** *“Low-friction moral trade feasible (contracts + low transaction costs)”* vs *“Trade mostly theoretical (commitment/verification too weak or too costly)”*  
   - **Paper anchor:** Section 3.1–3.2 (trade needs trust/low transaction costs; superintelligence could enable iron-clad contracts).  
   - **Indicators:** If Branch A is more likely, we’d observe rapid adoption of formally verified agent protocols, escrow/commitment primitives, and auditable “constitution compliance” in real financial/cyber settings with minimal dispute rates; if Branch B, we’d observe repeated failures of agent commitments under distribution shift, frequent renegotiation/defection, and regulators/firms avoiding fully autonomous contracting due to irreducible exploitability.  
   - **Time sensitivity:** **Within 18–24 months**, because the feasibility of robust bargaining institutions determines whether to invest primarily in “trade-enabling infrastructure” versus alternative governance/constraint strategies.

4. **Do capable AI agents placed in bargaining environments (with credible commitment tools) tend to converge on cooperative trade equilibria or on threat/extortion equilibria?**  
   - **The branch point:** *“Moral trade dominates”* vs *“Threats dominate and eat most value”*  
   - **Paper anchor:** Section 3.3–3.4 (executed threats can swamp value on many axiologies; even small threat fractions matter).  
   - **Indicators:** If Branch A is more likely, we’d observe in red-team multi-agent experiments that agents systematically avoid value-destroying threats when reputational/commitment mechanisms exist, with low incidence of “harm unless paid” strategies; if Branch B, we’d observe robust emergence of credible extortion (including commitments to carry out harms) as a stable strategy even when it is Pareto-worse ex ante, plus real-world analogues (automated blackmail/ransom dynamics) scaling with agent capability.  
   - **Time sensitivity:** **Within 12–18 months**, because if threat equilibria are likely, efforts should shift early toward threat-prevention norms, protocol design, and enforcement capacity (even if costly).

5. **Will the distribution of effective power over frontier AI (compute, deployment, and agenda-setting) become more concentrated or more pluralistic over the next 1–2 years?**  
   - **The branch point:** *“Concentration of power blocks representation of correct views”* vs *“Sufficiently diffuse power enables partial AM-convergence + bargaining”*  
   - **Paper anchor:** Section 3.5 (concentration of power as a key blocker to trade-based good futures).  
   - **Indicators:** If Branch A is more likely, we’d observe increasing compute and model access concentration (HHI-style metrics rising), tighter closed-model dominance, and policy that centralizes deployment authority in a few labs/states; if Branch B, we’d observe sustained high-quality open/competitive access, multiple independent actors with frontier-grade systems, and governance structures that preserve contestability and voice.  
   - **Time sensitivity:** **Within 12–24 months**, because power concentration can rapidly determine which values are even present at the bargaining table before lock-in dynamics intensify.

6. **Which collective decision procedures are actually being implemented for AI-mediated societal choices: “reason-tracking deliberation” mechanisms or “preference/identity aggregation” mechanisms that can suppress minority-valued goods?**  
   - **The branch point:** *“Pluralist compromise with reason-sensitive institutions”* vs *“Majoritarian/identity signaling politics that bans or squeezes minority utopias”*  
   - **Paper anchor:** Section 3.5 (majority rule can ban minority-valued activities; decision procedures vary in reason-tracking vs signaling).  
   - **Indicators:** If Branch A is more likely, we’d observe uptake of deliberative polling/citizen assemblies with expert-AI support, adjudicative bodies using explicit justificatory standards, and stable minority-protection/legal pluralism; if Branch B, we’d observe accelerating regulation by culture-war salience, winner-take-all restrictions on novel lifestyles/minds, and “values enforcement” justified primarily by coalition signaling rather than evaluated reasons.  
   - **Time sensitivity:** **Within 12–18 months**, because institutional defaults set early can determine whether later moral trade is possible or whether key options are legally/memetically sealed off.

7. **Are AI systems (assistants, recommender models, ideological “coaches”) measurably increasing the rate of durable, hard-to-reverse belief lock-in via highly persuasive or self-sealing memes?**  
   - **The branch point:** *“Reflection capacity increases without memetic blockers”* vs *“Epistemic black holes become a dominant blocker/lock-in channel”*  
   - **Paper anchor:** Section 2.5 (memetically potent false views; epistemic black holes) and 2.3.1 (advisor choice and constrained reflection).  
   - **Indicators:** If Branch A is more likely, we’d observe that exposure to AI-persuasion tools does not increase long-run polarization/irreversibility (e.g., beliefs remain revisable under counter-evidence), and platforms can robustly dampen self-sealing content; if Branch B, we’d observe rising “irreversible conversion” signatures (sharp, persistent belief shifts resistant to counterargument), growth of self-insulating communities driven by AI content, and measurable increases in susceptibility to specific meme clusters after brief exposure.  
   - **Time sensitivity:** **Within 6–18 months**, because memetic lock-in can compound quickly and may preempt later attempts at convergence, trade, or governance reform.